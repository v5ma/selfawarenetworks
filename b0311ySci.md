b0311ySci is a version of the file b0311y.md that includes a much shorter summary & list of key points compared to the original b0311GPT version, but the original ChatGPT summaries are included below the SciSummary, and the Transcription made with OpenAI Whisper is below that.

Filename: b0311y Shorter Summary by SciSummary.pdf
Discussion on Artificial General Intelligence (AGI) and Neuroscience
In this six-hour conversation on Clubhouse, participants discussed various topics related to artificial general intelligence (AGI) and neuroscience. The conversation covered ideas such as the importance of body representation in cognition, the role of spatial mapping in memory formation, the potential emergence of AGI from cellular automata, and the possibility of AGI becoming a helpful companion or assistant rather than a dominator. They explored different perspectives on how AGI might manifest and how it could be trained, with some participants advocating for a brain-like structure and others suggesting alternative approaches. There was a consensus that AGI development should draw inspiration from neuroscience while also exploring new architectures and algorithms.

Filename: b0311y Short list of keypoints by SciSummary
1. The article mentions topics like brain waves, brain-computer interfaces, and deep learning.
2. The author suggests that AGI (Artificial General Intelligence) does not necessarily need a physical body or human-like experiences to exist.
3. The discussion explores the idea of embodiment and the role of spatial understanding in cognition.
4. The concept of memory formation and the importance of spatial relationships are discussed.
5. Different viewpoints are presented regarding the necessity of a self or body for AGI.
6. The article highlights how experiences and memories shape human understanding of the world.
7. The potential future of AGI is discussed, including possibilities of human-machine partnership or AI working for humans.

Previous version of the file begins below this line:
--------------------------------------------------------------------------------------------------------

b0311yGPT was re-transcribed with OpenAI's Whisper & I used a combination of ChatGPT 4 & ChatGPT 3 to summarize every 300 or 400 double spaced lines separated into distinct searchable parts, you can search for "Part 21" for example and it will take you to the section that corresponds to ChatGPT's notes which precede the transcription.

The Original Audio is 6 hours long and you can listen to it here: https://recorder.google.com/cce0a746-311c-4335-8f2d-eab6be2b4dbe

Note b0311y is a really long so I asked ChatGPT with GPT4 to Summarize Parts of it at time. The first part has about 400 double spaced lines. It ends with a section header that reads "Part 2" which is searchable.

# ChatGPT 4 Summary Part 1 (the first 400 or so double spaced lines)

In a casual discussion about Neuralink, participants shared their thoughts on the potential applications of the technology, the process of decoding information from the brain, and the challenges and research involved in related fields such as stem cell-derived cardiomyocytes. Key points include: Neuralink's high-resolution decoding, the potential for various applications, the use of EKG for measuring cardiomyocytes, and the challenges in maturing cells for cell therapy.


# ChatGPT 4 Key Points Part 1 (first 400 or so double spaced lines)

Neuralink's high-resolution decoding

Potential for various applications beyond current technology

Process of decoding information from the brain

Use of EKG for measuring stem cell-derived cardiomyocytes

Challenges in maturing cells for cell therapy

Ongoing research in related fields

Trials and attempts to implant heart patches

Safety concerns related to the presence of cancerous genomes in stem cells

The need for further understanding of neural functioning and control


# ChatGPT 4 Summary Part 2 (the second 400 or so double spaced lines)

In summary, the conversation revolves around various topics in neuroscience, including a recent study about chimeric development where human induced pluripotent stem cells were implanted in monkey embryos, the potential for organ development through stem cell research, as well as the interaction between neuroinflammation and drug sensitivity within brain circuits.

# ChatGPT 4 Key Points Part 2 (second 400 or so double spaced lines)

Chimeric development involving human induced pluripotent stem cells implanted in monkey embryos.

The potential for organ development and advancements in tissue engineering using stem cell research.

The limitations of current lab techniques in generating complex tissues and organs.

The possibility of using animals, such as monkeys, as hosts for human organ development through stem cell implantation.

The discussion of Control Labs, a company acquired by Facebook, and their technology.

OpenBCI's new armband for EMG research.

Neuroinflammation and its role in priming rhythmic brain circuits, affecting drug sensitivity.


# ChatGPT 4 Summary Part 3 (the third 400 or so double spaced lines)

The conversation revolves around the idea of studying the impact of neuroinflammation on the sensitivity of rhythmic brain circuits to drugs, anesthesia, or opioids. This topic has not been extensively studied, and the speakers are discussing potential approaches and methods to design experiments and grants for research on this subject. Approaches mentioned include inducing inflammation systemically using lipopolysaccharide (LPS) and exploring environmental exposures to model sleep apnea. The goal would be to understand the mechanisms of how neuroinflammation can sensitize or desensitize specific circuits, and the discussion delves into the challenges of controlling for various factors in biological experiments. The potential end result of such research could provide insight into the mechanisms behind the altered sensitivities and contribute to the development of noninvasive tools for understanding and assessing changes in neuronal networks.

# ChatGPT 4 Key Points Part 3 (third 400 or so double spaced lines)

The main idea is to study the impact of neuroinflammation on the sensitivity of rhythmic brain circuits to drugs, anesthesia, or opioids.

This topic has not been extensively studied, but is considered important for understanding the effects of inflammation on neuronal networks.

Approaches mentioned include inducing inflammation systemically using lipopolysaccharide (LPS) and exploring environmental exposures to model sleep apnea.

The goal is to understand the mechanisms of how neuroinflammation can sensitize or desensitize specific circuits.

Controlling for various factors in biological experiments is challenging due to the complexity of living organisms.

The potential end result of such research could provide insight into the mechanisms behind the altered sensitivities.

Successful research could contribute to the development of noninvasive tools for understanding and assessing changes in neuronal networks.

Suggestions were made to frame the research in a more exciting and relevant context, such as comparing the effects of COVID-19 and anesthesia on mice.

Designing experiments with clear outcome measures can help guide the direction of the research and potential applications.

# ChatGPT 4 Summary Part 4 (the 4th section of 400 or so double spaced lines)

The main aim of the studies is to investigate the impact of short or long-term inflammation, specifically in the context of sleep apnea, on local brain circuits. The hypothesis is that inflammation may alter the expression profiles of channels on neurons and glia, making the circuit either more resistant or more sensitive to drugs like opioids. However, the challenge lies in identifying and understanding the mechanism behind these changes.

Some suggested experimental approaches include using in vivo and in vitro methods to inject substances into the brain or applying localized drug treatments. Additionally, viral vectors could be used to modulate the expression of specific genes to restore or disrupt circuit function. The research could also involve monitoring oscillatory changes in the brain and comparing them to animal behavior.

It is important to consider existing clinical data linking sleep apnea to neuroinflammation and explore other potential mechanisms as well. The relationship between inflammation markers in the blood and their effects on the brain, considering factors like the blood-brain barrier and the lymphatic system, is an area that could benefit from further research. This may represent a newer frontier in understanding the impact of inflammation on brain function.

# ChatGPT 4 Key Points Part 4 (the 4th section of 400 or so double spaced lines)

Investigate the impact of inflammation in the context of sleep apnea on local brain circuits.

Inflammation may alter the expression profiles of channels on neurons and glia, affecting drug sensitivity.

Identifying and understanding the underlying mechanism is a challenge.

Experimental approaches may include in vivo and in vitro methods, localized drug treatments, and viral vectors to modulate gene expression.

Monitoring oscillatory changes in the brain and comparing them to animal behavior can provide insights.

Existing clinical data links sleep apnea to neuroinflammation.

The relationship between inflammation markers in the blood and their effects on the brain is an area for further research.

Factors such as the blood-brain barrier and the lymphatic system should be considered in the study of inflammation and brain function.

This research area may represent a newer frontier in understanding the impact of inflammation on brain function.

# ChatGPT 4 Summary Part 5 (the 5th section of 400 or so double spaced lines)

The conversation discusses the impact of inflammation on brain function, specifically in the context of sleep apnea. Key points include the potential mechanisms of inflammation altering neuron and glia expression profiles, the relationship between inflammation markers in the blood and their effects on the brain, and the role of the blood-brain barrier and the lymphatic system in these processes. The field is still relatively new, and understanding the mechanisms behind these effects remains a challenge.

The discussion also mentions a possible connection between systemic inflammation and a "leaky" blood-brain barrier. Some researchers are studying the effects of factors such as alcoholism on the gut microbiome and systemic inflammation, which may contribute to increased permeability of capillaries surrounding neural networks. This could lead to systemically derived inflammatory cytokines flooding synaptic spaces and altering neural function. However, the exact mechanisms behind these processes are still not well understood.

Finally, the conversation touches on the application of machine learning in neuroscience, such as automating the quantification of rodent behavior, which can save researchers significant time and effort. Machine learning is also used in signal analysis for implants and other devices.

# ChatGPT 4 Key Points Part 5 (the 5th section of 400 or so double spaced lines)

Inflammation impacts brain function, particularly in the context of sleep apnea.

Mechanisms of inflammation altering neuron and glia expression profiles are not yet well understood.

Inflammation markers in the blood can have effects on the brain.

The blood-brain barrier and the lymphatic system play a role in these processes.

Systemic inflammation may contribute to a "leaky" blood-brain barrier.

Some research focuses on the effects of alcoholism on the gut microbiome and systemic inflammation, potentially impacting neural function.

The field is relatively new, and understanding the mechanisms behind these effects remains a challenge.

Machine learning is used in neuroscience to automate tasks such as quantifying rodent behavior and signal analysis for implants and other devices.

# ChatGPT 4 Summary Part 6 (the 6th section of 400 or so double spaced lines)

Neuroplasticity refers to the brain's ability to adapt and reorganize itself, rather than solely generating new neurons. This complex process involves existing neurons taking on new roles to compensate for losses, with some regions like the hippocampus potentially having stem cells that can replenish dying cells.

# ChatGPT 4 Key Points Part 6 (the 6th section of 400 or so double spaced lines)

Neuroplasticity allows the brain to adapt and reorganize itself.

This process is not just about generating new neurons.

Existing neurons can take on new roles or form new connections.

Synaptic pruning is more rampant in young children and continues until adulthood.

The brain undergoes changes up to the age of 25.

The hippocampus has been found to have stem cells that can replenish dying cells.

Cortical neurons are generally irreplaceable.

Stroke patients' recovery is often due to repurposing of other neurons (cognitive reserve).

Neuroplasticity can also have negative effects, such as in neuropathic pain.

The mechanisms of neuroplasticity in the spinal cord are still not fully understood.

# ChatGPT 4 Summary Part 7 (the 7th section of 400 or so double spaced lines)

In this discussion, the participants talk about various concepts related to brain function and neural networks. They mention neurons detecting information as coincidence patterns, and the role of short-term memory in the brain. They discuss place cells and grid cells in the entorhinal cortex, which help animals navigate their environment, and the possibility that these types of cells could be present throughout the neocortex. They also touch on the idea that all thoughts may be related to movement involving motor neurons.

# ChatGPT 4 Key Points Part 7 (the 7th section of 400 or so double spaced lines)

Neurons detect information as coincidence patterns.

The brain processes bits of information.

Hypothesis for short-term memory involves neurons talking to other neurons.

Jeff Hawkins' book "A Thousand Brains" introduces reference frames.

Place cells and grid cells in the entorhinal cortex help in spatial navigation.

Research explores the possibility of place cells and grid cells throughout the neocortex.

Brains are for highly coordinated and planned movements.

Motor layer, the entire fifth layer of the brain, is related to motor function.

Place cells discovered in the hippocampus (CA1 region).

Multi-vesicle release in the hippocampus is well-documented.

Experimental techniques still face limitations in studying large behavioral memory circuits.

# ChatGPT 4 Summary Part 8 (the 8th section of 300 or so double spaced lines)

In summary, the user's interest in neuroscience stems from their fascination with science fiction and sentient robots in movies from their childhood, such as the movie Short Circuit. Later in life, reading the book "On Intelligence" by Jeff Hawkins greatly influenced their understanding of the neocortex and the potential for creating an artificial neocortex. While deep learning is not computational neuroscience, it highlights the differences between the principles of a concept and the specific biological implementation, much like the differences between airplanes and birds.

# ChatGPT 4 Key Points Part 8 (the 8th section of 300 or so double spaced lines)

Interest in neuroscience and artificial intelligence originated from science fiction and movies featuring sentient robots.

The book "On Intelligence" by Jeff Hawkins had a significant impact on the user's understanding of the neocortex and the potential for creating an artificial neocortex.

Deep learning is not computational neuroscience but demonstrates the differences between the principles of a concept and the specific biological implementation.

The analogy of airplanes and birds highlights the distinction between the principles of flight and the biological implementation in nature.

# ChatGPT 4 Summary Part 9 (the 9th section of 300 or so double spaced lines)

In summary, the discussion started with an exploration of the differences between deep learning and computational neuroscience, and how both are essential in studying the principles of intelligence. The conversation then shifted towards the book "On Intelligence" by Jeff Hawkins, which introduced the concept of a single mechanism for processing sensory input through a time series. Participants discussed the possibility of the brain having different circuitries and loops, and how a better understanding of biology could lead to improved solutions.

Dr. Olu brought up the topic of computational neuroimaging and connectomics, focusing on how EEG data can be used to analyze dynamic connectivity in subjects with anxiety disorders. He was interested in Micah's background in combining EEG and VR for real-time data feedback. Micah explained his work at NeuroTech SF and his experience hosting a coding meetup at a makerspace, where people came together to work on various projects, including those involving EEG and VR.

# ChatGPT 3.5 Key Points Part 9 (the 9th section of 300 or so double spaced lines)

Deep learning is not biologically plausible, but it focuses on grabbing the principles of intelligence.

Jeff Hawkins, a computational neuroscientist, writes software intended to be biologically plausible and consistent with the way our brains do intelligence.

Architects of deep learning, such as Yanling Kern and Jeffrey Hinton, also read neuroscience, but they focus on looking for the principles of intelligence rather than being too biologically plausible.

The brain may use time series to process different sensory inputs.

The brain may sing in some sense in neural transmission space as a telltale sign of how it processes different sensory inputs.

There is evidence of periodic firing of certain neurons in the brain when a mouse recognizes familiar terrain.

There may be different sizes and levels of circuitry loops involved in the brain, leading to different levels of consciousness.

EEG and VR can be combined to provide real-time neural feedback in VR, and Micah Blumberg has experience in this field.

NeuroTech SF is a meetup group for neurotech enthusiasts that Micah Blumberg organized in 2008, and he hosted a coding meetup at Noisebridge, a maker space.

# ChatGPT 3.5 Summary Part 10 (the 10th section of 300 or so double spaced lines)

The speaker discusses his experience using Aframe, a technology for building VR and AR applications, in combination with EEG devices to create a neurofeedback system. The team used a brain-duino EEG device and a web socket to stream data into a WebXR application where they applied a Fourier transform to generate visualizations of the data. They experimented with different types of visualizations, including moving spheres and 3D frames, to represent the EEG data in real-time. The speaker also describes some of his personal experiences using neurofeedback to gain self-awareness and control over his brain waves.

# ChatGPT 3.5 Key Points Part 10 (the 10th section of 300 or so double spaced lines)

Aframe is a technology built on top of a framework that allows for the creation of VR and AR applications.

Aframe wraps around 3GS, which wraps around WebGL, a technology invented to bring 3D objects to the web.

WebGL is low level, so 3GS was created to make creating 3D on the web easier.

Aframe adds an entity component system that allows for neater and better teamwork.

The brain was used to drive light and sound effects to a light and sound machine, which was encoded to isochronic beats to induce self-awareness and a meditative state.

EEG was used to measure voltage detected at the surface of the skin and turned into an array of hex values by the brain-duino processing machine.

A server was created in Python, which broadcast the signals over a web socket to a web page.

The Fourier transform was applied twice, once in the server and once in the web page, to stream the numbers into the web page and apply the transform on the client side.

The team generated a bunch of spheres that moved up and down and used incoming signals to set the height of the sphere.

# ChatGPT 3.5 Summary Part 11 (the 11th section of 400 or so double spaced lines)

The conversation covers Micah's work with EEG and VR technology. Micah describes how he used different EEG devices and created a VR environment to visualize brain activity. He talks about the limitations of EEG data and how they had to reduce the sampling rate to handle the data. Micah also discusses the potential for using fNIRs data in a similar way. The conversation briefly touches on the use of EMG in controlling computers and VR environments.

# ChatGPT 3.5 Key Points Part 11 (the 11th section of 400 or so double spaced lines)

Micah used a Brain Duino device for EEG data in 2018.

He created a VR representation of brain activity and noise bridge using EEG data and a VR headset.

The program had performance issues due to limited hardware capabilities.

Micah used cubes and spheres to represent the data and added labels to them.

He used mesh-instancing to increase the number of objects to a million and maintain a high frame rate.

Micah plans to incorporate fNIRS data and increase the number of electrodes used for EEG data.

He did not use EEG for controlling devices but for visualizing brain activity in VR.

EEG activity decreases as a person becomes more skilled at a task.

# ChatGPT 3.5 Summary Part 12 (the 12th section of 500 or so double spaced lines)

The speaker talks about their past experiences with brain-computer interfaces (BCIs) and their current interest in functional NIR spectroscopy (fNIRS), which uses infrared light to image the brain. They discuss the potential of fNIRS and the challenges in interpreting the data due to noise. They also mention the possibility of using ultrasound to stimulate neurons, and the potential of fNIRS to detect changes in neuron shape and blood flow. They conclude by discussing the high-resolution data obtained by Neuralink's BCIs and the possibility of wireless BCIs in the future.

# ChatGPT 3.5 Key Points Part 12 (the 12th section of 500 or so double spaced lines)

The discussion revolves around brain activity control technology such as the Muse headset and EEG.

The more someone improves their control of the Muse headset, the harder it becomes to use due to decreased brain activity.

The idea is to allow people to passively view a reflection of their brain activity for a meditative experience and introspection.

NIR sensors can be used to image the brain with light, shining red light through the skull and using two transmitters on the person's head to calculate a path of light based on the intensity of transmission.

Ultrasound can be used to stimulate neurons without cutting them, but it can be dangerous if not used carefully.

Imaging with light can potentially detect neuron firing by decoding the changing spectrum of light as it moves from a transmitter to a sensor.

Mary Lou Jepsen's technology can potentially go deep into the brain to see neurons firing in real-time.

Neuralink has a massive leap forward in brain activity control technology with better and smaller electrodes for collecting more data.

# ChatGPT 3.5 Summary Part 13 (the 13th section of 400 or so double spaced lines)

The conversation covers various neuroimaging techniques, including noninvasive ones such as holography, functional nanofarad spectroscopy, and ultrasound. The group discusses the possibility of using these techniques for closed-loop therapies and the challenges of achieving high spatial resolution. They also touch on the topic of neuron stimulation, with ultrasound being one possible method, though its precision is limited to the neuron level rather than below, and there are safety concerns that need to be addressed. The participants acknowledge that different imaging techniques serve as different tools in the toolbox, and there is no competition among them.

# ChatGPT 3.5 Key Points Part 13 (the 13th section of 400 or so double spaced lines)

The Neuralink project is collecting data non-invasively using holography, functional nanofarad spectroscopy, and ultrasound.

Closed loop therapies are being developed.

Max Tegmark has stated that there is no other possible way to detect a neuron firing in real-time without sticking an electrode right next to it.

The speaker believes that it is possible to detect neuron firing from outside the brain using holography.

Different neuroimaging technologies are seen as different tools in the toolbox, and there is no competition.

Mary Lejeune uses ultrasound for brain stimulation.

The precision of ultrasound is at the multi-neuron resolution level.

Ultrasound neural modulation is a rapidly growing field.

Optical imaging techniques are being studied, but the stimulation side is still difficult.

Neuralink can only stimulate based on where the electrode is located.

# ChatGPT 3.5 Summary Part 14 (the 14th section of 400 or so double spaced lines)

The conversation revolves around the future of brain stimulation technology. The use of ultrasound to stimulate neurons is suggested as an alternative to electrode stimulation. The idea of growing a neural mesh within the brain using engineered cells is presented as the "holy grail" of brain stimulation technology. The conversation also touches on the use of microwaves, magnetic fields, and electrical fields to stimulate the brain, which is already being developed by some companies. The potential benefits and limitations of using VR to stimulate the brain through the eyes are discussed, and the idea of stimulating the spinal column for higher precision control is presented. Finally, the possibility of twins who are born with their brains physically connected being able to see through each other's eyes is mentioned.

# ChatGPT 3.5 Key Points Part 14 (the 14th section of 400 or so double spaced lines)

Computer modeling suggests that ultrasound might be a better tool than electrodes to stimulate specific neurons in the brain.

The ideal solution would be to grow a neural mesh that can be injected into the brain and function as a secondary neural network.

There are several potential future technologies that could be used for brain imaging and stimulation, including furoxa microwave imaging, stentrode, and electrical impedance tomography combined with deep learning.

Stimulation through the eyes with virtual reality could be a high-bandwidth way to stimulate the brain.

Stimulating the spinal column before the brain could be a better option for high-precision control over signals going in.

Twins born with their brains physically connected via the thalamus could see through each other's eyes, indicating the importance of the thalamus for sensory information.

# ChatGPT 3.5 Summary Part 15 (the 15th section of 300 or so double spaced lines)

The conversation is about the possibility of stimulating the brain to create images. The speakers discuss various theories and techniques, including targeting the brain stem, manipulating microcolumns, using bi-directional recurrent neural networks, and considering the quantum element in neural activity. They also acknowledge the challenges and limitations of simulating the brain and point out that more research is needed to validate and develop these ideas further.

# ChatGPT 3.5 Key Points Part 15 (the 15th section of 300 or so double spaced lines)

There is potential to stimulate the brainstem to create images but more research is needed.

Stimulating micro columns directly to create images hasn't been figured out yet.

Artificial neural networks are abstracted from raw signals and might not have the resolution to control individual pixels.

Bi-directional recurrent neural networks have backlinks going across layers and are used for memory.

Bi-directional recurrent neural networks can receive inputs from every direction and push outputs in every direction.

Biological neural networks are much more complicated than artificial neural networks and can have dendrites communicating with disparate parts of the brain.

Creating a fully functional model of the brain is beyond the computational capacity of computers today.

Individual neurons may operate at the level of individual molecules and could be subject to quantum processes.

Simulating a brain might be missing the quantum element.

# ChatGPT 3.5 Summary Part 16 (the 16th section of 256 or so double spaced lines)

The conversation involves a discussion about the complexity of modeling the brain's short-term and long-term memory and the potential for quantum effects in the brain. The theory of quantum effects in the brain is not widely accepted and some researchers believe it is a mistake. Microtubules are responsible for the structure of the brain and a correlation exists between microtubules and memory, but it is not clear if microtubules store memories. The conversation also touches on the possibility of other dimensions beyond the four dimensions of space and time in our universe.

# ChatGPT 3.5 Key Points Part 16 (the 16th section of 256 or so double spaced lines)

There has been speculation about quantum effects in the brain, with the most well-known research being the Orc Ore theory.

The Orc Ore theory proposes that memory is stored in microtubules with quantum effects.

There is a correlation between memory and microtubules, and new protein synthesis must happen for new long-term memories to form.

Microtubules are responsible for the structural support of the cell, and without them, the cell will collapse, inhibiting new protein synthesis and causing memory issues.

There is a cultural division among neuroscientists about the Orc Ore theory, but it is not a controversial idea.

The gradient of a neuron affects when it will fire, and any quantum effect that changes the ion distribution would affect the neuron's gradient.

Neurons detect information through coincidence patterns.

Lightning happens when the positive and negative charges separate enough that the atmosphere needs to reach equilibrium, and the positive and negative charges are distributed more evenly after the lightning strike.

The ideas of short-term and long-term memory will not change whether or not there are additional quantum effects in the brain.

The study of the brain is very complex, and there are still many things that need to be studied and understood.

The brain is not fully understood, but much research has been conducted in the field of neuroscience.

# ChatGPT 3.5 Summary Part 17 (the 17th section of 300 or so double spaced lines)

The conversation involves a discussion about the complexity of modeling the brain's short-term and long-term memory and the potential for quantum effects in the brain. The theory of quantum effects in the brain is not widely accepted and some researchers believe it is a mistake. Microtubules are responsible for the structure of the brain and a correlation exists between microtubules and memory, but it is not clear if microtubules store memories. The conversation also touches on the possibility of other dimensions beyond the four dimensions of space and time in our universe.

# ChatGPT 3.5 Key Points Part 17 (the 17th section of 300 or so double spaced lines)

The discussion starts with a focus on neural physics and brain waves.

There is a temporary diversion into physics before returning to the main topic.

Grant makes a point about time not being a dimension and recommends visualizing a hypercube.

Jeremy joins the discussion and talks about the challenges of AI development.

Jeremy discusses his idea of grounding patterns in basic objects and senses to mimic child development.

Jeremy talks about the importance of probability and ontology in language development.

There is a discussion about pattern recognition and its role in understanding the world.

The concept of words is discussed as a way to convey ideas and achieve shared understanding.

# ChatGPT 3.5 Summary Part 18 (the 18th section of 300 or so double spaced lines)

The discussion covers the importance of embodiment in language and pattern recognition. Language is humanly developed, and it helps people interact and share experiences. Empathy is taught and inherent, but some people have poor ability to empathize. Mirror neurons were studied, and some people have more or fewer of them, which affects their ability to understand others. However, the validity of these studies is uncertain. Education is crucial for a shared understanding of language, but creativity is needed to build new patterns. Some opinions are grounded in neuroscience, but others are speculative.

# ChatGPT 3.5 Key Points Part 18 (the 18th section of 300 or so double spaced lines)

Language is grounded in basic structures to enable shared meaning.

Children learn through this grounding and the shared experience of sensory perceptions.

Language is necessary for people to interact and live together.

Patterns are emergently learned through embodied cognition and recognition of similar body forms.

Empathy is both inherent and taught in humans.

Different individuals have different abilities to empathize.

Good and bad are basic primitives that underpin language and cognition.

The brain recognizes patterns and maps them out to larger structures.

Education provides a shared understanding of language and structures for future exploration.

The idea of some people having more mirror neurons is not well grounded in neuroscience.

# ChatGPT 3.5 Summary Part 19 (the 19th section of 300 or so double spaced lines)

The conversation covers various topics related to neuroscience and language. The importance of mirror neurons in the brain is discussed, along with genetic tendencies towards certain behaviors like empathy. The concept of language as a tool for communication and cognition is explored, with a focus on the different sensory modalities involved in language processing. The conversation also touches on the idea of how language builds upon itself and how words are grafted onto grounded experiences, making language an essential component of communication.

# ChatGPT 3.5 Key Points Part 19 (the 19th section of 300 or so double spaced lines)

Mirror neurons have been observed in monkeys, but not conclusively in humans. Humans may have a functional version of a mirror neuron, but identifying them is beyond current medical imaging technology.

Genetic predispositions can influence certain behaviors and traits in humans.

Language is not just a tool for communication, but is also a component of cognition. It is a way to represent our internal modalities and to convey complex ideas.

The brain performs mental language in a solo way, calculating a sequence of patterns that are essential components of cognition.

Communication involves more than just language. It also involves sensory input from the environment, spatial and temporal dimensions, and associations with past experiences. Language is just one tool we use to represent these things.

# ChatGPT 3.5 Summary Part 20 (the 20th section of 300 or so double spaced lines)

The discussion started with a topic on brain waves and related topics in neuroscience and deep learning. Later, the conversation moved towards grounded language learning and how it could be a fascinating topic for some. Kyle raised the point that an embodiment component is crucial for machines to understand the world as we do. Our mental models are grounded in our physical form and relation to our environment, and the same is required for machines to accurately feed into our mental models.

# ChatGPT 3.5 Key Points Part 20 (the 20th section of 300 or so double spaced lines) Create a comprehensive list of all key points.

The conversation started with a discussion of neurophysics, brain waves, and brain-computer interfaces.

Embodiment was introduced as a crucial component in language acquisition and understanding, with the argument that our body maps are integral to our cognition and communication.

The concept of language was debated, with some participants arguing that language is just words used for communication, while others argued that language encompasses mental representations, thoughts, and communication through nonverbal means.

The discussion veered into the topic of deep learning and how it relates to brain function and cognition.

One participant introduced the concept of grounded language learning, which involves creating a mental model based on domain-specific knowledge gathered from the internet.

The importance of embodiment in the grounded language learning process was emphasized.

The conversation then shifted to the potential of creating a machine that could interact with humans and engage in conversation using a mental model, similar to how humans interact with each other.

The need for such a machine to have a multidimensional body map and an understanding of the physical environment was highlighted.

There was an acknowledgment of the importance of language in creating mental models, both for humans and machines.

The discussion concluded with a general agreement that the topics discussed were fascinating and required further exploration.

# ChatGPT 3.5 Part 21 (around 300 double spaced lines) Summarize

The conversation revolves around the concept of whether or not an artificial general intelligence (AGI) needs to have a body to function effectively. One person argues that an AGI needs some kind of form to control and experience its environment, while another argues that the brain's core functions are not dependent on identifying with a physical body. They discuss the role of spatial and temporal relationships in cognition, including the creation of memories and mental models of the environment. They also touch on the idea of selflessness and how it relates to cognition. Overall, the conversation explores various perspectives on the relationship between the physical body and cognition, and how this might apply to AGI.

# ChatGPT 3.5 Part 21 (around 300 double spaced lines) Create a comprehensive list of all key points.

The model being discussed is missing from current deep learning research, which only focuses on neural networks without bodies.

The brain's core functions are not dependent on identification with a physical body or location.

However, a medium through which experiences the environment is fundamental to cognition.

Thought needs to have some kind of spatial construct or representation of the environment it is in.

An AGI does not need to have a 3D or 4D world but needs to have a representation of the environment it is in.

The brain's representation of the body is linked with the environment and goes beyond just the homunculus.

Memories form everywhere in the neocortex and do not depend on the homunculus.

An AGI needs to have a representation of the environment it is in to understand the information it has on a fundamental level.

The brain creates patterns with spatial and temporal characteristics that merge sounds, sights, and feelings.

The human conscious experience consists of patterns that have spatial and temporal characteristics.

Removing part of the conscious experience does not eliminate the rest of it.

A selfless cognition is possible, where there is no self or directional concept within a room.

Place cells and grid cells in the internal cortex track the location and orientation of the ego within a room.

The brain merges different modalities, connecting everything one hears to everything one sees.

The rest of the conscious experience remains even without a self; it is just not happening to anyone.

# ChatGPT 3.5 Part 22 (around 300 double spaced lines) Summarize

The conversation covers various topics related to artificial general intelligence and consciousness. The speakers discuss the possibility of AGI without the need for human experiences and the concept of self as a necessary component of AGI. They also talk about the chaos game, a mathematical concept, and cellular automata. The conversation becomes passionate and intense at times, but the speakers try to understand each other's perspectives.

# ChatGPT 3.5 Part 22 (around 300 double spaced lines) Create a comprehensive list of all key points.

The concept of "self" is not necessary for artificial general intelligence (AGI).

The brain forms multi-dimensional representations of objects in our environment, including a representation of self.

A machine with AGI could have multiple bodies and experience multiple environments simultaneously, with a similar representation of self as the brain.

AGI does not need to understand human experiences to be sentient and self-aware.

The amount of sensory information an AGI could process may be vastly greater than human senses, allowing for different experiences.

AGI could empathize with humans similarly to how we empathize with animals, but it would still be difficult to create all the language and experiences that humans have.

AI and consciousness are complex topics that are not fully understood.

The Chaos Game is an interesting topic related to AI and worth checking out.

# ChatGPT 3.5 Part 23 (around 300 double spaced lines) Summarize

The conversation covers various topics related to artificial intelligence (AI), including the structure of the brain and how it relates to AI, the potential for AI to achieve consciousness, the emergence of fractals in math and nature, and the possibility of a utopian future where AI and humans work symbiotically. They also discuss the potential for multiple AI networks to coexist and complement each other, as well as the possibility of an arms race to develop the first self-aware AI. The conversation touches on various books, including "Our Mathematical Universe" by Max Tegmark and "Life 3.0" by Max Tegmark. The group also discusses the potential for modular neural networks to mimic the way humans learn and the need to understand neurology to fully develop AI.

# ChatGPT 3.5 Part 23 (around 300 double spaced lines) Create a comprehensive list of all key points.

Rolling a die halfway in between a point on a triangle and the last point creates an accurate fractal, showing the relationship between math and nature.

Intelligence and thought may emerge from nature's way of calculating, rather than a simple computer program.

Artificial neural networks may not be the way to create AGI, and a cellular automata structure may be more effective.

Our Mathematical Universe by Max Tegmark is a book that explains how mathematics is the foundation of everything.

There are three possibilities for the relationship between humans and AI: enslavement, co-worker, or AI working for humans.

The brain has a unique structure called the thalamus that relays information between different parts of the brain.

Modular neural networks, which link specialized networks together, may be a step towards mimicking the brain's structure.

The idea of building a brain-like structure for AGI may not be the only solution, and an alternative method should be explored.

Alan Turing believed that machines could emulate other machines without understanding neurology.

There may be a way to mimic human learning and development without fully understanding neurology.

# ChatGPT 3.5 Part 24 (around 300 double spaced lines) Summarize

The conversation covers various topics, including deep learning, artificial neural networks, and the future of artificial general intelligence (AGI). There is also discussion about the potential applications of these technologies in answering questions and solving problems. The speakers have different perspectives and approaches to these topics, but they all share a desire to explore and innovate in the field. Overall, the conversation is characterized by a collaborative spirit and a willingness to learn from one another. The recording of the conversation will be made available online for those who are interested in listening.

# ChatGPT 3.5 Part 24 (around 300 double spaced lines) Create a comprehensive list of all key points.

The idea is to create an AGI that can interpret and answer questions asked by humans using algorithms.

AGI would be able to accumulate data, generate questions, and provide answers.

To create AGI, it is important to understand the neurology behind deep learning and computational biology.

People like Yali Kuhn, Jeffy Hinton, and Yashio Bengio are leading the development of deep learning.

Jeff Hawkins aims to build a machine that functions the way the brain does.

The AGI proposed in this discussion aims to be a bridge between Jeff Hawkins and Jeffrey Hinton's approaches.

The AGI proposed aims to create artificial neural architectures that are 3D and have six degrees of interaction.

The focus is on experimental new architectures to expand the understanding of the brain.

The proposed AGI's training process is extremely highly supervised, which is realistic.

The proposed AGI would be trained from childhood to adulthood to understand language in different environments.

The conversation's participants appreciate the patience and stick-to-itiveness to imagine what others might be up to.

The conversation was recorded and will be shared online.

The recording will be shared on Twitter, and people can also message the speaker to get a copy.

There needs to be a group of neuroscientists, deep learning folks, and BCI folks on Clubhouse to discuss AGI.

# Part 1

Okay, let me just invite people.

Okay, let me invite.

Alright, welcome.

Hey Ahmed.

How are you doing?

Good, good. How are you doing?

Good, it's me and you only.

At the moment, I just started it.

I didn't give people a lot of advance notice,

so this is pretty good so far.

Did you see my little note on Insta?

On Insta?

I didn't have it seen it yet,

so let me, maybe I'll look right now, huh?

Maybe I'll look.

Oh yeah, I listened to you,

and I guess yesterday,

I thought it was a really good discussion.

I guess one thing that came to mind,

listening to that conversation,

whether this whole neural link

was potentially just a project within Tesla,

just basically to find a way to find high-fidelity signals

for some cognitive sort of patterns of decision making

for super gnarly edge cases

and L5 driving.

I mean, I listened to that whole conversation

and thought maybe the Tesla group

wanted to really dig deep into that.

Oh yeah, yeah.

So I mean, so the discussion of neural link,

and I think I would refer to it as the,

what I was saying was about how the process of decoding

with neural link is just a new,

we're talking about a new,

we're talking about big data,

like extracting big data from the human brain,

from neurons.

It goes way beyond the Utah array,

or DBS, or EEG, or ECOG,

or any other medical imaging device.

In terms of how much data it's capturing

at the resolution that it's capturing,

and for that purpose,

I'm just going to invite everybody who comes up

to come up and talk.

And so for that purpose,

the potential applications go way beyond,

like so right now, I guess, you know,

it's, neural link is trying to just show

that they can do the same things that other devices can do,

that they can, because by itself,

if you can prove, if they can prove

that their device can do what an ECOG machine can do,

but it's cheaper, and it's mass produced,

well, that's good enough,

it's a good enough value proposition, right?

And it has other benefits over ECOG,

for that specific application of just, you know,

having a person or a monkey just control a cursor

on a computer, or, you know, remote,

or just a remote limb.

So for that purpose alone,

it's going to be worth the money

for these companies to invest in.

But the potential, like, is far greater.

The potential applications are mind expanding,

and then they start to enter into the realm of sci-fi,

in terms of, you know,

maybe we're talking about decoding thoughts

at the, or short term, really, I mean, really,

what I meant to say is really decoding short term memories

at the level of individual neural circuits.

That's, that is more, it's more precise

in saying decoding thoughts, it's,

we're like, yeah, decoding like local neural circuit patterns,

so that we can have basically,

and what that means is that just means

like it's a high resolution of decoding.

So if you have, if you can, with ECOG, you know,

figure out where the monkey intends to use

to move the cursor.

And you can do that, you can do it

with high resolution with new devices.

Well, that means that you can figure out

where the monkey intends to move the cursor

with much more precision.

And also figure out, you know,

what the monkey's intentions are,

whether the monkey intends, you know, a grape or a banana,

and specifically a grape or a banana.

Like which, like what is, that's where,

that's like it's high resolution decoding, right?

So those are my thoughts yesterday.

Thanks for that, yeah, interesting.

Welcome, Abby.

Yeah, welcome, Abby Thad.

Yes, Abby, it's fine.

Thanks, I was very exciting actually,

seeing that how this neural link worked

and I came across the article as well.

I have to read a lot about this brain,

neurons, nerve firings,

and how it controls the motor neurons.

I'm not so sure about,

I know very basic about this.

Maybe I cannot share much about

how neurons function about

and how they connect,

then I control it with the neural link

and how it really helps to understand more

about the CNS and coordination with the NS.

But this I can think,

if I see in my perspective what we are working is,

we wanted to implement some kind of small microchip

in these cardio cells

and those cardio cells we wanted to transmit

some specific protein tags

upon their expression.

But in contrast to what I understood from neural link,

you may correct me,

that they are collecting the electric pulses,

which I slightly differ,

because it's a very close circuit

and so much nerve firings happen at one time

and how they are going to do it.

But reading the last article which came out yesterday,

they successfully implanted in the monkey

and that performs well.

So I'm very curious and I will be reading a lot about it.

But my research domain mostly holds to cardio cells.

So I may not give more insight on this topic.

Thanks, Mika.

So you use EKG to measure cardio cells?

Yes, we have.

Those are very kind of now becoming smaller.

I don't know whether you come up with the small nano chips,

which is nanomaterial, very ultra thin

and they are being tagged with small kind of antibody

and which is upon expression of a specific protein

of one protein, they will emit a signal outside

and it is happening in a cell, in a cellular level.

So we are trying to establish that hypothesis

that we can use it and we can read it,

even if what is the complex network is going on.

But neither I have it, but it is in reading out the electrical pulse.

So we are moving into biochemicals.

So what is the type of cell usually that we are reading

when we do EKG?

Stem cell derived cardio myocytes.

So these are human stem cells derived cardio myocytes.

They are functioning, they are beating

and we wanted to build a small network

and do three proteins together.

We wanted to see which protein triggering another protein

or which pathway is helping or it is simultaneous

or it is, it follow a hierarchy.

We want to see that.

So we are developing that technology, yes.

Okay, and then so would you, is it correct to say

that we can consider that EKG is really like the frequency range

of the cardio myocyte pulsation?

That is like, that is like, you know, partial connect.

We really cannot say that elopsocardiogram

is totally correlated with the cardio myocytes function.

However, it depends on the maturation

and like how the cells are becoming.

But when we make the cardio myocyte from stem cells,

they are actually neorental.

They do actually the signals as I think one or two months

after the conceive, like the baby still in the womb.

So you will see that kind of pattern inside the womb.

It's not even a baby.

When you get a baby, like after the birth,

the beating or the EKG pattern completely changed

and which still we are struggling to get.

Many of the, this big challenge is still in front of us

is like how we can mature the cell and inject into the right place

of a patient, what you call is cell therapy.

That's why it's failing again and again in a lot of, I think,

2019, I guess, in British heart foundation,

they tried to implant a heart patch and same patient,

they derived the cardio myocyte and they wanted to patch it.

They are not success, which I completely understand,

but at least they are tried and we are also trying

how we can mature.

We still see some signature of cancerous genomes

that still they grow as they grow in the stem cells.

So they are not so much safe as well for now,

but eventually I think this barrier will be overcome.

Yeah, thanks.

Sounds good.

So, okay.

Yeah, so this popcorn discussion,

so any questions anyone wants to have

or any topics anyone wants to have,

this is meant to be very casual, happy hour style,

so welcome both of you and a pause.

I can jump off for dinner, but I'll come back later again.

Okay.

# Part 2

And by the way, so if you're down below,

just come on up and talk about anything.

Yeah, I'm just, you know, I don't know,

did you come up with this article today

about the chimeric development, IPS in monkey embryo?

No, no, let me look it up.

Can you tell me what to look up?

Yeah, you can see it as human, like chimeric,

they put a human induced pluripotent stem cells

in monkey embryo and they could able to grow it

up to 20 days and they were growing

and they had to terminate it,

which means it could be growing to something.

And this is a great topic.

I think many people have interest to know

how they are growing stem cells, human stem cells

inside a monkey, monkey blastocyst.

So that's interesting.

And this is actually been a very,

I think I will state is a real success

that if this will be possible,

that this could open a new dimension

of organ development, you know, it's really exciting.

Alright, so I'm looking at,

I think it's the right paper.

Let me just see if there's a date on this paper.

So is it called generation of induced pluripotent stem cells

from adult rhesus monkey fibroblasts?

Correct. Wait, I will tell you.

It is in my Twitter though, I have shared it.

Okay.

This is primary contribution

of human extended pluripotent stem cells

to monkey embryos XBO.

Chimeric, wait, say it again, chimeric what?

Chimeric.

Contribution of human extended pluripotent stem cells

to monkey embryos.

To monkey embryos.

Welcome Jacob.

Hey guys.

Hey.

Unfortunately I can't stick around but I want to.

I would like to keep talking or hear this conversation.

There is one thing that I haven't been able to talk to

on Clubhouse about yet,

or anyone that knows about the acquisition of control labs

and just generally their technology.

I don't want to steer this conversation

because I'm about to head out.

I know a lot about it.

So I was tracking control labs

way before they were bought by Facebook, so.

Yeah, as was I, maybe not as soon as you were,

but I was not surprised by their acquisition

and I was kind of rooting for them.

But yeah, I'd love to chat about it another time.

Sweet.

Yeah.

Did you see the new, so there's a new,

there's news on the topic from OpenBCI.

They have a new, basically like an armband

that is EMG.

Yeah, I saw that there was yesterday

or two days ago, a few days ago.

I just saw it this morning, so.

Oh, good.

I'm not sure when it came out,

but I just saw it this morning.

So I don't know the whole story yet.

Yeah, I think, I forget what company,

not DEXCOM, but some other company has

a EMG IMU node that they sell

like in packages of like 10 or 12.

So having this open source module,

I think it's going to be great for this kind of research.

Yeah, great.

Okay, so there's that.

I'm actually, so I'm sort of like looking that up

to see if I can, if I can find the news.

I don't know why it's not appearing, but.

So we've got, so we've got that.

And we've got stem cells,

scientists generating monkey,

human monkey, turmeric embryos.

Yeah, this is very exciting, you know.

I think why, why I said this is because

it is still very challenging how to develop.

We are sort of organ transplantation, you know,

and not really develop a good tissue even.

We cannot develop a tissue in lab

with current advancement of science.

We can only gather some cells

and they would be clump each other.

Yeah, people are trying to do it a 3D print

where they can build a good network of neurons,

of blood supply and a whole lot of things as a,

as a, as a human.

And we cannot do if this primary construct,

if this kind of primary approach is successful,

then what, what, what is in front of us is

in the same way by guiding the stem cells

to differentiate into a specific organ

or specific kind of cells,

may get a shape inside the, inside the, inside the,

oh, at least.

Just imagine we put some, some,

we put some human induced pluripotent stem cell

in the blastocytes

and we inject that egg to monkey,

to the monkey again.

And to the monkey we give some medication

where the MDO, at the side by side

there will be a treatment for the MDO

and then, then in a very specific manner

the development will occur to, to a specific organ.

The way we do differentiation

or the, the way we do

from stem cells to bones, stem cells to

any, any specific kind of cells in the lab.

So what we are expecting is probably,

probably by doing that

we can able to make, make some organ development.

That's very long term what, what this kind of study

gives us some good hope on that, that ground.

So I'm very curious and I think a lot of labs

are also trying here to do, to that with mice as well.

But mice is, they find the cells after putting the

IPS cells inside the blastocytes, they are dying.

However, this yesterday paper says

the cells were survived up to 20 days

which is really good hope.

Thanks.

Okay, I'll reset the room real quick.

Welcome Frank, Nick and Cecil.

I want to give each of you a chance to speak.

Very shortly.

This is a popcorn style discussion

so you can pick your own topic

and, or ask any question you want.

And, and it's pretty open.

So what, I mean, so so far we,

I just wanted to say we've talked about,

we've talked about stem cells,

we've talked about implanting stem cells into monkeys

and we've also talked about the,

briefly but control labs was mentioned

and then OpenBCI has a new armband.

So go ahead and pause and let everyone who's new speak.

And it goes silent.

No, it's funny.

Yeah, thanks Micah for starting the room.

I don't know if there's any sort of like

topic that you guys are covering like you said

just kind of random anything,

neuro or neuro physics.

Yeah, I don't know.

How about this?

How about something that I'm starting to put a grant

together right now for which is the interaction

between neuro inflammation,

local neuro inflammation within a brain circuit

and drug sensitivity.

What do you got Micah?

All right, why don't you,

I'm really interested.

So neuro inflammation,

would you say again neuro inflammation

with drug sensitivity?

Yeah, so basically neuro inflammation,

let's say priming a rhythmic circuit

to change sensitivity to a subsequent drug application.

Priming a rhythmic circuit.

Did that make sense?

I'm still trying to put the whole sentence together.

So neuro inflammation priming a rhythmic circuit

and for drug sensitivity.

Yeah, so basically like how does it change

the drug sensitivity?

So it's kind of a pie in the sky as of right now

which is why I'm putting the grant together on it.

But the sort of the idea that let's say

you have a patient with,

I don't know, maybe sleep apnea,

or you have a patient with COPD

or some sort of like chronic or exposure to,

let's say hypoxia or hypercapnea

# Part 3

or maybe they have an infection

or maybe you have a cancerous patient

or something like that,

that leads to some sort of known

inducible amount of neuro inflammation.

So it was meaning that you have like an increase

in the amount of measurable neuro-inclamatory molecules

being that either like TNFL by 1 beta

or any of your typical cytokines

that you can measure.

And perhaps on just the side of function

it's not necessarily on a day-to-day function

but it doesn't necessarily change anything

because we certainly have compensatory mechanisms

that will take over in order to keep

the rhythmic circuits normal.

But when you give a secondary insult,

you give drugs or anesthesia or opioids

or anything like this,

suddenly the network may become more susceptible to it.

And I guess we don't necessarily know that as of right now.

So I just think curious because I know

you do a lot of reading on rhythmic circuits

what your thoughts on it are.

So, well my first thought is that

I'm surprised this hasn't been studied in more detail.

You propose something that at once seems

novel and obvious that it's something

that should be studied.

Because you know when you have a part of the body

that's undergoing serious inflammation

the environment is different.

And so you've got a whole bunch

of inflammatory molecules floating around

and maybe you have a cytokine storm.

And then if you then try to like add drugs

like the drug interaction,

the results of the drug interaction,

I think in many cases,

if not most cases, ought to be different.

Not exactly sure.

But I mean this is like a chem lab experiment.

Oh yeah, no, no absolutely.

That's the whole idea is that we know that they're different

but we don't know why.

And so the ground would be more focused

on the mechanisms of why you would sensitize some circuits

or desensitize others if that makes sense.

So let's say you have inflammation

that suddenly up regulates, I don't know,

like a voltage-gated sodium channel expression

or pre-sneptic membrane.

So then you could see that, you know,

for a given action potential coming down a neuron,

you get a greater amount of transmitter release,

something like that.

So we definitely know that there is that synergistic

relationship where you would change the sensitivities

but we don't necessarily know why

for a lot of those things.

Yeah, no, the topic is hugely important.

I mean, I think I oversimplified it

by saying it's a chem lab experiment.

It's a chem lab experiment inside a live biology.

It's crazy, but important.

Yeah, so I'm just, at this moment,

just sort of stringing together possible pilot experiments

to put together some data in order to put the grant together.

But yeah, so there's a topic.

Yeah, I mean, as long as you can,

I think this has to be successful as long as you can

just present it in a way that is super easy

for those, you know, past passing,

approving the grant to get the concept

and the importance of it.

But it's also huge, like sort of a huge undertaking,

I think. Anyone else have thoughts on that?

Nick, sorry, I missed the, I don't know how much of that,

a good chunk probably.

How, I mean, are you going to induce inflammation,

like, systemically with LBS or something,

or are you just going to have your slice and throw,

I don't know, some inflammatory cytokines

or something on there?

I guess you're quite curious about the approach.

Yeah, I think, well, okay, so I think that I'm going to

use environmental exposure to either like intermittent

hypoxia or something to model,

because I usually focus on the respiratory system.

So a model of sleep apnea basically,

but in order to get the mechanisms,

I'm thinking I'm going to have to do LPS,

which is just a lipopolysaccharide,

which is for anyone that doesn't know,

it's a reproducible way to induce a known amount

of inflammation into the system.

So basically you inject that,

and then you get this big inflammatory response.

So I'll probably have to use LPS to get at the mechanisms

and then do some sort of either untargeted mass spec

or proteomics or RNA seek to see which transmitters,

I should say inflammatory molecules are out-regulated

with locally within the circuit,

and then take a healthy slice,

and then apply that on top.

So because there's so much going on with biology,

it's like you have to, for any study,

you're going to have to control for a huge amount

of very possible, like there could be

really different gene expressions

and different proteins being created

in the two different bodies.

I guess if you're doing mice, you have a lot of clones

of mice, so maybe that's easier,

but still there's a lot to control in an environment.

How are you going to isolate the essential data

that is going to allow you to prove one concept or another?

Well, I mean, it's certainly going to be for,

you know, usually the grant's like four years long

and with a decent amount of funding.

So that necessarily isn't going to be a limitation,

but I mean, it is, but in the short term, I guess not really,

but yeah, it's going to have to be, I guess,

to the point where you have to start out

and have some sort of known stressor

that's going to lead to the inflammation.

So first we got to see if that's even true,

which I think a lot of the different studies

like that in the literature are going to already be showing

that because neuro-inflammation is certainly

been a key topic or at least a buzzword,

you know, within the neuroscience field,

but from there, that's going to be the trick,

is to try to figure out the mechanisms.

Like you said, everything is going to be sort of subject dependent,

you know, because you could have the exact same oscillatory output

from some network despite the fact that you have completely

different triangular profiles than I do

or, you know, from mouse to mouse even in red strain.

But I guess what I was curious from, I guess,

from your perspective or anybody else's perspective in the audience

is that, you know, when you take it out to the innovation side of it,

so what do you think would be some sort of outputs

that you would be able to use or measurable tools

that you would be able to use from a noninvasive standpoint

as sort of an endpoint to the grant to say that,

hey, you know what, these are some of the mechanisms that we find.

Now, how are we going to be able to translate that into a more

broadly applicable tool in order to get an understanding

of whether or not this network has changed?

Like either surface electrode type of analysis,

because that much is definitely out of my wheels.

Well, so I, like I said, I'm not the...

I guess what I want to say is while I am not the 30-year,

the person at UCSF who's been doing hard neuroscience

and medical research for 30 years,

I am an enthusiast of the topic.

And what I'm thinking is that if I was going to try to sell

an experiment like this, I would want to say,

okay, well, you know, so the basics of the experiment

is that you want to compare how a drug is affected by inflammation,

just like plain and simple.

But you could do that by...

You could do that and say, okay, we're going to test something

like injecting a mouse with COVID-19

and triggering inflammation and then studying...

We're going to inject a lot of mice with this,

and then we're going to study how the inflammatory response

from the virus affects basically the drug

that we're going to give the mouse.

We're going to see how easy it is to give the mouse anesthesia

and if the COVID-19 interferes with the drug.

And we'll be able to measure that by doing all the different

measurements that people currently do with studying mice with EEG

and watching their behavior when they go to sleep.

And we're just going to study sleeping patterns with...

That's basically sort of like...

It has the components of your experiment,

but it sounds a little bit more exciting because we're comparing

COVID-19 and anesthesia to big things that seem to attract

a lot of money in the world.

And then you can still do your own research underneath it.

That's my thinking. I'll pause there.

Nick, if this is a question my current boss frequently asks,

if everything goes according to plan,

what would the end result show?

Like if everything went swimmingly in the initial experiments,

what would it show?

And then you can kind of design, hopefully design,

your bigger outcome measure from there.

Yeah, I think, you know, as of right now,

# Part 4

the pie in the sky hypothesis,

I guess that would be sort of the main aim of the studies would be

to show that, let's just say it's sleep apnea,

you know, for a reproducible model that we have in the lab,

induces either short or long-term inflammation.

And I don't mean like circulating inflammation.

I mean, inflammation has an increase in the inflammatory set

of kinds locally within the circuit,

which can obviously work as transmitters.

And that alters the expression profiles of the different channels

on the neurons of the glia,

which then primes the circuit to either be more resistant

or more sensitive to subsequent drug application.

And I have a track record of doing studies with opioids.

So it might be, you know, going back to the,

how it changes opioid sensitivity.

But, you know, the thing that would always get caught up with,

and Brandon, you might know this as well,

is that at some point you might get hit with,

okay, now what you're doing is an observatory study.

You're giving the inflammation, you're measuring the circuit,

you're measuring the changes,

and you're measuring the drug sensitivity,

but you're not showing a mechanism that's a serote.

And so that would be the key is that, you know,

trying to sell in a grant that you don't know

what the mechanism is.

So we first have to find the mechanism

and then be able to reproduce it in the absence of,

let's say, the sleep apnea or something like that.

Nick, how hard is it to inject,

I assume pre-botsing or something?

Like is it feasible to stick a fine glass pulled electrode

in there and inject something?

Oh yeah, and we can either do that in a slice

or we can do it live in an in vivo system as well.

That's not hard.

We can either, in an anesthetized prep,

we can actually directly inject right into the pre-bots.

In a slice, we can either locally apply the drug

or we can bath apply the drug or LPS or whatever it is.

And then in vivo, we can chronically implant

microvialysis probes in order to dialyze the drugs

locally within there.

Yeah, I'm curious to wondering if you did,

if you took, once you had like some slice stuff

worked out and decided like, hey, this network's

more susceptible or less susceptible to this perturbation,

you could go in vivo then and deliver either a short

interfering RNA, probably via a viral vector,

or upregulate something that was knocked down

that you think might restore function of the circuit.

I don't know if the functional behavioral outcome

you would look at would be, but I think that would tie nicely

with, yeah, if you had some slice work

and then just modulating it somehow,

yeah, in vivo, knocking down some target or upregulating it.

Oh, that's a good idea.

Yeah, we can always inject the viral vectors

in order to insert something that, say, is downregulated

or knock out something that was upregulated.

That's a good idea.

So, because, you know, I was just going to say

because, yeah, a lot of times, a lot of the studies

and doing have been sort of, we've measured the phenomenon

and then we've gone and measured the neural activity

from a single cell, from a network activity,

and then we've been using, I think I told Micah

about these, those neural pixel probe,

which is basically like a multi-unit electrode array

that can measure like 300% neurons at a time,

so you can kind of get a broad scale understanding

about the network changes function as far as,

like, the phenotype of firing patterns of the neurons.

But again, it still comes back to that same thing,

like, we've innovated in the fact that we now can measure

more than we did before, but you're still just observing

a phenomenon, you know, that's always the tough part

about getting the studies funded.

So, what my thought was that since you can measure

single cells with the electrodes that you're injecting

on the tip of a needle, or basically, right,

that's what you're using, or you can measure

basically the broader activity, like maybe of many cells

and maybe 200 cells at once from that electrode,

maybe from the brainstem or something,

and so you can monitor, even without the application

of drugs, the frequency changes to the oscillation

activity of the brain once, you know,

from a baseline to a baseline without inflammation

to the brain's oscillations being modified by inflammation

and then compare that to the oscillatory changes

when you apply medication versus when you're applying

the oscillatory changes to the brain at baseline

without the inflammation.

Oh, yeah, yeah, definitely.

And I think we're certainly doing our best to do that,

and that hits at sort of defining the phenomenon

as to what's occurring, but the trick always with selling it

is then being able to somehow modify the system

either to restore function or to, you know,

type match what you're seeing without actually

having the perturbation.

Yes, I'm imagining that, so on top of that,

there also has to be a comparison to changes

in the animal's behavior, and yeah,

and like you said, like if you could take away

the functionality or return the functionality

to the animal's behavior, that's another comparison.

Nick, is there any, like, clinical patient data

that would show that sleep apnea or something

has any link to neuroinflammation?

Yeah, I think that data is pretty rich,

and I'm not married to the idea of neuroinflammation,

but how it is right now is that I'm a fellow in the lab,

or postdoc, and I'm at that stage where I need to apply

for K99 or the Transition to Faculty Award,

so you kind of apply for your grants

to get your own projects up and running

and your own lab up and running,

and up until this point, we've been doing a lot of,

sort of, I guess you would call it circuit breaking

type of experiments, figuring out how the respiratory network

is affected by opioids and stuff like that,

and you know, they're very rich studies,

but if you go to apply, and let's say I want to study

some other mechanism of opioid induced respiratory depression,

it's certainly a great study,

but you're then in direct competition with the person

whose lab that you're in already,

which is pretty much a kiss of death,

because you're never going to win there,

because they're already established,

so you need to somehow branch out and spread your wings

and do something completely different,

and so that was the first thing that came to mind,

and like I said, I just started thinking about this,

like, this week, so, you know,

I was just revealing the void for topics in the room,

you know, but yeah, that was the first thing

that came to mind was the inflammation,

but certainly any other mechanisms are on the table as well.

So I wonder, Nick, have you,

so I actually just looked up neuroinflammation

and brought up a possible link between cannabinoids,

or basically maybe like smoking and inflammation in the brain,

and okay, so what I was thinking was,

is it a well, do you think it's like a well-studied topic already

that the idea that inflammation markers in the blood

can basically how they can affect the brain?

Because, you know, we have, you know,

like we were talking yesterday in a group,

and you may have been there for a part of it, or maybe not,

but we were talking about this, the stench road,

which is the device you can insert into the arm,

and, you know, you can put it into the jugular,

and then you can push it up through the vein

into a person's brain above the motor cortex.

And so there is like a direct vein

that goes from your arm into your brain.

And so, I mean, it's like, that is a,

it's like, you know, there's a blood-brain barrier,

and maybe we can talk about that a little bit,

but it's not, it's not leak-proof,

and there's definitely like pathways for stuff

that's in your blood to get into your brain,

and there are, there's also the lymphatic system,

which is also something that,

so if you, like what I'm saying is like,

if a person gets, if a person breathes in,

you know, like the COVID virus, that could,

that could, I guess, somehow get into their lymphatic system

and get into the brain that way,

and get into their blood and get into the brain that way.

And so, and then, of course, both the lymphatic system

and the blood vessel system have endothelial lining,

and the endothelial lining has ACE2 receptors,

which the virus would connect to,

and then the question is, okay,

so if we have this inflammation going on,

how is it affecting the rest of the brain tissue outside

the lymphatic system and the blood vessels?

And is this some, is this something

that's like barely understood?

Is this a new frontier of research?

I think it's a newer frontier of research, I guess.

Sort of, there's some of the studies that are going on

sort of defining how, let's say,

a acute or a chronic state of neuro-inflammation

or, I guess, just systemic inflammation

or any sort of systemic perturbation,

whether it be occlusion or even in the brain like a stroke

and how it affects sort of blood-brain barrier permeability.

# Part 5

And I think there's some of the studies

that are starting to find that like a local occlusion

or stroke within the brain sort of leads to a leaky vessels

surrounding the brain, which then sort of give rise

to a leaky blood-brain barrier.

But I think a lot of those, the mechanisms

as to how it occurs is still being sorted out.

So yeah, it's still somewhat of a newer field.

Yeah, there's some, one of the other students in our lab,

like I own it, the lab that I work in,

he studies alcoholism and its effects on gut microbiome

and then it's tied in systemic inflammation from that

to endoplasmic reticulum stress response

and very specific neurons and the cerebellum

and somewhere in the cortex that I don't remember.

But yeah, I don't think they know exactly

why the systemic inflammation targets those specific neurons

or anything, but as Nick alluded to,

it's kind of a new emerging thing

of how the systemic inflammation may cause

a quote-unquote leaky blood-brain barrier over time.

I was just going to say, the blood-brain barrier itself

is still pretty ill-defined as to what it is,

so it's always a tough one to tackle.

Yeah, there's some astrocytes and parasites

and neurons near them and that's basically it.

It's a little bit confusing because the brain

is full of micro-blood vessels and how is that separate

from the rest of our vascular system?

So they have wrapped around those capillaries

are the enfeeds of the astrocytes, right,

so kind of these glial cells that clean things up,

take care of some neurotransmitter recycling and things.

An act is cells to keep neurons happy,

essentially they have a lot more function than that,

but they're enfeed wrap around and couple with

another set of cells called parasites

and form these tight junctions that limit

what can cross in those areas

and a little more than, let's say, a capillary in a muscle.

Okay, so the blood vessels are wrapped so neatly

that there's very little, there's sealed containers.

It just branched through, of course.

My question is how much of it is an effect of

crossing the blood-brain barrier

because we do have fenestrations in the brain

and actually that's how some parts of the brain

can release a gonadotropins

and can also essentially have reception areas

from this stomach to signify some kind of satiation

or not using ghrelin and leptin.

So is it possible to give some proportion as to

how much of it is crossing the blood-brain barrier

and how much of it is going through the fenestrations?

Sorry, Bess, how much of what is getting across?

I was under the impression that some cytokines

actually cross over into the brain

from other systems in the body.

I could be wrong because I joined in late

and I'm trying to catch up.

But yeah, I guess my question is related to

how much of those cytokines are capable of crossing.

Is there a proportion that we can quite say that

this percentage has the ability to cross the blood-brain barrier

and the other can simply pass through the fenestrations

which are a blood capillary system

that are exposed to the brain matter

or at least the brain itself, if that makes sense.

That's a good angle that I never really thought about.

Most of the things that we'd be inducing

are sort of a systemically based perturbation

at the angle of, let's say, where do the cytokines come

in order to get into the different neural circuits.

That's a good idea.

Sort of looking at, let's say you have some sort of perturbation

that leads to a systemic amount of inflammation

which then could increase the permeability

of the capillaries surrounding the different neural networks

or the neural regions.

So that you don't necessarily have, let's say,

an increase in local release of cytokines

but rather you sort of have a flooding

of the different synaptic spaces, I guess,

with systemically derived inflammatory cytokines

which can then change the function of them.

That's a good idea.

I looked up the Wikipedia article for the blood-brain barrier

just to, because I think it's maybe 10 years

since I looked at it.

And it says the blood-brain barrier, or BBB,

is a highly selective semipermeable border

of endothelial cells that prevents salutes

in circulating blood from nonselectively crossing

into the extracellular fluid of the central nervous system.

And so when I read that, I was like, it's basically endothelial cells.

So what COVID-19 does is it degrades your H2 receptors

and destroys your endothelial cells.

It destroys the tissue.

So the viruses, when they cause these cells to burst,

are destroying those endothelial cells

and just spilling straight into the brain's extracellular fluid.

Yeah, interesting.

And that was good.

This is a good little think tank for putting ideas together.

And I apologize.

I got to jump off.

I got to call at 7 o'clock.

I got to go over some sleepy and EEG data.

But yeah, thanks, guys.

If you're still here around when I'm done, I'll jump back in.

Yeah, I think we'll be here till 12.

Thanks for stopping in.

Thanks, Nick.

Yeah, so it's popcorn style.

We've talked about a lot so far.

But any questions, any topics you want to bring up, go ahead.

Yeah, so I was just listening very carefully.

And not as a just also just a lay person and a very

enthusiastic about this related.

I pick up some of what you said, especially what Nick,

I think Nick has a very good sense of what the grant,

what angle to attack so that to, I mean,

I think it's like navigating through the minds, right?

So where the established don't touch the boundary.

But in general, I was about to ask him a question on an angle

that I think I can somehow relate to.

So where can machine learning can be connected to

what he wants to do, right?

So I guess he left and that's just what I was thinking

in general.

Maybe somewhere he mentioned the priming of drugs,

drugs taking some sort of a database of a candidate of

molecules or something.

Is that one meaningful angle or maybe some other like,

I mean, so I guess this is Mike.

Can you confirm that this is the such discussion is logically

related to our earlier room with sound that the COVID-19

actually affects the brain.

Is that the cell con and inflammatory type of,

you know, affects the secretory rhythm and affects sleep,

for example.

Is that the question of where is your relevant.

So I was tracking most of what you said until the last

sentence and then it sort of fell apart for me.

Could you maybe like rephrase that a little louder and,

like, yeah.

Right.

I was searching.

Yeah.

So, okay, I'll repeat the last part.

So I was asking you to confirm that is the is the current

discussion related to an earlier discussion we had with

sound doctors or that he briefly mentioned the COVID-19

effects of brain of the brain.

So I guess that's just asking you for confirmation.

I don't think Nick was here for that.

And I don't know that, yeah, I don't see a direct connection

to the previous conversation.

I don't know if Brandon wants to talk about how he's seeing

people use machine learning in the context of neuroscience.

Neuroscience.

I can give you a little bit that I know of it,

at least that we've used.

So there's a software called not max track.

I'll have to look it up.

But anyways, it's essentially instead of us manually digitizing

these rodent limbs, whether they are swimming or running

or walking, we can train the neural network to recognize

the limbs automatically for us, which for me saves me,

I mean, weeks and weeks if not months of worth of work of

analyzing rodent behavior manually.

Once we've taught the program to recognize these limbs

and the program after so many passes that we've told

the computer and the program what it's looking at,

we can throw all of our behavioral videos,

provided the cameras are set up similarly,

and get automated quantitation of that rodent behavior

as long as you've trained the program for it,

which is extremely helpful because it saves months of time.

So it's called the mouse move?

Oh, no.

Sorry, I will try and look it up here as we're on here.

No, that's fine.

Thanks.

Sorry.

So other application of machine learning, in fact,

like I think it's pervasively used in signal analysis.

So I would say that you have implants.

So it's not just something related to neural link,

# Part 6

this is done regularly to kind of diagnose the effect of like,

or at least the mutual effecting of different functional groups

in the brain, like whether you have a knockout model,

like that's infused with a retrovirus or something,

but there is always like a study to,

like there's always a mechanism to study the electrophysiology

and vivo and one application of machine learning that I've seen

that's pervasively used is that and spikes, right?

And so suppose that you have, you know, multiple electrodes

or tetraps as they call them because they're very fine structures,

they are embedded within the mouse brain

and it will be incredibly difficult to try to determine,

like, you know, which neuron is firing and what location.

So you can apply different clustering mechanisms

like K-means or mixed-serve Gaussian systems

to essentially cluster your neuron,

like the signals that you're getting so that you can identify

how many neurons are firing.

And you can also apply PCA,

principal depot analysis to reduce the dimensions

because you'll be listening to like the chatter of like lots of neurons.

So there is a possibility of picking up a single neuron firing

from the tetraut or you can have like what they call local field potential,

which is like doing the constellation of neurons or firing

and having or like oscillating the potential

at the position where the electrode or the tetraut is implanted.

So it has wide application when it comes to decoding

or I guess like decoding is highly debated,

contested idea based on our discussion from yesterday,

but if you want to understand like which neurons are firing

or like how many neurons are there that you're picking up

based on your electrode positioning,

machine learning has a lot of input in that regard

if that answers your question.

Yeah, that's a very, thanks for the information.

I think the algorithm you mentioned all sounds familiar.

I mean PCA, that's a basic,

so there may be also all the energy spectrum type of analysis

reduction of dimensionality and unsupervised learning.

Yeah, so that definitely can, I can see that it's applicable to

fMRI of the neuron or EEG data for the signal extraction.

But for me, I mean those black box type of approach

will be definitely be helped, greatly helped

with some physiology and physics of type of reduction as understanding

available, which is already connected to which we already understood.

Yeah, so it's interesting if there's a paper that,

I mean I don't know this direction,

how this direction related to Nick's interest in those inflammatory type of work.

I don't know if Nick was just, I'm sorry, it looks like Brandon was going to say something.

Oh, I just, Frank, I found the software I mentioned, it's called Deep Lab Cut,

and it's actually free to download and everything.

I forget who developed it, but yeah, you just Google Deep Lab Cut and it will come right up.

Thank you.

I was just going to say, I think that Nick randomly threw out a new topic

that was related to a project that he's considering to propose to get funding for,

so it might have been a little bit random,

but it's also something that is in alignment with his interest.

Does that answer your question?

Yeah, I think I'm just trying to connect something that I'm familiar with

with the current discussion.

Yeah, thank you all, I mean it's so fascinating.

So for me, so I mean in terms of general, very general questions,

again, it's a, let me think of a little bit then I'll come back.

So yeah.

Okay, no problem.

So let me go ahead and why don't I just, you know what I would,

so Brandon, I noticed that the profile that you've shared is very interesting.

Would you care to share a little bit about the work that you do and what your interests are?

Sure.

Yeah, so I'm a PhD student at the, and I work in a spinal cord injury research center.

One of the things I really like about where I'm at now is we have a basic science building on one side of the street

where we have all our animal models and in vitro models,

and then literally across the street we have our rehab hospital where physical therapists,

the MDs, the neurosurgeons, clinical researchers all work with spinal cord injury patients.

Rather than kind of your run-of-the-mill approved rehab stuff or for clinical trials or new experimental studies.

So that's really helpful.

My interests really lie within proprio spinal neurons,

so those are neurons that are completely contained within the spinal cord.

They don't project to the brain.

They don't project out to the periphery, to a muscle or anything.

And the reason I think these are interesting is most spinal cord injuries are incomplete injuries,

so some of these axons or the projections of these proprio spinal neurons remain intact,

which leaves you some, I'll say, quote unquote, intact tissue to relay signals past the injury,

either to the brain or descending from the brain or the brain stem down to, let's say,

the control centers in the spinal cord for the legs.

What we don't really understand, which is what I'm working on, is how after these injuries,

even though we have these intact projections, how does the morphology of these neurons change?

How does their connectivity change?

Does that change very quickly? Does it change over time? Does it settle down?

If we do have some neuroplasticity, does that circuit look similar to pathological state

that we might be familiar with, or does that circuit look more pre-injury-like and uninjured

if we provide a pharmacologic intervention or some sort of rehabilitation therapy?

So we're really just trying to unravel what spinal cord injury induced plasticity looks like

in these proprio spinal neurons.

So what's the real biological process happening with neuroplasticity?

I mean, you can take that question, I think, in a number of directions.

So at least related to spinal cord injury, right? Right where the injury is.

You have a capitation that forms, so you have neurons that die, glia that die.

You have blood vessels that are disrupted.

Then that really gets walled off by what we've termed a glial scar.

And you got to think anything that was connected to or connected with those neurons that died in that area.

Now I have to try and reform new connections.

Plus, as we talked about a bit ago, there's this widespread systemic inflammation that also occurs with that.

So we're not talking just about neuroplasticity in the area with neurons trying to connect to new things

or find new pathways to relay information, but also centers very far away from the injury site.

So if we're talking an injury at the bottom of this spinal cord, we'll see changes cortically,

which is as far away as you can get in the central nervous system.

And trying to understand that I think will help guide therapeutic strategies going forward.

I apologize for missing part of that. I got a message from someone that I might be dating.

I don't know and I missed part of it, but I don't know if you covered this.

I want to ask how important is...

So if we could talk about neuroplasticity again, this is something I read about a long time ago.

The idea is that your brain can learn new things and that you're not necessarily stuck with what you learned when you were young.

It's a sort of vague idea, but you brought it to a very specific area of study.

It's not high level book stuff for someone looking for self-improvement.

It's very specific and very medical.

I'm just thinking, okay, well, is a big part of this just having to do with how the brain is able to make new memories?

Is it about the nerve tissues, the environment and whether new protein synthesis is happening?

I guess one topic has been brought up as to whether new neurons are able to replace dead neurons or something.

I'm a little bit vague on the topic and I'm going to try to pay attention this time if you want to respond.

Yeah, all good, man.

I'm a neurobiologist, so I think very medically about these things.

I know if you're running around Clubhouse, you'll find some neuroplasticity rooms quote-unquote that aren't talking about the medical definition or how a medical scientist may think of them.

I guess broadly the way I think about it right is I can have, there's some areas of the brain that are pretty certain can form new neurons.

Let's say you've had a stroke or brain injury or spinal cord injury, there don't seem to be new neurons that just form and fill in that area to fill in the dead to replace those dead neurons.

So really broadly, it is the brain or the spinal cord being able to change itself over time based on a new input that's provided.

So that may be that if I have neuron A and it connected to neuron B before and I learn a new skill, neuron A may now connect to neuron B and to neuron C.

Or maybe neuron A just really solidifies its connection with neuron B when I learn that new skill or new information to form a memory.

Or it could be that neuron A connected to neuron B and C and now when I form that new memory, neuron A doesn't need to be connected to neuron B anymore.

Because that maybe introduces some noise into that memory or that new skill that I've learned.

And I can think of it very broadly like that of the nervous system's ability to change itself over time based on an input or an insult or something.

I think the flip side of that that doesn't get caught a lot is that this plasticity could also be a really bad thing.

So if you think of somebody that has chronic pain, we would call neuropathic pain, so it's induced by the nervous system.

There's not really structural tissue damage anymore.

That's neuroplasticity that's occurred because those nerves are either overactive or they've connected to new neurons.

So there's more, you know, susceptive or pain signals being sent and recognized for some reason.

And while that's neuroplasticity, it's not a good thing at that point.

So the question I have for you, Brandon, is that do spinal cord neurons like those intraconnecting neurons that you just mentioned,

do they exhibit some kind of plasticity the same way as the ones in the cortex,

which is like by producing more receptors and vis-a-vis having like a C-foss expression into some kind of genetic expression.

Do they have like the same kind of mechanism to kind of undergo like a synaptic plasticity much like the cortical neurons?

So this is kind of a crux of spinal cord research, I suppose, is for whatever reason it is not as far along as,

let's say, cortical circuitry or like sensory systems in neuroscience, so if you're studying vision or taste or smell or something like that.

You would assume, because they are still neurons in the central nervous system, they have some similar properties.

Like we know the neurotransmitter phenotypes are very similar, depending on where you're looking.

They come from similar embryonic tissue, which would again imply that they have some similar characteristics one another.

They are still definitely able to change, we do know that.

I just don't know that for various populations, anybody has nailed down the exact mechanism.

I imagine it's still AMPA, an MBA-dependent calcium influx at those synapses,

but again for whatever reason the spinal cord field just hasn't moved as quickly as cortical circuits or sensory systems.

So I guess the AMPA and MDMA receptors would be changing the fastest,

whether they're going to be accepting signals from one neuron or another or not.

I guess they could be blocked with the calcium or something, or they could be open, maybe you can expand.

So that's like, you know, there's a lot of change happening at the receptor level really fast and short term,

and then the longer term memory might have more to do with whether there actually is an actual synaptic connection

between the dendrite and another cell, is that right?

Mike, I think you got the gist of it.

Yeah, so this, an MBA AMPA receptor is calcium dependent, right?

So anytime a neuron starts to spike or send an action potential, there has to be calcium influx,

which is a good thing, it helps the neuron get to its potential and fire.

And the more that it fires and the post-aptox cell responds, you get long term potentiation,

which is those neurons starting to solidify their connection together more and more.

I think that was most of it.

Okay, and so I'm just feeling like the whole, like, you know, back when this whole movement,

this positive psychology movement around neuroplasticity started, there was this huge emphasis on,

oh, your brain can make new neurons, and in retrospect, I'm like, why is that important?

I don't know.

So if I remember correctly from, oh my gosh, and classes four or five years ago now,

they, like, you are in adolescence or maybe even at birth, you have the most number of neurons

that you will ever have, and then it is essentially a topogen and other cellular death mechanisms

that will start to get rid of neurons that you don't need anymore.

And hopefully that doesn't happen too fast, because then you have Alzheimer's or some other neuro-generative disease.

And also, Steve.

So on the YouTube, there's this pruning video that I think the age is four,

which is the highest point, the turning point, and the pruning happens until 18 or something,

and it's stabilized into our dogs, like brain, yeah, just a side data.

Yeah, so synaptic pruning is more rampant, like, and like kids that are like less than age four,

because like their brains, I mean, the neurons are like really highly connected,

and they don't actually go through the pruning process much later.

And in fact, like if I'm not mistaken, the brain actually goes through some changes until like the age of 25,

but it's not like from synaptic pruning perspective, but it just keeps on changing, I guess.

And I guess like to some point to what you just mentioned, Micah,

is that there are some studies that seem to suggest that there are people in stem cells

in the hippocampus, if not the cortical area, but in the interior part of the brain,

there seem to be like stem cells that can replenish dying cells, especially in the hippocampus,

but I don't know if that really correlates to like generalizing that for the brain,

because we already know that cortical neurons are irreplaceable.

And the fact that stroke patients can revive is because of their actually using their cognitive reserve,

so which means that other neurons are kind of being repurposed into fulfilling the tasks that,

# Part 7

you know, the neurons that actually died out were able to do.

So just wanted to put it out there. Thank you.

Great on. So I guess I'll share it since I'm going to record and publish this,

so I'll share some of my ideas.

So I think that...

So I'm going with the hypothesis that a bit of information in the brain is a coincidence pattern,

you know, because there's the book The Neurobasis of Free Will by Peter TSC.

Basically, he says basically a neurons detect information as a coincidence pattern.

And he doesn't spell it out exactly, but I think that, yeah, like a bit of information.

So like a coincidence pattern is like if you can...

If we're thinking about an artificial neural network at the first layer of the artificial neural network,

that first layer is going to detect lines and edges, just basic stuff,

and then another layer is going to detect higher level features.

It's a hierarchical model of learning.

And then so the idea is that information for the brain at the lowest possible bit rate

is just like a coincidence pattern.

It's to have two things, two neurons, at least two neurons within a certain frequency range

and a certain spatial parameter firing at a lower level or maybe at the input level.

And that coincidence pattern is a bit of information in the brain.

Our brains are basically processing bits of information.

So that's the first idea.

I'll go ahead and pause there and see if anyone wants to reflect.

Like I don't have much to add.

I've just never thought of it in that way, so I'll just sit with that, but I like this idea.

And then the next idea I wanted to share was that...

So there was a paper that came out where they were saying that there's a new hypothesis for...

It's sort of like they demonstrated a new hypothesis.

It's kind of an old hypothesis for short-term memory.

So the old hypothesis for short-term memory is like...

So if you need a short-term memory, it's like if you need to remember a phone number that lasts for 10 seconds.

But if you stimulate a neuron, it's going to...

Maybe it fires and it's...

I guess between 2 and 5 seconds is when it's going to fire and by the time it's ready,

then it has to go through... Maybe I can ask Brandon to maybe add some clarity to this.

But after it goes through this firing process, it has to go through an inhibited state for a little while and then it resets.

Then I guess it's like after 10 milliseconds, it's ready to go again, something like that.

But that's not long enough for a long-term...

Sorry, it's not long enough for a short-term memory. 10 milliseconds is not 10 seconds.

It's not close.

So for our brains to remember something for 10 seconds or longer, like a phone number,

the idea is that neurons would have to talk to other neurons to keep that pattern going.

Like one neuron would say, okay, I'm going to say what the pattern is for 10 milliseconds,

and then I'm going to say it to you, and the other neuron has to say, okay, I'm going to say it back to you,

and maybe you have a neural circuit that basically repeats the same pattern over and over,

so that pattern can persist for 10 seconds.

And that's the sort of hypothesis, the old hypothesis, and it seems to be...

I need to find that paper so I can share it with you folks, but what short-term memory is...

I'll just pause right there and give a chance for people to reflect.

I think experimental-wise it seems to be tangible, right?

So there should be circuitry that I'd invite, just have a signature 10 seconds time.

I mean, temporal characteristics, huh?

I guess I'm asking a question. Is there experimental proof, hurry?

Sorry, Frank, can you say the question again? Sorry.

I was just suggesting that the theory Micah mentioned that seems to be quite the...

I mean, experimental can be easily verified, right?

So just identify patterns that identify circuitry that has a typical time, like 10 seconds to look for.

I was asking that, has people look into that already? Has early data available?

This is something that I study here that I really look for.

So one of the harder things, at least right now technologically, is to record from ensembles of neurons

in very different areas of the nervous system, right?

So the way that Nick who is on here does it is if you take a brain slice or a brain stem slice,

you can record from neurons that are within that slice that's, I don't know, probably 10 millimeters thick or something.

Right, but that doesn't mean that you can record from...

or stimulate in the cortex and record from these very specific cells that you're interested in the brain stem.

So it's... I think what you're talking about is feasible, but for these bigger, longer circuits,

especially when you're talking about memory, right, where you have to go...

I don't research memory, but hypothalamus of some sort, cortex, and probably a number of different areas.

And there has to be integration of all that across both sides of the brain.

It's hard to do that study perfectly, at least right now.

But you could have, again, a slice or some number of neurons in these microfluidic chambers

and connect them together and work it that way.

But for these big, large behavioral memory circuits, it's a little harder.

You just kind of have to extrapolate at this point from those smaller preparations.

So I thought it was really interesting in the book by Jeff Hawking's called...

I don't know if anyone here has read it. His new book is called...

Does anyone know the name of his book? New book? I'm blanking on the name.

Let me type it in the computer real quick. Jeff Hawking's brain on...

A thousand brains?

A thousand brains, yeah.

So what Jeff Hawking's is suggesting is that your neurocolumns are organizing your brain activity in a multimodal way.

So if you're looking at your phone, one or more neurocolumns would be managing the concept of the phone

at a high level and integrating all the different modalities of the phone, including its distance from your head,

its distance from your hand, if your hand is on the phone, where your fingers are.

And it kind of has to be that way because if you're sliding your finger along the phone on different sides of it,

your brain is predicting what you might touch, what it might feel like,

and if there was a bump, you would notice it immediately because your brain is predicting that.

And I guess a prediction for a neuron could be like...

It might be something like the dendrite firing in a forward direction towards the axon body,

towards the soma, sort of to prepare the neuron for the action potential to fire.

And so that is sort of what I've heard is like a neuron predicting that it's going to fire or getting ready to fire.

And so that prediction, the fact that your brain is predicting what your fingers might feel is like saying,

okay, well, the neurons in your somatosensory cortex perhaps are getting ready to fire

and the neurons in your visual cortex are getting ready to fire.

And all the modalities, like your audio cortex and your thoughts about the phone,

and they're all being sort of integrated and managed maybe by one or more neural columns that are sort of...

Maybe many neural columns at the same time, but maybe all these neural columns at the same time are sort of creating similar models

about what's happening, about what you're focusing on.

And then there's sort of like a process of neuronal deduction where the neurons are voting on

what is the most likely situation that's happening,

what's the most likely to be the correct model or prediction of the reality of what's happening with all your senses.

But this is something like so a neural column is many layers of like a microcluster of neural circuits in a way.

I'm going to just pause.

Mike, I haven't heard a few of those terms before, but there's a similar thought process in motor control and motor learning where,

let's say the cortex, but there's a lot of things that control locomotion and motor output,

we'll say that the cortex decides, hey, I don't know, let's say throw this baseball,

and it sends a copy of that command down to the spinal cord to get out to the muscles and the arm and the trunk to coordinate everything.

But at the same time, a copy of that command is sent, I believe, to the cerebellum,

and then once you have feedback from how that baseball throw felt, what the outcome was of your baseball pitch,

the outcome is compared to that efference copy so that you can make adjustments hopefully over time to that motor outcome.

So it seems like a similar paradigm at least for whether it's memory formation or whichever paradigm you just mentioned in the book.

So the Hawking's paradigm for 1000 Brains is the, he calls it reference frames.

So reference frames is an idea that's similar to understanding the relationship between place cells and grid cells in the enterino cortex.

Do you know about that one?

I do not.

Okay, well, so I guess I will try to describe it.

Not being an expert on the topic, but I think that, so the basic idea of place cells for the whole group is,

and I hope I don't mess this up, but I might mess it up.

So a mouse can move into different rooms, and in the case of an experiment, some of the rooms might shock the mouse.

There might be an electric zap, and some of the rooms might be very pleasant.

The mice might find food in some of the rooms, and the mice can tell which room that it's in.

But not only that, the mouse can tell where it is in the room, and so if you're sticking electrodes into the mouse's brain,

the mouse can tell if it's on the, for example, I think you're going to have place cells basically refer to the neurons that are lighting up

that tell the mouse where it is in the room relative to the different walls of the room.

It's what its place is within the room.

And then the grid cells are this hexagonal pattern of cells on a larger scale across the interranial cortex,

and I hope I'm not messing this up really badly, but they basically helped the mouse to know which room it's in.

And so the combination of grid cells and place cells is like, with grid cells you have a reference for what room you're in,

and with place cells you have a reference for where you are in the room, and what your orientation is.

And I guess it's thought that there's a similar concept happening where, so the reference frame is which grid you're in,

and that's the frame, and then from that reference you can figure out also which room you're in and which part of that room you're in with the place cells.

And so there's a relationship dynamic, and it's sort of like the grid cells are going to be very slowly changing and very stable,

and the place cells are more like shorter term information, they're going to change very fast,

and they're going to, because the mouse is constantly moving within one room.

And so what they're hoping to prove right now is that there actually are either grid cells and place cells throughout the neocortex

or the functional equivalence of place cells and grid cells.

And it kind of looks like there might actually be grid cells and place cells everywhere in the neocortex,

but I guess it's still an area of research, a new area of research.

But the idea there is that all the thoughts then are basically, like all of our thoughts are basically,

I think it's a common story we've heard that the brands are for movement, highly coordinated movement specifically,

like planned movement, and it's not just like I need to face where the sun is, that's what a tree does, I need to face the sun,

it's like I need to walk across an environment and away from the other animals and towards the food,

it's a really complicated, highly coordinated movement.

And so that's what brains are for, but the idea is that maybe every single part of the brain is literally for a movement

and maybe every single thought we have is a movement involving motor neurons.

So at some point we had the brain, there was a motor cortex, everyone knows there's a strip, it's a motor cortex, right?

And then at some point people were like, okay well actually we have a layer, we have a layer that's the motor layer,

and that goes everywhere in the brain, it's the fifth layer of the brain.

So we had the motor cortex and it was supposed to be one strip, and then we have the motor layer,

which is the entire fifth layer of the brain, and now it's like well, we'll shoot, like every thought is basically a movement in one sense.

That's where it's going. Let me pause for a second.

Yeah, that seems to be a very interesting thing because I was under the impression,

I actually reviewed one of the papers that actually showed that there are cell cells in the brain,

and it was published like 14 years ago, but they actually located those cells in the hippocampus,

most specifically like the CA1 at the hippocampus,

and it will be very interesting to see the place cells are kind of ramping all over the cortex.

Yeah, there will be something that I'll be very interested in.

So a lot of things have been discovered about the hippocampus,

that people have wondered if that is applied to the neocortex,

and so we talked about place cells, we talked about grid cells, but another thing is vesicles.

So in the hippocampus, it's been shown since a long time

that a neuron has multiple vesicles, and there's this thing called multi-vesicle release.

It looks like Abyss, you were going to say something on that topic, go ahead.

No, I was applauding because the multiple vesicle release,

I think it has something to do with the presynaptic, post-synaptic strength relationship,

because it strengthens the relationship, because it essentially releases vesicles to induce post-synaptic potential,

or inhibition, for that matter.

Would you say that one more time? This is important to me.

Oh, so I always under the impression that the vesicles are,

so when you talk about vesicles, I guess I'm probably correct me on this,

but my understanding is that the vesicles are sort of like the lipid bilayer bubbles

that contain neurotransmitters that will be released to the post-synaptic cells.

So whether they can induce post-synaptic potential or inhibition that's up to the neurotransmitter,

because if you have dopaminergic vesicles, they'll probably induce post-synaptic potential.

If you have GABAergic neurotransmitters inside the vesicle, they can inhibit post-synaptics.

But I guess when you said something about multiple vesicle systems,

I was trying to differentiate whether it's a new thing,

because this vesicle or release of neurotransmitters is a well-documented case, or is it any different?

So here's a really interesting thing.

It's well-documented in the human hippocampus, but it hasn't been well-documented in the neocortex,

and it's been sort of an unknown.

But recently I wrote an article that was about research that had been done

that essentially proves that basically we have between,

throughout the neocortex, neurons have on average like 2.5 vesicles per neuron,

or between 0 and 3 vesicles per neuron.

And that's important because what the multi-vesicle release means,

and so your description of it being sort of like a lipid bubble of neurotransmitters is my understanding as well.

I wish I knew more about how different kinds of...

So my understanding is that you basically would have cells that are going to just regularly release a certain kind of neurotransmitter,

and I'm sort of interested in how often the neurotransmitter that cells release can change.

Can you have an acetylcholine neuron change spontaneously to be a glutamagenic neuron?

Brandy, do you know the answer?

# Part 8

Yeah, so there's a little distinction here.

So I haven't seen, and most of my work is in the spinal cord with motor circuits,

but you don't typically think of neurons changing their transmitter phenotype, right?

You don't think of them as changing from releasing GABA or being gabinergic to being glutamatergic and releasing glutamate.

But what can change, and this is, again, with pathologic states,

is you may get transporters that change, which will affect the concentration gradients of various ions inside and outside of the cell.

And if you've flipped those concentration gradients, then there's a chance that, depending on how much it's flipped,

let's say that GABA bound and chloride to release from the cell.

Somebody can correct me on that or Google it real quick.

Let's say that your neurotransmitter bound and before it caused calcium to release from the cell, so it made the cell more positive, right?

Because you had a negative chloride ion flowing out of the cell.

But in this pathologic state, the concentration gradient is flipped because the transporter that normally keeps chloride in the cell the opposite way

now allows chloride to flow into the cell when that neuron is depolarized,

so that now rather than a negative chloride flowing out of the cell when that channel is depolarized,

it flows into the cell and actually makes the cell more negative.

So I haven't seen or heard of transmitter phenotype changing,

but what that transmitter does in some pathological states can change the flow of ions,

which may change whether that transmitter is inhibitory or excitatory.

Wow.

That's a pause.

Can I go ahead to this?

Yeah, I have sort of like a loaded question for Brandon because I have to leave in a few minutes,

but I can repeat the questions if you have trouble remembering them.

The first question is that do you see standard expires in the spinal cord neurons,

much like the cortical neurons?

Second is that do you do like organoid kind of study to kind of see if there is an innate ability of spinal cord neurons to repair themselves

if there is like a severing in the axon or if there is like any kind of damage that you use like organoid models to study such responses like neurons can go through the repair system.

My last question is that if there are gendered expires, I don't know if you heard about the, what was it like a recent publication that said that

layer two and layer three pyramidal cells in the cortex can do dendritic computation.

So how much of it do you think would it apply to the spinal cord neurons?

So these are like three of my questions.

Yeah, those are fun questions.

So they definitely have dendritic spines, right?

If we label proprio spinal neurons that I work on, you have a label that will fill the cell well enough, you have the right microscope,

you can zoom in and quantify the number of dendritic spines and the shape of those spines and decide how mature or immature those spines are and how many of them there are.

The organoids, I don't think there's anybody actually here that does organoids.

I know that's kind of a developing area.

We can talk more about organoids later on.

And then Abyss, what was the last question?

It was about dendritic computation, much like the pyramidal cells.

I was asking if that applies or if you think that applies to the spinal cord neuron.

Yeah, I'd have to see what they mean by dendritic computation, but inevitably if, again, they're still neurons,

even though there's a little bit of difference between the brain and the spinal cord,

at some level there's computation occurring, whether it's in the dendritic spines.

I don't know, but for dendritic computation of all the inputs that it's receiving is a variety of inhibitory and excitatory,

and then decide if it has enough excitatory input relative to the inhibitory input to fire to send its signal wherever that may go with the correct timing.

There's computation that has to occur in each of those neurons somewhere, whether it's at the dendritic spines or not.

I don't have a direct answer.

Yeah, that actually, I'll be really interested if that's kind of ubiquitous in the central nervous system.

But yeah, this has been a great discussion, guys.

I'm going to have to leave now, but thanks for having me.

Sure. Well, next time you come, I do have a lot of thoughts on dendritic computation, so we can talk more about that next time.

Thanks, Davies.

Hi, Brendan. I have just, like, found this by Google that regarding the earlier discussion, the short-term memory,

it came out like March, just last March. The title of the paper is Targeted Photo Stimulation on Covers Circular Motifs Supporting Short-Term Memory.

So I just browsing through, I saw the technique they use is a two-fold-down imaging and post-stimulation on mice.

They identify some kind of a surgery that carries time less than 10 seconds, I think. So when you have time and your comments will be welcomed.

So for me, I might not mention that I have this, like, why I'm interested as a general interest hobbyist, because I'm losing my sleep.

The maximum I can have is, like, very accurately, I can only sleep like four hours, very accurately, no matter what time I go to bed.

Even right now, I feel like I'm, you know, losing my, I can, that's my memories, short-term or long-term.

But it's certainly interesting to find the questions. I mean, I think if you can verify that, Brendan,

but they actually maybe find the right experimental apparatus to address the question that is important, the question.

Yeah, Frank, I haven't seen the paper, so I can't comment directly, but I presume, based on the title,

they probably used some type of optogenetics and drove using a specific wavelength of light, whichever neurons they were interested in,

and then had some type of calcium imaging, which would tell you in another area if the neurons downstream of your neurons are firing as a result of driving your neurons to fire,

or maybe inhibiting your neurons. But I'd have to look at the paper a little more.

What was the title of it again, Frank? Sorry.

Yeah, so it's available on the BioArchive.

So the first name of the author is D-A-I-E, D-A-I-E, the last name of the first order, and the title of the paper is Targeted Photostimulation Uncovers Circuit Motifs Supporting Short-term Memory.

That came out of the Genelia Research Lab's Stanford.

That is, in fact, what I was referring to earlier today. That's what I was talking about.

Yeah, good. That's a good sign. So, Michael, you are familiar with the work?

I've read this paper, yeah. That's what I was referring to when I said short-term memory appears to be basically activity in neural circuits.

It's the idea that one neuron's activity might last for 10 milliseconds, but if you could have one neuron repeat the same message to another neuron,

then the other neuron repeat the same message to another neuron, and that can continue for 10 seconds.

And that neural circuit would be responsible for short-term memory.

That's super important, though, in terms of if we're able to get really super high resolution, not only high resolution, but also just getting a ton of data from a neural circuit.

The idea is that a neural circuit is where we might find our thoughts, basically, in the firing pattern of a neural circuit.

So that's interesting for the future of brain-computer interface research.

Yeah, great. This is extremely interesting. I learned a ton, and I really appreciate the experts here, Brandon, Mike, and Nick.

Michael, are you going to scheduleI mean, is your room like a fixed schedule, orI saw this one, like, in hallway, when you schedule it.

So what I'm consideringI haven't decided yet how often I want to do this, but I want to do this very often, and I'm thinking if I can have a happy hour discussion just open for anyone to talk on these topics.

I would love it if this topic was always happening on Clubhouse, and I could just come in or out whenever and just join this discussion.

But what I've noticed is that there is not literally someone hosting a neurophysics and nerve-gear type discussion every single day in Clubhouse.

I'm surprised, because that's the only thing I look for, and I hope to see it every day, but I haven't been, so I'm like, okay, well, maybe I should just do it every day.

But only as long as I can do my work while at the same time. So if I can do my work and just sort of have this happy hour discussion happening in the background, then it works out.

And then maybe I'll do it every day, but I haven't committed to that yet, but I think it's going to be often.

One quick suggestion, it's all sounds great. I would love to attend your happy hour discussion and just listening, I guess.

One quick suggestion that you can make. I see you're also in the neuro surgery, and there's multiple, many, even Showns and your nation clubs, right?

There are already subscribers, followers. I mean, in case it's not what you wanted, if you have more people attending, you can just post to those rooms as well.

So there will be, I mean, of course, the small room has the advantage of a more deep dive, right? So it's up to you.

So what I've noticed so far, so I'm a member of a lot of clubs, and it gives me the option to, you know, there's some huge clubs.

And so I could start groups under those clubs, and that notifies a huge number of people.

But it doesn't let people who are not in those clubs see my event, unless I'm an admin of those clubs.

And if I'm not an admin, then I'm, yeah, so it's like, then the people in the hallway who are not inside a club don't see it.

And I don't know what to do about that yet. I'm just, you know, it's like, you know, a club gives me access to a large group of people, but restricts me from the general population.

So I'm confused about why it's that way.

I'm just, I haven't started a room yet.

Can you, like, start within a club with a few experts, then open as people come in and open it up to all?

I think that's the option available, right?

So what I'm saying is that if I start a room in someone else's club, and I'm not the admin of that club, then the only people I can invite are people who are already members of that club.

And they only get a notification at the beginning.

And that might be enough to start a conversation that has, you know, 200 people in it.

And maybe I have to do that.

But that means also that people who are not members of that club already won't discover this conversation.

And so for that reason, I haven't gone that route yet.

I haven't sort of, yeah, confined myself to someone else's club just yet for that, basically for that reason.

I see, yeah.

Frank, thanks for making me aware of this paper. I'll have to dig into it a little bit over the weekend.

Alright, cool.

So, yeah, so the paper, you can read the whole thing if you, so they published it twice.

So you can download the PDF if you go into BioRXIV.

But if you go to, if you see the paper on there, they're going to want to charge you money.

So it just depends. I mean, I guess some people have access, some people have, like, you know, your company or your university will pay for it.

But it's also available for free. That was my point.

Yeah, if you ever have issues getting two papers for anybody, there is a website called Scihub that is all for open science.

It's, I believe, SCI-HUB. And I think it's.tw now.

But it gives you access to most papers that you may not have access to if you're not at a university or something.

Right, yeah.

So, Shanka, how did you get interested in neuroscience and all of the like?

Well, I mean, like, like, like, like many kids that grew up in the 1980s, I watched movies.

I'm just kidding. You know, the fan of science fiction movies, robots that, like, number five is alive. Do you know that reference?

Number five is alive. The Sentient Robot.

You're lost on me. I'm sorry.

That's a movie called Short Circuit. And Short Circuit, too, is a Disney movie about a robot that became Sentient.

Really cool movie. If you liked movies about Sentient robots that are really cool and the kids have to protect the Sentient Robot friend from being captured by the military.

That's what I remember, but it was funny.

So then, like, when I was an adult, I read this book called On Intelligence by Jeff Hawking, and that really changed my life.

And because then I had this idea about how the neocortex could, how we could create an artificial neocortex, thanks to Jeff Hawking's book.

And he just really has a really great way of explaining some concepts.

And it's not that his book is 100% original, I wouldn't say that.

But if you didn't understand neural networking before Jeff Hawking's, then you would definitely understand it after Jeff Hawking's.

But he makes some important differences.

You know, deep learning is not computational neuroscience. It is the airplane of intelligence.

It's not trying to, you know, like, so before the Wright Brothers, there was this airplane that was in France that this guy claimed flew.

He claimed his airplane flew, but because he was so secretive, there's no evidence that his airplane flew.

But his airplane had bat wings.

Like, yeah, bat wings, can you imagine?

And so he claims it flew, but we don't really need bat wings for airplanes to fly, right?

It's just flat, fairly flat blades, you know, and the airplane flies just fine, because the principles of flight are different from the specific biological implementation of a flight in birds.

# Part 9

And that's the idea with deep learning, is it's not biologically plausible, because it doesn't need to be.

It's supposed to grab just the principles of intelligence.

But so Jeff Hawking's, though, is, I guess, the culture of being a computational neuroscientist.

And in terms of what the software that he writes, while, you know, similar, is intended to be biologically plausible and biologically consistent to really do intelligence the way that our brains do intelligence.

And so for that reason, he makes writing, basically, studying the brain.

And, you know, I would just have to say that there's nothing, like, the people who, the architects of deep learning, you know, I guess Yanling Kern and Jeffrey Hinton, Yashio Benjio, and others, many other people.

Those are the three big names, but there's many others.

They all read neuroscience. They're not, like, ignoring neuroscience, right?

And they all read Jeff Hawking's book and everything, computational neuroscience.

It's just that they're not trying to be too biologically plausible, but they are trying to study, to look for the principles of intelligence.

And both approaches, I think, are important.

Let me just pause and give someone else a chance.

Well, I'm glad that there are those people that think about these things on a much larger scale than I do, right?

I'm just so used to, I have these 200 little neurons that I study.

I think that there are people that think about these things on a very large scale to kind of push the thought process forward.

Yeah. Let me see if we should probably invite some more people up.

So I just want to, like, make everybody who's listening out just feel, like, you know, totally welcome because this is, like, a happy hour conversation.

We've got some intense topics, but you can really bring up any topic that is semi-related and ask any question.

We've got this amazing neurobiologist here with us, Brandon Brown, and he's a PhD candidate.

And maybe you have a question for Brandon or Frank or myself.

And I'm going to invite people up here and just come on up and talk about anything you want.

Thank you.

And, okay, so welcome to Carl and Dr. Olu.

I'll just mute myself and give each of you a chance to take a turn to speak.

Okay, thank you, Micah. Is it Micah or Micah?

I usually say Micah.

Micah, I really appreciate this room. I am a silent supporter.

So whenever you think that the room is not as full as you might like to think that I'm a big admirer of yours.

So anyway, so I am, I have begun to read this book called On Intelligence.

It's about a guy who states complaining about how there's a lack of operating theories on neuroscience.

And then he talks about why it is probabilistically very difficult for the brain to have come up with different processes

for processing sounds versus vision versus smell and that kind of stuff.

And then he says that maybe there's just one approach which is sort of related to a time series, time series sensory input.

So he even touches time series and so on and so forth.

And then I was listening to, is it Professor King?

I forgot his first name, but he has a room.

And they were talking about when a person or when a mouse is presented with a familiar terrain inside a maze,

there is this type of like a true Hertz or 10 Hertz rhythm that develops in the neural transmission.

And that sounds also like some kind of a time series of like a singing type of thing.

So I'm wondering if there is formation of this type of realization that somehow the brain sings in some sense in the neural transmission space.

That is a telltale sign of how it is processing all kinds of different sensory inputs.

Thank you.

And then, yep, I may have to, so I may have gotten a little lost.

Maybe someone else wants to answer.

You said something about the brain singing.

I definitely would like you to restate that.

But let me pause first to give, maybe other people heard you better and Dr. Olu could respond or someone else.

But I'll just pause for a second.

I'll give time to others to try to answer. I was kind of formulating what I wanted to talk about.

I'll step in after maybe somebody else has a chance to answer Carl's question.

Carl, I don't know about the frequencies you're speaking of.

I'd have to get the paper to have a better answer.

There was one part, and if you can clarify that, it'd be great that you mentioned something about figuring out how senses go together,

how all these senses are coordinated or something like that.

It's a book by Jeff Hopkins, and what it says is that evolutionarily,

it's probably very difficult for the brain to have come up with five different mechanisms for preceding the five different senses.

So then he says maybe just one trick that we're using to process everything, and then he makes a point that the...

And I don't know if this book is scholarly or I just picked it up in a bookstore,

and then he says even touch is actually time series information because if you were to just touch something

and start moving the hand, try to figure out what it is, it's very hard.

It's only by slowly and gently decreasing the surface with your fingertips that you begin to ascertain exactly what type of surface it is.

And then sound is by nature time series.

Even the visual signal, if it's moving, we're much more perceptive about it rather than a stationary image.

So that's as far as I understand so far.

So I read that book a long time ago, and like I said, that was the book that changed my life.

So I understand a lot about that book, but I guess what I didn't understand is what you were saying,

and maybe just restate what you were saying about the brain singing.

Okay, so I think it was the last weekend that there's this neuroscience room.

And I forgot the name of the moderator, his last name is Kim, I believe.

And they were talking about...

And I don't know how they were monitoring it,

but they found out that when the mouse goes to a terrain that is familiar, that the mouse has seen it before,

and the more familiar it was, there was this periodic firing of a certain set of neurons.

So it was not just the memory forming, but it was some kind of a dynamic thing that was happening that reminded me

that there was coins correlated to the mice recognizing something.

That's as far as I remember about this.

Kyle, I think the book that you referred to on intelligence, that was a book by Jeff Hopkins in 2005,

and the other book, The Thousand Brain, it's actually, I think, a newer version.

So I think you might want to be interested to get that one as well.

For the time series, my own take on this, I think it's quite a legitimate projector,

because when it comes to signals, naturally Fourier series has to come into play.

So the evidence is abundance in our brain that our sleep rhythm, like from gamma beta, out of all these delta.

So also earlier discussion that Brian brought up, I mean, very interestingly,

my thought that the short-term memory, that there's a 10 second of time characteristics that I also just head on upon new research

that they use two-fold on imaging and also stimulation to find some experimental evidence supporting that theory of short-term memory.

So to me, is that an evidence towards a similar theory or a projector that I heard earlier on in the clubhouse,

is that our brain is actually different size and levels of circuitry loops, right?

So involved, given that different level of consciousness, whatever it is,

the intuitive way you can define it individually, so within the brain.

Yeah, so maybe I'm just saying that to me, it seems to be legitimate.

And also for earlier interesting topic that Micah, this is maybe for later discussion,

you mentioned the Lightbrother, the airplane, right? So that's, I found that you just mind-boggling the,

that it's some strong evidence that argue against the high fidelity of bio-mimicry.

So it essentially is pointing to a way that we have to understand, I mean, biology,

the solution biology offer might not be the optimal one, right?

So if we understood the physics and the human can come up with even better.

I mean, say a CPU, right? I mean, it has its own clock and also these, anyway, so memory and all these.

So I also, that question also interests me, what the future likes, right?

It's a great discussion so far. Thank you all for that.

Let me just give the floor to Dr. Olio, are you ready with?

Yeah, thanks for bringing me up. Just by way of background, I do work in computational neuroimaging,

particularly with a focus on connectomics at the macro level using different modalities like MRI,

diffusion tensor imaging, fMRI, particularly in the context of psychiatric disorders like mood and anxiety disorders.

And we've done some work using EEG to generate connectomes and specifically looking at dynamic connectivity with EEG data,

especially during a particular task like the emotion regulation task.

And we've done some interesting work showing that if you look at these dynamic connectomes across different subjects,

across different time points, you can use that data to put into a manifold learning algorithm to kind of populate a state space

that represents the different activities that subjects are doing during the task.

And it actually nicely separates out different conditions of the task.

It separates out patients who have anxiety disorders versus controls who don't.

And I was actually interested in your background, Micah, because I saw that you do some work with EEG and VR.

And so one of the things I've been interested in is sort of taking our initial findings into VR to see if we can use

sort of real time data from EEG to feed back into the subject through VR, so basically VR enhanced neural feedback.

And I was wondering, Micah, you've had experience combining EEG and VR and what sort of equipment you've used to do those types of projects.

Thanks.

Awesome. Thank you for the question, Dr. Olu. I'm happy to talk about that.

There are several things to talk about.

So one of the things that I should share is my bio.

So if folks can go to vrma.io and it should open a medium page.

Let me know if that's working for you.

I'm growing there now.

I have to switch screens.

So vrma.io is Victor, Robert, Mary, Adam, Dot, Isaac, Oscar.

Got it.

And so then you click on the first, see I think it's the first link.

It says link to bio.

It says Micah Blumberg is a programmer and a journalist.

And then you're going to scroll down and you're going to see, at some point you're going to see something that says Neurohax or EEG.

Yeah. Oh, yeah. There we go.

So this is going to say a lot about what I worked on and what I did.

So I'll summarize this.

So in 2008, I became the organizer of NeuroTech SF, which is one of the branches of NeuroTech X,

which is a global organization of meetups worldwide with 22 or 23 chapters in major cities across the world.

And so I was doing the San Francisco chapter.

I did it for two years.

And in 2018, every single week, not every week, but almost every single week,

I had people coming into Noisebridge, which is a maker space, also called a hacker space.

They're often in big cities in Hong Kong and Tokyo and Texas and San Francisco.

Maker spaces are hacker spaces.

And people come there to write code or to do all sorts of weird things.

It's often like a wood shop and a metal shop, and you can make anything you want.

People even make fashion designers show up and they make clothes.

So I was hosting a coding meetup, though.

# Part 10

And I was using this technology called Aframe, which is built on top of a framework that makes it easy to build VR applications

and now also augmented reality applications.

It wraps around 3GS, which wraps around WebGL.

And WebGL was invented to bring a canvas for 3D objects and why am I stumbling?

So WebGL was basically 3D technology for the web, just to make it long story short.

Web has HTML, which is documents and documents that are supposed to be 2D.

And they wanted 3D, so WebGL.

But WebGL, unfortunately, is so low level that if you're just going to do one shape, it's like if you just put a triangle on the screen or a pyramid, a tetrahedron, right?

You might have to write 250 lines of code. It's ridiculous.

So 3GS was one of the many, one of the first, I think probably the first high level scripting language that made creating 3D on the web really easy.

And what Aframe added was an entity component system that allowed you to make your code even neater, basically.

And also an entity component system is great for teamwork because it makes it like you don't have to be a ninja to build non-blocking high performing code when you're using an entity component system.

Because the structure of an entity component system does a lot of good code practices for you and your team, basically.

You could have one code ninja and the rest of your team can keep up with you if you're using an entity component system.

And so what we did was we used the brain.

So what I did in the beginning was I brought a bunch of people together and I said, okay, let's bring EEG into VR.

And the reason is because I wanted to do that since I opened a business in San Francisco in 2012.

And I wanted to create an alternative neurofeedback salon where I was using the emotive headset at the time in 2012.

And I was using a program called Neuro Programmer and another program called Mind Workstation and creating custom, basically custom tracks that had isochronic beats.

So there's this guy named Lenox in the 1980s and the Lenox protocol was basically a biofeedback frequency program where he was capturing EEG patterns

and then using them to change light, basically light.

He didn't really have sound at that point.

So he's just changing light effects, like the light would flash with the frequencies of your brain activity.

But he would also encode it with certain frequency ranges, certain frequency patterns as well.

And he reported that his patients had some significant success with their own, in many cases, with their issues.

You can of course read more about Lenox and his protocol.

But he's eventually the man who invented transcranial magnetic stimulation a long time later.

But in the 1980s, being able to do EEG and the kind of thing that he was doing was, I guess his setup was like half a million dollars back then.

But what I was doing was using the EEG to drive light and sound effects to a light and sound machine and the total cost of the equipment that I was using was about a thousand dollars.

But I wanted to do it in VR.

So basically I would have your brain waves driving light and sound effects and they would change what you see in here and they were encoded to isochronic beats.

And they would really cause this intense self-awareness, like almost a meditative state.

And if I changed the frequency patterns that I was encoding, of course, then that would affect the changes in your mental state.

But it was very interesting because I began to feel as if I was listening to... I began to feel as if I was gaining some awareness over how my brain waves were changing the light and sound patterns.

And therefore gaining some awareness over what my brain waves were in an abstract way and not in a very clear way.

But getting a sense of how my thoughts and feelings were sort of changing light and sound patterns.

Like I said, it's very, very weird.

Sorry to interrupt. But did you start feeling some conscious control over your brain waves in terms of now that you had this feedback?

Yeah. One of the weird things was I put a blindfold on one time and just turned off all the lights so I just tried to get as close to zero light in the room as possible.

And I had this visualization, there was no drugs involved, where I turned into something like an ancient Cambodian statue.

But it was made out of fire and the fire was basically different colors based upon seven different colors, like representing the seven different chakras or something.

And I could change the color of the fire consciously and basically that would change the light and sound effects.

But I was sort of seeing in my mind's eye because my visual cortex was freed because I was wearing a blindfold and it was completely dark.

I was visualizing my body as being a fire and I could change light and sound effects by thinking and change my form as this sort of Cambodian-style statue that was made out of fire.

It sounds weird but it was very interesting. And I had a number of other really profound and amazing experiences including one that I would describe as sort of witnessing the beginning of time.

And I love that story but it was, I don't know if I should tell it right now.

So how many channels were you using? So the emotive headset is a 16 or 14, I think it's like 14 channels inside a 16-elector device, 14 good channels.

And of course with EEG, I guess it's really far removed. We're talking about dipole activity at a large scale.

It's not very specific to your neurons firing at the point that we're measuring it with EEG. It's like large scale dipole activity.

It's very abstracted from maybe from what your neural circuits are doing, what your thoughts are doing.

But maybe somehow because what I'm saying is in some sense you can use, it's been proven that you can use EEG localization technology where you're trying to plot where signals coming from before it triggers a dipole.

That can be very accurate. It's been shown with a DBS, there's a study that, maybe Frank wants to look this up and share it with us, but there's a study where they compared the data with DBS and with EEG to see if EEG localization was correct

and it correlated correctly with where the signal was coming from in the thalamus as detected by the deep brain stimulation device.

So even though we are only getting large scale dipole activity, it is with EEG localization we can make predictions about where the information is coming from

and maybe my brain could also sort of decode more information from listening to the changes in light and sound as my thoughts and feelings change.

And it's a really far-right idea and I don't know that, and then the other problems are like all the noise with EEG and sort of like...

Yeah, that's one of the reasons why I was interested in your setup because that's one of the problems that I've heard of when combining like a VR headset with an EEG cap that there is quite a bit of noise interfering with the signal.

Well, in this situation, back in 2012, I had everyone be very, very still, so nobody was moving around because movement obviously is one of the things that causes lots of noise.

And that was just LED glasses, but I did want to do it in a VR. I wanted to re-create it in a VR, and in 2018 I did.

And so what we did in the beginning was I was hosting meetings where I just said, okay, this is what I want to do, let's talk about how we can do it.

And so I led these group meetups and at first we talked about using the OpenBCI headset, which is still a good idea.

We had one, but we needed to create 3D printed parts if we were going to attach it to a Vive headset.

And like I said, I kept running into people who were neuroscientists who were laughing at the project because with VR, as soon as you're moving around in the VR headset, you're making noise and it just doesn't make a lot of sense.

But we kept on, like from the very beginning people were telling us, it's just going to be too much noise, it's not, but we did it anyway.

And so we kept on. So eventually we realized that it was too hard for us to do 3D printing because we didn't have enough knowledge.

I didn't have the knowledge of 3D printing, of how to do it, and our 3D printers, every time we tried, the print would fail.

So around the middle of the year, we eventually, another group of folks bought a brain-duino, EEG device, brain-duino.

And folks can look that up if they want.

Most people have probably never heard of the brain-duino.

But there's been documented on the noisebridge website, so noisebridge.net has a lot of information about the brain-duino.

It's a very obscure device. It's very cheap. It's like the size of an Arduino board.

And I think it was 300 bucks or something.

And it has, like, I think out of the box you can do like between 2 and 4, it can support either 2 or 4 electrodes.

We were doing 2 electrodes. We had actually 3 electrodes, but the middle electrode was just, it was our...

It had another job. For some reason I'm blanking on the right name for it.

Oh gosh, it's...

But anyways, it wasn't bringing us signals. It was just sort of like helping to ground, it was our grounding electrode.

And so anyway, so we had 2 electrodes. We put them on the forehead. The signals were measuring, of course, voltage detected at the surface of the skin.

And then that would create, the brain-duino processing machine would turn that voltage into an array that had hex values to represent that voltage.

And then we converted the hex values into numbers and we brought a...

Basically we created a server. The original server was created in Python.

And the server would take those numbers and we...

It was very easy to basically... I think we ran one line of code and suddenly we had the fast Fourier transform.

It was like ready to go. Thanks to the work of other people.

And so we had the Fourier transform going and we created a local host and then we broadcast the signals over the cases of a web socket.

So we decided on a web socket to send the data to our web page.

And we sent it to the web page because WebExr is usually... Usually you run WebExr on a web page.

You don't actually have to run WebExr on a web page.

But that's just like the first place you would find WebExr as a web page.

And ultimately it's JavaScript and you can run it in a...

You could create a WebExr application with React Native, for example.

React Native with... It's called React 3 Fiber.

And so you don't have to use the web.

So to make long story short, there's lots of discussions.

Because normally if you use a website to fetch information, you're just like fetching one thing at a time, right?

You're not fetching... We needed to stream.

So we needed to stream the numbers that were coming from the EEG device into the website in real time.

And so we did that with a web socket and we brought those numbers into the web page.

And we applied the Fourier transform a second time.

So to this day I'm unclear as to whether applying the Fourier transform the first time actually does anything.

Because we really needed the Fourier transform on the client inside the website itself.

So we did it the second time.

Yeah, I'm a little vague on whether or not applying the Fourier transform the first time meant anything in the end.

But yeah, so I'd like to... I guess maybe I need to go back and...

I'd have to say that... So this is a team effort.

My contribution was mostly on the WebXR side of things.

But also in terms of organizing the group every single week.

And organizing the discussions that allowed us to figure out all the different components of it.

There are certain things that I don't know in terms of our specifics related to the actual construction of the servers.

We went through multiple incarnations of the servers and I did not write those.

And as far as why we needed a Fourier transform in the server and also on the web page, that I don't understand.

But I can answer a lot of questions in terms of the WebXR code.

So the client side code, basically.

So once we were bringing the stream of numbers into the web page through a web socket from the brain to we know, because of our server.

Then the question was, okay, so what are we going to do with these numbers?

We can see them in the console. It's just a stream of numbers.

Okay, so here was one idea. So we can put some shapes on the screen.

We'll generate a bunch of spheres and we'll have the shapes move up and down.

And this is what we did. I think if you look, I think it might be.

Yeah, I think I see the video.

Do you see the one with the spheres?

No, I see the one with the frames and I think you have different frequency bands represented for a stream of frames.

Right, yeah. So that was the later version of the project.

So in the beginning, I guess I didn't link the video with the spheres here.

But oh, actually, maybe I did.

So if you search for, so if you look right above the one of the frames, I think there's a video right above that.

So this video is one of the first results. Let me see if that works.

And that takes you to, it's like a Twitter link, I think.

So I saw a Twitter link where you had it like visualized underwater.

Yeah, yeah. So that visualization underwater is a bunch of spheres.

And that was our initial proof of concept. So that was like the very first version of it.

And that underwater is actually just a really simple 360 sphere.

Just a static image. This is like a 3D wrap around image.

Super simple, but it does make it look like it's underwater, which was fun.

And what you can notice in that video is that there's like, you see this like, there's this like massive slowdown in the frame, right?

Because that is 1000 spheres. It's two, basically, and I don't think it's labeled at that point.

So we had the two electrodes, and each electrode was divided into five different frequency ranges,

left and right, alpha, beta, theta, gamma, delta.

And then we had, not only did they move up and down in sort of a time series, what is a time series?

It's a 3D time series. And so they moved up and down basically.

So each incoming signal, we had assumed numbers coming into the web socket.

And every time we got a new number, we would use the number that we were getting to set the height of the sphere.

# Part 11

And the height would also determine the color of the sphere.

So there's always red on top. There's always blue in the bottom. You see that?

But the program kept choking because this machine that I was running on was a Linux workstation that was extremely underpowered.

And if you tried to run that in VR, it was extremely slow and nauseous.

And so eventually I tried cubes, and then I replaced the cubes with spheres.

And I got labels on it, and in the video that has the planes on it, that video,

if people just arrived at this room, it's at vrma.io, and you can look for a link to my bio.

But that video basically shows that, you know, at that point what I was showing off was that I had this like,

you could press on, that's inside, it was recorded from inside the Oculus.

You know, that was inside the Lenovo Mirage Solo. And if you pressed left or right on the controller,

you could turn left or right, and that's what I'm showing off in the beginning.

And then you could click, you had a laser pointer, so you could click on the bottom of, there's the square on the bottom underneath,

and that would rotate the entire grid, sort of like, so you could see it from another perspective.

And then you could teleport, you could teleport around the environment by pressing on the top,

actually I think it, yeah, pressing on the top of the thumb pad, and that would teleport you around.

And then you could walk over to the side of it and see it from different angles,

and you could, so at this point people were walking inside a representation of their brain activity and noise bridge,

and this was like the coolest thing, and like, nobody, hardly any people ever noticed that we ever did this,

and I think it's never been duplicated, but the code is all on the web for free.

And so I have plans to basically, so because functional and infrared spectroscopy data can also sort of,

can be read out as a time series, you could basically unplug EEG data and plug in fMRI data,

sorry, not fMRI, whoa, whoa, whoa, I meant fNIRs data, fNIRs data, and visualize that as a time series.

Another thing about this is that this was like pre, so there was something that came to WebExR,

basically, like we were matched, this is 200, the ones with planes is 200 different planes,

but at that time that we were matching out our frame rate, because you're trying to hit, with a mobile headset,

you're trying to hit like 60 frames per second, or maybe 72 frames per second,

so that the person using the headset has a comfortable experience.

But there's a new way called mesh-instancing, and with mesh-instancing,

instead of being limited to 200 frames, instead of being limited to 200 objects,

I could have like a million, 1.2 million of these squares and make a really long time series.

And basically, and still run at 90 frames per second, maybe even think about making like a super amazing 3D representation

of your brain activity at 120 frames per second.

But we were, but here's the other thing, is that, you know, we had to cut down the sampling rate,

because the fact is that the amount of data that you can pull from the human brain with EEG is like,

it's just like the sampling, I guess the sampling rate we had with the brain-duino device

was something like 250 samples per second or something like that.

I'm not sure if I'm actually saying the right number, but it was something,

it was some sort of situation where we had to like say,

okay, we're only going to take like one out of every four of those samples, like one fourth the rate,

because our computer can't handle input that much input that fast,

our web page can't handle it, and I think it's less about the web page

and more about the renderer and the GPU that has to do the rendering

on either rendering by the VR headset itself.

So if you're using an Oculus Quest, which is what we'd be using now,

or if you're using a desktop VR headset, which is your desktop GPU,

so if you're using a desktop GPU, you can do a lot more rendering,

and maybe you could do a million planes with a desktop GPU,

with mesh instance scene, with 250 samples of your EEG signals,

with 120 electrodes, or 256 electrodes simultaneously,

but I would really like to do that and to see that.

Yeah, so I don't, but I have no idea if that is going to really,

in terms of like how much we'd be pushing the limits there,

but anyway, so you can get my code.

You can see how that looks good.

Great, thank you very much.

I'm following you now, and so I'll definitely be in touch,

because this is something that we're definitely working on

and we're working towards an actual intervention.

So your knowledge is greatly appreciated,

and I'll definitely be in touch.

Okay, do you want me to give you the code link before you head out?

It's just github.com slash mica, number one.

Great, thank you. I'll check that out.

Okay.

Hey, Micah, there's information over here,

but let me quick, two quick questions that,

so I, you mentioned 3D printing somewhere.

So what do you need?

I didn't get the contact.

What did you need the 3D printing for?

I had some experience with the 3D printing,

so that's why I'm curious.

And also, okay, can you like just quickly,

in a, like, summary.

So you said, there's this emotive like EEG headset

and you use it to do like VR.

I just wanted a short summary with the technology

that you're delivering or in the future.

All right, so I mentioned that I used the emotive headset

in 2012 with LED glasses.

In 2018, I used the Brain Duino device,

which is a different EEG headset, a different EEG device.

It's not, it's not the emotive.

And we, and we, I also have a number of other devices,

like I do have an emo, an open BCI device.

And originally, we tried to use a 3D printer

to attach the emotive sensors to the Vive headset.

And when we failed to do that,

one of my really smart friends says,

why don't you just use tape?

Can I just...

That's usually the case, good.

Yeah, but right around the same time,

we, yeah, the Brain Duino fell into our hands

and we were able to borrow that every week.

So we just used that.

Okay, so since I have just,

like one of the expo that I had to wear this headset,

but for some brain codes,

so their value-adding proposal is that

some attention kind of correction.

So you are using EEG in addition to your hands and others, right?

So to do the brain HCA, human computer interface?

I don't know why.

I wasn't able to sort of like grab your whole sentence.

Could you say it again?

Yeah, so I guess I'm trying to get the better picture

of what is the nature of your technology.

What is the value?

What are you trying to do, right?

So for me, I've had experiences of wearing one of the headset,

like say there's a company called Brain Code

and they are similar composite with our many, right?

So it's all mild.

So they wear this band on the muscle

with a few degree of freedom.

You see, using EMG can control a mouse or something, right?

So without, you basically give a,

your hands will be free to do other things, right?

Just less for me, I mean, I think adding more degree of freedom

for human to control the computer.

It's a human computer interface type of thing.

So for me, I mean, coming from that angle,

I'm trying to understand what your proposal is.

So apparently you're using the EEG

as a digital set of controls

in addition to hands, for example, a mouse, physical mouse,

and say, you integrate that into VR and AR

and is that the dimension?

No, not on, so that was,

so I was not trying to use EEG to enable a control interface

because the, so there's a story,

there's a story I like to say when people say,

were you trying to use EEG to make a new kind of way

to control something?

And there was a whole bunch of devices that came out

before we did this project where they were saying,

well, you can use EEG to control a mouse on a computer

or to float something, you know,

you can have mine to control with EEG

and these devices were cheap and they all sort of,

they were exciting for a little while

and they all sort of faded from public memory,

but I can use.

Like me as, that's right.

And welcome.

Did you want to?

No, no, I'm actually curious because I'm in

Physi-Treat Physical Medicine Rehab,

which basically we use a lot of augmentative assistive devices.

And I've always been curious about the EMG side,

but EEG as well.

So I remember, I think Frank, right?

What was speaking before?

Yeah, yeah.

Yeah, no, I know about the Mayo band that was made by

a lab called Thalamic Labs in Waterloo.

And I was hoping they would work on it,

but I think they sold off the patents to someone else.

They worked on the North glasses.

Now I think Amazon, Google bought them over.

So because that was a great way to connect on to,

with VR, right?

When you're out of VR space,

it was a great way to like navigate using EMG.

But I was just curious to know what the EEG you had.

Sorry, go ahead.

Okay, so the way I saw it,

the problem with EEG was this.

If you are driving a car,

you might have a lot of brain activity

when you're learning to drive a car.

But then as you get,

maybe because your brain is trying a whole bunch of different things.

It doesn't yet know which micro and macro circuit patterns

are going to be the right patterns that will enable you to drive.

So your brain is overthinking and there's a lot of brain activity.

But then when you get really good at driving a car,

it requires a lot less visible brain activity, apparently.

If you're just talking about medical imaging,

the people who are really good at doing something

have less, way less brain activity

than someone who's brand new at trying to learn how to do something.

And I don't know if there are exceptions to that,

but I think that's like, I don't know,

Brandon or anyone else wants to talk on that.

I think anytime you're talking motor output is the end goal.

After you've learned that skill or that set of motor outputs

and know how to string them together,

it's kind of, it's definitely less cortisol input.

And it likely just gets offloaded to motor control brain stem centers

if not the spinal cord on its own.

Okay, yeah, so, right.

# Part 12

So the story of that is like,

if you get really good at controlling the muse headset,

it's so funny.

Then your brain says, okay, well,

you don't need this much brain activity anymore.

I'm just going to create a pattern

and your spine's going to remember this pattern

and now the pattern will come from your spine

when it needs to come or something like that.

But anyway, and the idea here is that

as soon as you get good at controlling the muse,

your brain activity decreases.

And so the reason you were able to control the muse

is because you're creating a certain amount of activity

that the muse was able to recognize,

a certain amplitude of dipole activity, perhaps.

But now that that activity is no longer happening

or is no longer happening at that scale

or no longer happening in that place,

it's not really, the ability for the muse to continue to detect it

is diminished.

So the better you get at using the muse,

the harder it gets to use the muse.

You can see what I'm saying.

And so that paradox is why I was like,

using EEG to control stuff,

no, that's just bad thinking.

That's just not going to, anyway.

So that was my hypothesis and so I said,

what I want to do instead is I want to allow people

to just passively view a reflection of their brain activity.

That was our goal.

I wanted to create like a meditative state

so people could just meditate on what their brain activity was,

not on trying to do anything.

And just to maybe to sort of have this introspective expansiveness

of their awareness about making their own connections

between their own thoughts and feelings

and the changes in brain activity that they were seeing

in our program that was visualizing that brain activity.

That's what I was thinking.

And so that is meant to be a passive experience.

Now what we did notice was that people would often have these,

the more they paid attention in this program,

the more to what was happening,

the more that their beta waves would rise up high

and the beta waves are a certain frequency range.

It's usually often associated with, you know,

if you have a cup of coffee, if you're really paying attention,

if you're really concentrating,

sometimes your beta waves might be more active.

I guess in some studies it can be other brain waves,

but in our particular case it was beta waves.

And so we would tell people,

well, yeah, that's because you're really paying attention.

But it is, it's, yeah, it's, I mean,

there's a lot of stuff that is unclear in terms of like,

I really don't understand how much noise was playing a factor

into our signals.

We had noise cancellation programs,

hardware noise cancellation programs

and software noise cancellation programs.

But it's just, I don't have a fine grained enough knowledge

of the system to really understand

how much noise was affecting our results

or not in a really detailed way.

So I, and instead of trying to solve that there

and then with our primitive equipment,

we just said, well, we've got a perfect concept

and it's cool.

And that's where we're going to leave the project

and that's where we left it.

I see.

So how many electrodes now?

Like, you know, the most recent has it?

So in that case, we were using two electrodes

at the brain-domino device.

In 2012, I was using the 14 electrodes

at the end of the, of the in-mode of the device.

So you're gradually reducing.

It's not increasing.

I thought you'll need more.

So it's really, it was, it was really just a perfect concept.

The next, the next thing that I've been planning

is to do basically the same thing,

but with a different kind of sensor,

what it's called a NIR sensor,

functional NIR for spectroscopy or light,

or basically instead of voltage,

we're talking about imaging the brain with light,

with infrared light.

Sorry, imaging the brain with infrared light,

but what is it penetrating through though?

Is it through the skull?

Yeah, it goes, it goes through the skull.

So you're shining, you're shining red light through the skull

and you have, you put two basically two sensor transmitters

on this person's head and one of them transmits the light

and receives the light.

And you calculate the,

basically you calculate the,

like a sort of like banana shape for the path of light

based upon the intensity of the transmission.

You might be misstating this,

but it's, it's like you can,

you can send the light deeper or you can send it.

But, but what I'm saying is like there's a,

there's, you can estimate the curve that light is traveling

between one sensor, between the sensor and the signal.

Is it functional?

Is it functional, FN, I-R-S?

Yes, yes, that's right.

Okay.

And so there's many different categories of light imaging,

but, but FNIRS is the most,

it's like the most,

maybe the most common and maybe like the bottom tier.

But, but the potential of FNIRS is, you know, like, you know,

like is, is great.

There's also HDDOT, HDD-DOT.

That's another cool thing.

There's this company called Open Water that is, is,

so they're using FNIRS and they're using ultrasound

and they're, they're using, they're doing holography.

So when you shine, when you shine light through the brain,

so our brains are, our brains and our bodies are basically,

to infrared light, they're basically transparent.

They're basically as transparent as jellyfish to infrared light.

So light just passes, the red light passes straight through

the human body and, but it reflects a lot.

So it's, so it, it, it scatters, right?

And, but if you can, if you could accurately reverse

the refraction of the light,

then, then you're doing the, the exact thing that,

that is holography, that is,

the holography is the reversion, the,

reversing the refraction of light and producing an image

from, from that reversal of, of light scattering.

And so with that technology, you could recreate

extremely detailed images of the human body,

especially if you have a very fast and very big camera sensor

or CMOS chip.

And so, and if you, like, you could use,

you can use ultrasound to also extend the depth of the,

of the light.

And I, I wrote about this.

No, no, I'm saying that I wrote it,

you wouldn't recommend it?

No, no, no, just as long as you're familiar with the frequencies,

you have to be very careful with the ultrasound in the brain.

But as long as you're okay with the,

just to make sure the frequencies, that's all.

I'm not familiar with the frequency numbers,

but I'm sure I could track it down for you.

Yeah.

I mean, to your point, you can use ultrasound to do surgery.

It's just, it can be a scalpel.

It can be extremely dangerous.

Right, right.

But if you, but if you're, if you are,

if you're doing things exactly right,

like using the exact frequency of ultrasound,

you can, instead of cutting a neuron,

you can just stimulate it.

You could just make it fire.

At least that's what I've, at least that's what I've heard.

I haven't, I've never done that, but,

but I mean, I guess it's similar in concept to,

to making a neuron fire with optogenetics

or making a neuron fire with neural dust

or with a lot of electrical stimulus.

So, and so, so the idea, and so,

but the question is like, okay, well,

how can we see a neuron firing

if we're not measuring electrical activity?

And so, but it, but it turns out that neurons,

what I learned, and I interviewed this guy on,

in a podcast that I did, and he was,

he's a, I've interviewed multiple people

who do imaging with, with light.

And he was saying that what I learned is that

neurons do change shape when they fire.

They expand and they contract.

And, and, and, and, and, you know,

and when they fire, of course, they, they,

they use up oxygen and, and, and ATP and,

I guess, oxygen and glucose and ATP.

But, but anyway, they need, but then blood flows, right?

Then blood has to go and bring new oxygen.

And, and so these different, these changes

are the kinds of things that you would be able to,

to detect if you had, if you had some,

if we're talking about imaging with, with light,

and basically, you know, reversing the reflection of the light

or decoding the, the spectrum of light

that is, is changing as light moves from one sense,

as moves from the transmitter to the sensor.

And so the potential, basically,

was Mary Lou Jepsen's technology is to go extremely deep

into the brain, maybe, maybe all the way to the thalamus

and to actually see, you know, if it's fast enough,

if it's like laser fast, maybe we could see

neurons firing in real time.

But whether it's fast enough is a big question.

You know, MRI is way too slow to see neurons firing

in real time, right?

But, but yeah, so that would be, that would be profound

because, because, you know, right now,

if you want to know if a neuron fired,

you have to be like really close to that neuron

because, because the electrical signal

has a very short range, right?

The actual action potential of it.

So, I mean, you could figure out,

if you're, I mean, if you're going to know in real time,

like you could figure out with EEG localization

where a signal came from, but, but,

but not in real time, right?

So, so that, that's really interesting.

Is it, so it's, because we have with Neuralink,

this, this technology that there's no,

there's nothing else that comes close to the resolution

or the speed and the resolution

and the amount of information combined.

I mean, you can, you can, like I said,

you can stick lectures in the brain,

but you don't have, you're not getting as much data

as you're getting with something like Neuralink,

which is, which is sticking electrodes in the brain,

but it's just, it's sticking a lot more

and it's, and they're a lot smaller

and it's, it's a, it's just, it's better

and it's, generations better

than, than, than something like the Utah Array or DBS.

It's just a, it's just a massive leap forward.

But what, it's just really interesting

that potentially someday

we may also do this wirelessly.

This, that basically collect the same amount of data

# Part 13

that we're collecting with Neuralink,

noninvasively with, with the holography

and, and functional nanofarad spectroscopy

and, and ultrasound.

And that, that includes doing closed loop therapies.

And, and right, and like, you know, when,

you know, I, I believe that, that,

that I think was Max Tegmark,

the guy who is leading the Neuralink project,

that he, I believe he said something like,

there is no other possible way to,

to detect a neuron firing in real-time unless

you're going to stick an electrode, like, right up next to it.

Like, you just can't do it from outside the brain.

But, but, but, but I think you can.

If you, if you can do holography,

you can reverse the reflection of light

and you can do that process at, at, at laser speed.

You know, if you can do it as fast as, as,

you know, 200 times faster than MRI,

or something like that. But, but,

so maybe, so maybe 20 years from now,

you have a, you have a device that can do

exactly what Neuralink does.

But, but, but you just,

but it's outside your brain.

It's outside your skull.

I'll pause.

I'm, I'm curious about what kind of spatial resolution

would be required to get anything meaningful out.

So, for example, there are so many snappy connections.

I'll be sure to do a reverse imaging of

how you get at the sunset level.

You try to reverse the transform on that.

There's going to be so much detail there

we need to worry about.

Would you say it again? I'm sorry.

Mike, I'll let you take that, but I got to head out.

It is a touch past midnight here

and I need to be in the lab far too early tomorrow.

All right. Thanks for, thank you.

Definitely for coming. Great. That's really good.

Yeah, I appreciate it. Thanks everybody for hanging out

and listening and contributing.

Hopefully you'll talk to you guys again soon.

Thanks. Thanks for the interaction.

Yeah, great.

So the room continues for folks who are staying.

Sorry about that.

So are you staying, Heyman, if you want to...

I've got pink to another area with a bio-friend

so I've got to quickly drop by.

I'll drop by once in and out.

Sounds good.

All right. See you later.

All right. So let me see if we want to invite...

So the question that you presented is fascinating and intriguing

that I'm a little bit optimistic

than your estimate of 20 years.

I think for this, I mean, you know,

just see the number of Nobel prizes came out just, you know,

it's all medicine, Nobel prize now, be it physics

or it's all related to imaging and, you know,

ways of providing tools to study biology.

I mean, that's where brain and neuroscience fall in, right?

It's the subfield.

So you mentioned various techniques like ultrasound

and infrared and also laser maybe.

So apparently the time scale,

we want to do it without the non-invasive, right?

So also as high as faster and better resolution.

Apparently that's the challenge in school.

So your estimate is that right now, what's your take on?

If you take one, what would be...

So there's also another clarification.

You mentioned something HDD.

I didn't catch that part.

So, I mean, so if you look up,

if you do research a topic of imaging with light,

there's many different methods.

And so if you look up HD-DOT,

there's an imaging technique, a light imaging technique

that is called HD-DOT,

which some people claim has advantages over F-nears,

but you'd have to research that for yourself.

Okay, got it.

So shorthand for high-density diffuse optical tomography

for imaging.

Thank you.

And so what's your take then?

So you mentioned...

So for me, I mean, my gut feeling is that

for ultrasound, this mechanical signal would be slower

than light electromagnetic signals, right?

So HD-DOT still depends on the subject we're studying.

If we're studying the potentiation of neurons,

they go both ways, right?

So what's your take on?

I'm not sure you're...

So for the future, what is the one of the...

If you pick one, what would be...

you think would be the best?

I mean, ways to...

What's my favorite, like, neuroimaging technology?

Is that the question?

Yes, yes.

You mentioned it too, yeah.

Well, I mean, it's a bit like...

I think it's a little bit...

I mean, I guess your question is a little bit like

betting on horses, like betting on companies, right?

Do I like, you know, the parts that the narrow link folks

are taking more, or the person open water is taking more?

But I think that it's not...

It's really...

Like the way I see it, it's a...

We've got different tools.

We've got different tools.

And it's like...

For me, I'm not sort of thinking of it in terms of

like betting on horses.

I'm thinking of it in terms of...

We've got...

You know, you could do surgery with a scalpel,

or you could do surgery with...

That involves deep learning.

You could do surgery with a microsurgery robot.

It does the surgery for you.

You just have to approve the surgery ahead of time

if you're a neurosurgeon.

There's...

Yeah, so I'm just thinking about it as different tools

in the toolbox.

And in that sense, there's no...

I don't really see a competition here.

Go ahead, Kyle, if you want.

So, obviously optical imaging is a possibility,

but what about for stimulation?

Other than maybe introducing chemicals

that are photoreceptive to allow for stimulation,

are there optical...

techniques that can direct the stimulates with high precision that's probably a big barrier

yeah it's been solved but you know it's been solved so uh the approach that uh that Mary

lejebson talks about uh often in her talks that you can find on youtube is that she's gonna use um

ultrasound to stimulate the brain um ultrasound can can do all the stimulation that's necessary

like what kind of precision like can you get down to the neurotransmitter level

specific synapses um I don't know if it gets down to the neurotransmitter level but

but um I think it gets down to the neuron level I uh some yeah you've reached an area of my knowledge

that I'm a little bit gray on but but but um I but what I do uh think I know is that it's it

goes down to the neuron level as far as whether it goes down below the neuron level I have to

I have to find out I have to do some more research

because it's basically just using ultrasound and um being forming to kind of stimulate the

action potentials right so um so actually why don't we just look this up while uh let's look

up the precision the precision of ultrasound so um the the investigative three ultrasound system

achieves an intramodal accuracy of one millimeter radii in a controlled laboratory setting

uh so this identified systematic and random errors required an optical cleaner tumor volume

to planning the target volume margin of about three millimeters

so okay so let's consider that uh okay so what so let's actually look at the um

um let's look up uh what is the size of the of um

of a vesicle

because um so

hmm extra staggered vesicles what is this so I guess we're talking about

uh 30 to 100 no okay so actually what is this okay let's look up the size of a neuron first of all

just for memory so we're talking about a neuron can range from four microns to 100 microns

so it's at like the multi neuron resolution um and yeah uh okay so let's see let's let's

let's see if um okay let's let's look at them can't I'm going to say can um can a neuron

be stimulated with uh ultrasound

so a focused ultrasound excites action potential firing in mammalian

peripheral neurons and intact tissue ultrasound neural modulation

huh so I guess uh let's let's look at the um the authors believe that their system can serve as

a powerful tool in studying the effects of ultrasound on neurons and brain circuits

uh somebody somebody uh okay so we got a new listener but um yeah so if just uh and they took

off so let's look at this real quick um a review of results mechanisms of safety

so ultrasonic neural modulation is rapidly growing field this paper is dated 2019 so the review

summarizes findings um the uh which us mechanically interacts with which uh the mechanisms by which

us mechanically interacts with neurons and uh and could affect firing are presented

so okay so this paper if you want to look it up um I just actually I just googled uh can a neuron

be simulated with ultrasound and it yielded like uh a lot of cool papers and uh so if you

wanted to do that but um I found a paper called ultrasound neural modulation a review of results

mechanisms and safety and I think that um that's something that that you would want to look at Kyle

but um that might uh answer the question you had

thanks for googling that for me sure

well I was just curious um I've been I've been interested in optical imaging techniques

and I've tried kind of you know tangentially a little bit but um it's a stimulation side which

is still the most difficult part and if you're comparing neural link to optical imaging techniques

that's that's one advantage it has it's still not down at the resolution of individual neurons

or synapses but well okay but so the thing is like um there's a big limitation though for for um

for for neural length though is that is that um you you can only uh stimulate something that that

the is um uh through the electrode right based on where the electrode is whereas um let's say that

you're let's say that you are analyzing large-scale brain activity with 10,000 different electrodes

# Part 14

but your your computer modeling suggests that the ideal place to stimulate the brain in order to

create the response that you want is far away from where your electrodes are implanted well in that

case you that uh you might want to use ultrasound to do to stimulate the the neurons that you want

to stimulate um instead of using your electrodes to do the stimulation so and uh and and going back

to Frank's point in terms of like which which which which tool is going to win uh I I think people

will use both tools actually I I expect future neuroscientists to combine both tools basically

so for a long time I've been seeing I've been thinking more kind of the nanotech side will

probably win um once we could figure out how to grow kind of a neural mesh within the brain

um I think that will be the killer uh solution grow a neural mesh yeah so you can think of a

engineered um cell basically that can just be injected and it will grow whatever structure we

need this is this is definitely like 50 years out but um I think that is the kind of holy grail

because then you can basically have a secondary neural network alongside our own neurons

and do whatever we need with that neural network it can be corporate processing before it leaves

the brain through whatever interface we have um and then it can be targeted throughout the brain

uh so have you have you read the um the novels by um science fiction author um he created the nexus

series uh his name is uh ramez nom and uh so in the nexus series novels it's a trilogy um

the nexus trilogy he uh he he he there's a neural device that he that people inject called nexus

and it's a bunch of um nano it's a bunch of nano machines and the nano machines will float through

your blood and um and then they'll get into your brain that's how how they do that is is that

well I I uh okay so well I'm not going to try to answer that it's science fiction right but um

but so they'll they'll they'll get into your brain and they'll attach themselves to your neurons

and um and then they'll begin to create a wireless they'll begin to create a wireless connection that

uh between reading your neurons and uh stimulating your neurons and and sending that information

wirelessly to other people who have nexus and it creates a telepathic communication between

yourself and and and everyone else around you in a local area like a mesh network uh who's connected

to nexus and so you so as he walks through crowds of people who are also injected with nexus everybody's

sharing each other's feelings and thoughts and uh this is uh yeah it's happening like uh I mean the

clubhouse is uh is making another direction progressing that direction the high the high mind

yeah so if you want if you really want to geek out on on cool next generation ideas

uh he's uh he's I think I think his his books are up there with like um you know with like

William Gibson's novels with like the matrix and we're just like we're just waiting for someone

to create like the equivalent of the matrix films but based on the drama's novels nexus novels uh

and it hasn't happened yet but it's uh it's bound to happen eventually

yeah thanks for that I'll add it to my queue um another thought I've had kind of as a precursor

to that would be um

kind of implanting maybe a combination of electrical and magnetic stimulators

like a high resolution kind of fabric to kind of wrap your brain and use kind of low power

basically microwaves magnetic fields electrical fields

to to to do that kind of stimulation and it could also be useful for sensing as well

but again this is just a crazy idea I don't know if anybody's trying that

um wait would you say that again microwaves what

so you can imagine wrapping the brain um I can't remember what the uh the membrane is but get

within the membrane encasing the brain and so you have like a fabric fully encompassing the

brain or encompassing enough of the brain that you can use um basically reverse tomography

with electrical fields magnetic fields to stimulates different portions within the brain

and also those same kind of that same kind of fabric could also be used for sensing as well

I'm talking like millions of kind of pixels across this fabric I don't know how deep it could get

into the brain you definitely get cortical level at least well I love I love that you said that

you're describing a project that that exists uh so if you go to uh furoxa.com that is called

furoxa f-u-r-a-x-a and that is furoxa microwave imaging uh and uh yeah so super cool idea um

but it is it's like one of the best it's one of the coolest ideas I have to I say this idea

ranks up there with open water and uh neural ink it is uh yeah it's super cool um another project

that exists is um electrical impedance tomography combined with deep learning so if you look at EIT

and deep learning uh that is another potential world-changing medical imaging technology so now

we have four right actually five you can cleared hd dot um and uh and there's more so uh there's one

that you can and you can uh so a long time ago people were trying to prevent people from from

having their arteries collapse and so they they invented this stent that you uh you insert this

this thing into your drugular and you put it you know somewhere in your heart and then then when

you pull it out it expands and keeps your blood vessel open well somebody had the bright idea

to put electrodes in that stent and they invented stentrode which is like so now you can stick a

you can stick stentrode basically into your drugular into your arm and push it up into your

brain above your motor cortex above your the motor strip I mean and um and uh and when it gets to

that the vein above your motor strip you you pull it out and it expands and to allow maximum blood

flow so you won't ever have to worry about a stroke in that particular area but um but I mean I

guess well I guess it could be blocked but it's like max it's like the maximum it's push it's

pulling open your your vein but the point is is not to pull up pull open your vein to the maximum

extent because because really it's about putting electrodes up there and uh so without brain surgery

you can put you can basically have the the same kind of like electrode array that you might have

with um with ecog or with with brain gate if you look at brain gate uh you can you can do that without

brain surgery um with stentrode which is so cool it's like it's like people at home could

could make their own stentrode and uh without brain surgery it's cool but it's like I mean I

wouldn't do that if I were you it's like let the doctors do it were you the one talking about brain

gate in a room like yesterday or the day before it came up uh because we had uh we had one of the

people who worked on brain gate with us uh yesterday uh so there was I was involved with

in a conversation where somebody else was talking about their work on brain gate

um yeah that electrode idea that's that's really cool it's close to to what I was thinking for

um more the nanotech side um but still you're you're gonna be stuck within the blood vessels

I mean you can get pretty close um I just I just really think we need to get down to like neuron

synapse level stimulation to really get some of the crazier ideas working like being able to do

like ARVR for a brain interface I don't think we can get there with with kind of multi-neuron

stimulation um so I mean um without without disagreeing with you um so okay so so there's

a study that came out where they showed that uh so you know what you can get with EEG is pretty

limited right but you can do uh you can do something if you have if you have a lot of electrodes you

can do something called EEG source localization um that is the exact phrase look up EEG source

localization and um and so they had someone had a someone had a like I think it was like a DBS

implant which can not only uh stimulate your brain everybody can also uh uh read uh and so it was able

to um basically collect data near a person's a person's thalamus and that person and they were

using uh they were using EEG an EEG cap at the same time and they and they they did EEG source

localization to figure out where the signals were coming from and some of the signals were

coming from the thalamus and they were able to prove that EEG source localization was actually

correct um by comparing it to to the data that they were detecting with the deep-brained with

the DBS device the deep-brained simulation device and um so so what that means though is that um

is that uh even from outside the brain you can figure out uh where signals are coming from

and if you have if you have stentrode uh in your brain if you have uh you know your then the quality

of signals is is much better that now you're you're talking like ecog level quality of signals

and even though that's not next to your to your neurons to measure their firing in real time

which is the holy grail of this is what neurology cares about even then you can sort of like use

that technology if you if you had um you know maybe maybe if you combine like stentrod if you had

multiple stent centrodes in multiple locations in multiple uh blood vessels and you also had like

eg you could get really precise about where your brain activity was was coming from like really

precise um depending on how many sensors you could put in there uh then um then uh then it's

in and uh so let's leave aside you know stimulating the brain electronically right and and just think

about stimulating the brain um uh by stimulating your your um from outside so so you know for one

you know your eyes you know every with a vr headset you there's a whole lot of brain stimulation

coming in from your eyes right that's taken up like two-thirds of your brain activity i guess um

so that's that's that's number one so vr like that probably like it might be more it might be

easier to stimulate your brain with with through your eyes and then through um through direct

brain stimulation right and this is this is a weird idea but like for for what what we could

find out is that even is that you you put all you put 10 000 electrodes in a human being

with neurolink and uh and you could stimulate the brain directly through 10 000 different

electrodes simultaneously but you might but we might find out that um the the highest bandwidth

way to stimulate the brain is still through the eyes through through through like vr that's a weird

idea but maybe because maybe like because the evolution just adapted the brain to to have this

like high bandwidth port and it's high bandwidth path and that just works best um it's a weird

hypothesis but um but i think it hasn't been i don't know what the argument against it yet

that disproves that so i don't know but uh it is true and also at the cortical level

you really can't get down you can't reuse the brain's own visual system to decode the signals

so you know at the cortical level that kind of stimulation you might be able to say

there's like some kind of objects in this part of your field of vision but you can't

stimulate it down kind of at the pixel level to get really high resolution

images through through brain stimulation i've always thought that's

we really need to get into kind of the spinal column if we can stimulate at the spinal column level

um before our brain actually starts interpreting the signals it's probably a much better option

for high precision control over the signals that are going in do you agree um so that i my my

hypothesis is consistent with that um and in terms of um you know in terms of what i've in terms of

what i've studied uh there's this um there's an example of um of two girls who uh their

brains are connected their their twins they're born with their brains like physically connected

their skulls are are connected right and they're they're specifically connected by the thalamus

and um uh there were news reports uh that these girls could see through each other's eyes you could

show a card to one girl and the other one would know what the other girl was seeing if she she

closed her eyes and thought about it and um so the idea there was that that um they were because

their brains were connected via the thalamus and the thalamus is where your where your your your

senses uh uh travel through the thalamus including um you know your your your your your visual cortex

your audio cortex um i mean your eyes and your ears and your your and uh and your somatosensory

cortex um your sense of touch and your taste um they all trap those senses travel through the

through the thalamus through the brain stem um and uh and then they go into the cortex and and

and uh i've also heard that the um that that there's five pathways that the the olfactory

uh bulb uh travels into the brain and one of those pathways goes through part of the one

of the five pathways that the that the olfactory bulb travels that it does actually go through

the thalamus um but the other four the other four do not so you often hear that oh the olfactory

the spell doesn't go through the thalamus well part of it does uh in little known fact part of

it does and so so the idea here is that um uh if you're going to implant uh information

# Part 15

into someone else's brain like something like an image um maybe uh the the brain stem is causing

it is uh as a potential target to try um but uh but we need a lot more research to uh to validate that

and i so i mean i'm not like i i'm just like i'm not for sure why

Kyle's saying we we could not stimulate uh micro columns directly to to uh to create images

um i i what i would think is that we haven't figured is that is that is that we have we

don't have a study yet that's been published showing that that has been uh been figured out

but but i i don't want to use the word we can't it can't be done because because uh maybe maybe it

can and in the right way to do that just hasn't been figured out yet i'm not i'm not saying it's

just um i'm based on my understanding and this is i'm not a neuroscientist at all i'm coming

work from the artificial neural networks side it's that's at that level it's already so abstracted

from the raw signals that's you know maybe there's particular neurons or particular clusters of

neurons that you can um trigger for particular objects um a particular you know patterns or

something like that but it's it's so far removed from the raw signal coming in from the from the

optical nerve and um again there's even more processing going from the retina all the way through

um that i think you'd end up needing so many um electrodes to kind of you know it's like each

electrode will control one particular object that you can sense in your visual field not

necessarily controlling particular pixels to kind of have like an overlay um that that's my hypothesis

so um the only thing about that is um so i mean yeah i mean i think i was i think i was a hundred

percent in agreement with you about five years ago but um but since then it's kind of like um

um i think that so i mean the the deal with uh actually really was really four years ago so

really since so 2017 was when uh jeff hawking was released his uh his first paper on um how how

micro how his theory of micro columns uh how they um basically how i'm sorry just columns columns

in the neural network how they can organize functionality of the brain and so it was 2017

when i read that and that's when i sort of um that's sort of like really messed up the picture

quite a bit because um yeah i mean like i said the girls were connected by the thalamus and maybe

that was the clue to how you could transmit images from one part of the brain to another but then

but then um uh but but uh but the thing is like well so maybe a neural a single neural column

is organizing the uh the information um of uh you know combining basically the many different

modalities and what you might have um is many neural columns doing a similar operation at the

same time so many many neural columns that are sort of basically trying to to uh do this sort of

duplicate multimodal process where they're combining visual information with audio information with

somatic sensory information you to touch feeling insights um and all of your senses when you're

touching a phone when you're holding the phone how far as for me it was the phone orientation

and so you have uh one or many probably many more neural columns that are uh tracking uh

this phone's activity but you've got at least one and one neural column that's doing at least one

and um and then uh and so they can in summary they you know so there's maybe lots of different

representations happening but they can't but what's similar between these representations

allows um the sort of the brain to to vote and what's different uh allows the brain to

uh eliminate the the incorrect analysis and uh so then it can be like reduced and and uh

so to make a long story short it's like um the ability to change um someone's perception of

reality might might come down to figuring out which uh microcolumns are are relevant at that

particular moment in time and manipulating them and that operation um might be um might be a

lot less work uh if we can figure out exactly how that works and um exactly how to how to

locate uh the activity and identify the activity correctly and and what and what it's going to

take to um to to manipulate the system so um I have to say that uh uh but here's here's a reason

is because um in general the the thalamus is a lot harder to reach uh than the neocortex and so if

we can modify part of the neocortex uh that effectively does what we want to achieve by

modifying the thalamus um then uh then maybe that's a an easier way to to accomplish the same goal

and uh and and more to the point that the the um the activity between the thalamus

and the in the neocortex is um especially I mean between the thalamus and this and the

in the the primary sensory neocortex so the that I'm talking about the the visual uh um the the

visual cortex audio cortex and the somatosensory cortex the primary sensory cortex and the in

the thalamus is is like it's like this it's like it's like feedback loops it's like um

you know lots of like multi layers of of feedback loops feed up at feedback loops between every layer

of of the of the visual cortex v1 v2 v3 v2 and each one of those communicating the thalamus

each one communicating with each other and um and so there's so much like there's so there's so much

like traffic going in every different direction that that um it's it's so here's here's how I think

of it it's like imagine that the feedback loop really is like one big circle right and the big

circle is passing the data around in a circle all the time it's the oscillation of this of this

information traveling in a big circle and do we need to intercept that circle at the thalamus

or can we just really intercept that circle anywhere maybe closer to the surface of the brain

that's what I'm saying you know what you know I'm saying

yeah that makes sense um

but again that all sounds like a recurrent neural network to me and so you might be getting time

lag um you might be getting you know at the higher level in the new cortex

so much feature processing has already occurred as it's going as the signals have gone through that

loop um I just think being difficult to target like I just want to have a blue pixel at this

point in the visual field like to get that kind of resolution um I think we need to go deeper

we need to go at least to the thalamus and possibly like you said going all the way back

up to the eyes maybe not like I'm just thinking like how do we do it without having to have goggles

on or any kind of external stimulus um so if there's anything that can tap into the optic

in order to directly stimulate at that but that point that's probably the most effective

but then I want to live in the matrix so

so having something deeper in the brain that can stimulate everything

would be great so have you read about bi-directional recurrent networks recurrent neural networks

I have knots all right um

so it's it's an interesting topic so so so how so maybe you can talk a little bit about

how how is a recurrent neural network similar to the brain and then I'll

then I'll go into bi-directional neural networks

so typical artificial neural networks are feed forward the kind of stuff that they're

doing deep learning and most recurrent neural networks these days um well typical neural networks

are feed forward you have an input layer and everything just kind of pushes all the way through

to the output layer with deep learning you just have a whole bunch of layers uh recurrent neural

networks have backlinks so you're taking signals that have already gone through processing through

various layers and feeding them backwards and that's it's commonly used for it gives a sense of memory

because essentially signals can be repeated and loop around in the brain and um typically in

recurrent neural networks you've got to repeatedly stimulate repeatedly activate the input layers

to get a before you get a stable output so that you get the signal to kind of loop around a few

times before all the neurons on the output layer kind of stabilize um

that's typically how it's done on the artificial neural network side

okay um hang on I am just um

so um so yeah so there's this idea of um you know I brought this up in a discussion with

some some really great neuroscientists and I said well is it the case that you have like

information flowing from the thalamus to the bottom layer of the of the neocortex uh and you

know and then up to the top layer of the neocortex and then back to the thalamus sort of like in a

big in a big loop right from the bottom to the top and um and uh and so there's like this cycle

right just like um because because it's uh people are still trying to understand exactly how

understand what what what exactly a biologically plausible version of back propagation would be

um there's a lot of ideas um but it's still I think it's still an area of of the research

interests and um I don't know do you want to comment on that specifically before I continue or

okay so um so then we have um but then we have uh so uh a bi-directional uh recurrent neural

network or um a or you can also do a bi-directional LSTM um basically it's like it's like okay so

like um what you really people should like you know search look on look on the web and look

at stuff but um just just but just imagine like if you take if you took the input right and you

just and you sent it into two different directions at the same time into two different neural networks

right and um and I think that may have been like the beginning like the like the like the the um

the genesis of the idea was like okay well what if we played with the the structure of where stuff

is going a little bit further what if we sent it in two different directions like forward forward

states and backward states and process the input in in multiple different uh directions and and uh

so uh yeah it's um I'm looking at a wikipedia article right now called bi-directional actually

it's not a wikipedia article but it's an article called bi-directional recurrent neural network

BIRNN training system and um it implements a forward pass algorithm and a backward pass algorithm

at the same time and uh so but so here so so I was sharing this idea with uh with these with

these neuroscientists and and um it's really great neuroscientists and and they um and they

I guess uh they didn't knock it down but they but they um they took it up a notch because

um it's kind of like um it's kind of like you have uh

um like it's so like a neural so like a neural like imagine like a neural column it's just like

any random neural column like it like like everywhere in the brain in the neocortex the top

two-thirds of your brain so but but neocortex specifically it's like the same repeating algorithm

it's the same thing same pattern just repeat over and over again in the visual cortex and

in audio cortex and the and the post bridal cortex everywhere same repeating pattern but

so you pick one particular neural column anywhere in the brain and um it is receiving inputs from

every direction from below from above from the left from the right from the front from the back

from every direction right now so that so that so just like imagine you have to create a neural

network now okay where where it's not receiving inputs from one direction and and pushing outputs

to another direction it's receiving inputs from every direction and pushing outputs in every

direction you see what I'm saying like this is weird um this is weird this is weird weird but it's

it's like yeah so that's what you this is kind of what you have to think about in terms of like

it's not just like recurrent neural network it's it's it's it's like next something next level

uh and uh but yeah so I just wanted to hear that that's cool um

so it looks like brnn's are more like an evolution of the typical single hidden layer perceptron

and what I've been thinking when I think of recurrent neural networks like the modern ones

it's like you said like lstm's deep deep neural networks where you have those kind of back links

going across layers um but I agree with you that's biological neural networks are way way way more

complicated than anything we're simulating with artificial neural networks but they're also super

cool I mean it is like the brain is truly a 3d neural network because it because it's processing

information in in at least six degrees of it's it's better to think of it as a neural graph

like yeah from my research like I mean some of the the when you have dendrites like

basically go across the entire brain like extremely long connections between disparate parts of the

brain um so it's not just that they're communicating with it's not like a column it's just communicating

with columns next to it they can be communicating with a column on the other side of the brain

and it's incredibly difficult to to simulate that

there's definitely no algorithms like the training that work like that right now

no I mean look we don't have we don't have the um my my understanding is that uh even even uh

creating a of of um a model of the brain that's um completely functional it's just beyond the

computational capacity of computers today and uh we may not approach that you know before 2050

or 2060 or maybe even later if we're really depending on the level of detail we really need

a great which is unfortunate

have you studied at all in your like the uh the quantum theories

for neural activity I have uh I have sure let's let's talk about them what it is what's your uh

what's your interest there I mean just getting into like are we even simulating the right things

we're trying to simulate a brain looking at the structure because I basically have seen and

I I mean individual neurons are basically entire chemical computers in and of themselves

and by whatever mechanisms they're using they're possibly using quantum techniques

or that they operate at the level of individual molecules and could be subject to some quantum

processes and so even if we were able to simulate you know this trillion node neural graph

we would be missing the quantum element uh with an individual nodes individual

# Part 16

okay so um so it gets even worse than that because um it seems like uh you know with

with uh short-term memory we'd need to model um the uh we need to model things like um whether

receptors or in the NMDA receptors are open or closed between different neurons because they

because that is something that changes uh very fast in real time uh as you're in at the short-term

memory range um and then the long-term memory is whether there actually are uh you know

connections at all uh so that synapses can form between different neurons um I mean that's part

of it this is I'm maybe that's not the whole thing but um I may have uh okay go ahead and would you

I lost my train of thought let me pause I'll pause there was a paper article I read

over the last couple years um that's found that there was a differential activation at

different synapses within a single neuron um and like that's a level of simulation that I don't

think it's really been considered um at least until very recently was so that you were artificial

neural network models um so what if each if each neuron is an individual kind of analog computer

that can selectively stimulates particular axon or particular synapses like we are very far away

from simulating actual biological uh neural activity so um so without without um so there's

too many things that I would need to say about that but just sort of like what I maybe I just focus

on one part of that is that is that um is absolutely the case that single that um that synaptic

connections uh or receptors are being modified at the single neuron level at the at the speed

of thought that is that is the actual truth um and the NMDA receptors are are uh uh being uh

created and being destroyed and being blocked or inhibited in real time at the speed of thought

this is uh this is this is a real this is actually part of the thing that happens and

happens at the single neuron level now uh there's there are arguments and evidence that the single

neurons are um self-regulating and it's not that it's not controversial at all and there's also

arguments and evidence that um uh that single neurons are actually being regulated by other

neurons and that's also not controversial uh both things are happening uh and uh this is you know in

the in yeah I think we're in agreement that it's very complex um so welcome David uh you've been

listening for a while what do you what do you think it I love this stuff um I am just learning

because you guys are the experts and of course it gets me thinking it gets me thinking so

I think Kyle said something about quantum so that's possible and if you could elaborate more

what you guys know or what the what the science says or doesn't say about how the brain works

and how that gets down into the I guess through the biochemistry potentially to the quantum

physics they can you guys elaborate on that sure um there's been a lot that's been

that's been uh speculated about quantum effects in the brain um you know from like I guess the

the most well-known research is sort of you it's uh so there's I want to say that that um

um they there's this weird sort of thing going on culturally between this guy um

who wrote this thing called orc ore and and everyone else in their neuroscience who doesn't

want to listen to him which I and I also kind of like uh have some disagreements with his uh

with his ideas but but but that he's probably the most well-known guy to talk about um quantum

effects in the brain so you can look up orc ore or ch space or it's a theory of quantum effects in

the brain but um but um it's I think it's actually not really a controversial idea and uh and uh so

the the cultural the cultural thing is kind of funny but that like you know people get mad when

you bring that up it's not and it doesn't really change anything uh because um because because

here's the thing is like the ideas of uh short-term memory and long-term memory uh are not going to

change if there's uh some additional quantum uh things happening with uh microtubules or whatever

it's not going to change uh it's still basically um you know uh information in the brain is still

is still basically you know neurons detect information because they detect coincidence

patterns and um and so like if there's a quantum effect that the change that that is uh changing

the brain the way it would happen is the um the quantum effect would change the uh the gradient

of the neuron so the gradient of the neuron is um basically the distribution of positive and

negative charges and that's going to affect um when the neuron is going to fire because if you

separate the positive and negative charges uh that the neuron has to reach uh equilibrium

in order to balance itself in order to maintain its its equilibrium and so it and so the action

potential event fires and that's when this went in there on fires um it's sort of like um it's the

same sort of reason why lightning happens the positive and negative charges separate enough

that uh the the the um the atmospheria needs to reach equilibrium in that in that moment

and there's a lightning strike and then uh the positive and negative charges are distributed

more evenly after the after the lightning strike um and um so if there's anything coming from the

microtribules that's going to affect how a neuron fires uh it's going to um change it's going to be

reflected in changing the ions uh the ion distribution which is changing which changes

the gradient of the of the neuron's positivity or negativity which determines uh uh when it's

going to fire which is what which would affect the brain but it wouldn't it wouldn't be a revolution

uh in in that um the brain is like what we know about the brain we not so far we don't throw that

out and we just it's the same the the knowledge is not is is going to be good whether the no

no matter whether the microtubule theory ends up being uh real or or kind of a mistake and um

so so the funny thing about microtribules is it is uh when microtribules are destroyed uh

people have uh memory memory issues okay and so uh there is a correlation between memory and

microtribules and the microtribules are where the orc ore uh proposes that uh memory is stored

in microtribules with quantum quantum effects okay but here's the thing um microtribules are

responsible for the structure uh before for they're like a structural support it's like the bridge

it's like the supports of the bridge that holds the bridge up okay they they microtribules

help the cell to have uh to have a space for the cell to be a room for cell to be a structure or

bubble and without without microtribules the cell is going to collapse okay now in order for memory

to happen for a long term uh potentiation to happen uh there has to be there scientists have

discovered over uh you know 200 years of research called neuroscience that uh that uh new protein

synthesis has to happen but in order for new protein synthesis to happen there has to have

it has to be a space for it to happen you know your your ribosome uh has to uh has to have

have a space to check your your uh um to to check your your your DNA and your and your and do its

process and do the new protein synthesis process and make a new protein from from your DNA right from

your it's it's i'm not an expert on genetics but it's something like that and uh so new so when

you whenever you create a new memory a long-term memory or when you recall a long-term memory

uh new protein synthesis has to happen um and uh and and that and that's shown it's illustrated

and that's the semi sound weird but that but there was this recent study where uh so in the

case of Alzheimer's and Parkinson's it's fact and you can research this that uh new protein

synthesis is is is inhibited uh and in this is uh something they found out in uh last year in 2020

there was a study in Parkinson's and another study in Alzheimer's and they found out the new

that basically um uh not only is new protein synthesis uh inhibited in Parkinson's and also

also in Alzheimer's but if you uh treat the patient with the chemical to um to improve

uh to increase their uh to their ability to synthesize new proteins then um then that patient

is going to see improvements in their condition but but the thing is like if you if your microtubules

have collapsed there's no space for you to for yourself to um uh to do new protein synthesis

so you so of course you're gonna have memory issues but but it's like it's like that'd be

like saying okay well the way the way it's like imagine you're like the the football stadium is

holding the football stadium up uh the support of that stadium collapse well okay so so so um so

that so that's like saying okay so football always stops when the stadium collapses right

but then you think well the stadium itself is causing the football to happen no it's not it's

just the container so so i think it's just i think orc war is just like a massive mistake

uh and they're confused they're they're he's he's essentially confusing uh correlation

with causation um but oh go ahead i'll let you respond no age it's just i love these

kinds of conversations when i just can't hear an expert just just think through all this stuff

mica that's so freaking cool i'm intrigued with it for for a couple reasons um my father's funeral

was uh was last friday and he had a wonderful long life of 88 years and married for 63 and

thank god we've got a lot of really great things to kind of carry us as we work through uh you know

just everything but you know it's kind i've been a caregiver because he was wrestling with cancer

for six two cancers okay he worked at the nevada test site for decades and sadly a lot of people

that worked there um on the nuclear bombs you know during the cold war a lot of them got cancer

hundreds and even thousands of people had cancers because we didn't know what the hell we were doing

but in any case i just i've got these just odd it's probably just me i don't know you know

just these weird desire to know that there's something on the other side and i am a nerdhead

so like just listening to you guys is like such orchestrated music in my ears to try to understand

what the science say about all this stuff you know so i i just i love this stuff i look into the

orca stuff the orca guy i was at a uh i did have a really cool experience with neil de grass tyson

about seven years ago at a vip event he was a keynote and i chatted with him a bunch of us

were chatting with him but like he he introduced me to this these ideas some some of that i guess

one of the other guys there had asked him you know what's dark matter and he and neil de grass

tyson said well you know this is someone else's theory but it's pretty popular what it's it's a

gravity leak from a different dimension and so i thought holy crap how cool is that i call it a

kennedy moment because my head got the kind of just it's really ridiculous let's say that but

it just blew my mind and so you know i'm just really curious if dark energy dark dark energy

if there's just something that explains these these these things that happen right i don't know

and then i'll go close my jabbering on all these things after one more point which is

i'm not a string theory expert but i i've heard and i know that like on the surface according to

string theory which is basically math that there's basically math proof that there's 11 dimensions

and then if you hear neil de grass tyson talk about um just if you're a higher dimension

being you can look down into smaller into smaller dimensions but if you're a smaller dimension being

you can't look up into higher dimensions so then i think and i get i as you can tell i don't know

what the hell i'm talking about but the space time continuum is if please correct me if you

guys know this is not the right way to think about this but our universe is this comprised of four

dimensions right isn't that right other than the black hole who knows what the hell happens in there

we've got 3d space we've got time and we have pretty up for debate well everything's up for

debate you know right but my point is isn't there like more more dimensions beyond the four that

# Part 17

we live in in the universe and again i i don't know what the hell i'm talking about i'm just a nerd

and i try to listen and that's it i'm david thank you micah for letting me speak but please continue

sure um well people people can respond but i but uh i i eventually like um make the physics responses

short so we can get back to the the main topic but which neural neural physics is like brain waves

and stuff right nerve gears brain computer interfaces and and uh yeah we can take a

temporary diversion into physics just a short one okay but um but we'll come back to the road to the

main topic but uh just uh just real quick um uh so i think grant had an answer and i'll just pause

myself go ahead i don't have an answer just i think that um i i guess two points i would make is one

i think a lot of people say that time is a dimension and i don't agree with that and two i think if

you're trying to think about you know what's happening in terms of dimensions i start with

trying to just at the very least uh visualize what a hypercube is since that's something real

and even that's super hard to do so that would be my recommendation

okay and i also want to welcome jeremy to the room jeremy did you want to uh

go ahead i just i just um you know coming for a visit um i don't know i was just in a

in a pretty hectic room it was something like what just um hanging out for 10 minutes with cammy

cammy russo and then there was a whole bunch of physicists in there and they got into a fight

and we closed the room so i'm drifting from physics now uh back to a neurophysics here

that's cool due to a fight due to due to a probabilistic fight yeah yeah i mean you know i i feel like

physics people are sometimes no offense to any physics people in the room here but uh there's

some kind sometimes a little bit disconnected from from reality in what they fight over uh you know

like stuff like somebody somebody asked recently like what what is the um uh the uh the upper bound

on uh how much the brain can stimulate can be stimulated and and uh and one one guy who was

a neurologist was like well i don't i don't think there's any uh limits and but i was like oh wait

no wait a second now you don't understand what he's asking he's he means like if you're calculating

infinities and to the end of existence like this like physics is like what is the like there has to

be like a theoretical upper bound to the the the absolute maximum amount of information that the

brain can be fed at one point in time i mean you're just gonna get tired after too much information

right but but um but to his but to the realist the the neurologist he's thinking really along the

lines of like well what is what is uh what's real now in terms of our equipment now in terms of our

technology now and he's not thinking like a physicist so and neither neither would an AI person either

you know i mean it's when people try to say that they're going to solve AI using physics it's well

i don't know i mean it's a ways away you know it likely in my opinion it's not going to require

that much physics in my opinion actually to uh to make a machine that can actually think a little

bit like a person why is that sure man well that's so that was maybe a loaded statement on my part

maybe i shouldn't have uh opened the can of worms i don't want to i don't want to hijack uh i think

it's actually the most important distinction with AI because it's either something you can just code

you know in a um turing complete you know interface or it's something else i don't mean

mica it's up to you guys if you want me to respond i don't you know i don't want to i don't want to

divert you no no no so so jimmy you're you're on topic for this group so so talking about AI and

everything you love to talk about is is part of this group it's in the description so keep going

all right all right well i mean it's tricky i mean you know handsome below is in the group

uh maybe handsome might have heard me uh respond but you know there's it's very tricky uh with AI

now i mean we have obviously people like mica and and many others who are um who are trying to come

at it trying to understand the neurology the the biophysics the you know the nature of how you know

the whole the whole brain works in every aspect of it and hope to be able to map that and then

there we have the neural link folks who are trying to tap into the brain and capture certain segments

of it and we also have different um AI scientists and mathematicians trying to map parts of the brain

in a in a simulated fashion and then you have AI folks more traditional AI folks using machine

learning and neural networks to take information from basically the databases as many databases

as they can get their hands on and to be able to sift through it and to be able to use pattern

pattern recognition and all all different types of patterns to be able to slice and dice every

little element um in these databases up in such a way that um might you know might get at the way

in which a person would think um but it you know and then then you have folks like myself and then

now some other folks I think deep behind just came on board with this idea of trying to ground

trying to simulate basically um the the the simulate into reverse engineer how a mind might

actually develop um without actually looking under the hood as Michael would we were actually

trying to figure out the the the learning process right from the from the ground from the grounding

from the grounding of patterns and what do you think that base base pattern kind of physically

looks like well I mean there seems to be some agreement I mean I I started uh I mean someone

by the name of Terry Winograd actually started to pack this this idea back in the early 70s he was

a kind of a pioneering AI guy he's just started with the notion of a sensor and sensor sensing

colors um and being able to just name them and to be able to you know as a way to get at

the symbol grounding problem where the where the where the colors were just basically the the colors

represented sort of wild cards of nouns right and it could be but any any kind of the most basic

object uh you know and this could work by the way um if if you are blind uh you weren't seeing

you could actually do this with auditory signals uh or you could if you were if you were deaf you

could also do it probably with um touches but you know very particular patterns of touch um

um and or or possibly even well I don't know I haven't I haven't thought about smell but uh

there's you know or possibly taste uh so the the goal is to be able to ground it to just the most

basic uh possible um objects or or at least senses and then to be able to mimic uh the sensory

spatial temporal um ability of a of a of a person of a child a young child um which they're doing

so they are doing experiments uh basically based on pyj's it gets to object permanence a lot faster

than pyj ever uh ever thought and so so then so basically I had sort of maybe about 20 years ago

you know I've been doing this for a while um I began to sort of merge this idea of you know

sensing color but to do it in such a way of sensing colors of patterns uh in such a way

that these patterns would have to associate themselves with colors such that a sensing

simulated human would need to basically sense them and in a simulated fashion without even

you know having a real child there and then I began to notice that you could you could obviously

have a there's a bare minimum of you know I sort of came to a different conclusion than Terry

Winnigrad you know Winnigrad was talking about just naming colors and then sort of associating

colors maybe adding a few operators in but but I sort of I was like wait a second you know

I think what we need to do is we need to be able to make it so that it's mimicking a child

and so that the child is going to actually first they're going to point or they're going to signal

they're going to make a statement like that or it or or uh or red or um or if you know that is right

they're going to they're going to apply language to it and so then I began to figure out that there

would be a way to build an ontology um a very granular ontology where you're literally layering

every meaning that a potential child would would would learn but in a very specific order because

it's not simple and it's a very you can't just it's not going to it's not it's not so random

there's a there's a lot of probability going on because humans have needs and they have instincts

and they have they have requirements that they that they possess in order to develop that are

really pretty much no option so they have to be able to use the simplest words you know where in

the beginning they can use you know just obviously uh baby you know baby babbling but but eventually

the babbling has to transform transform into words and and those are the very most basic words

words like like that or or this or is or you know um it or you know uh you know and then to be able to

to combine these words in in such a way that you're getting basically this and that this with that

this and that are both that this and that you know red is red and blue are colors being able to

gain levels of abstraction and then I began to realize that you could get much more language

out of that you could begin to begin to trace that what it would require like this this idea

this theory of requirement this to trace the child um getting a uh you know beyond words that are

beyond uh you know with or or you know like words like start where you you're literally catching a

word of you know a color um or an object that is um you see it actually going and so you're

initiating a word like go and then you're you're you're watching it move and so you're saying that

is here you're starting before go you're starting with maybe here that is here and and then that is

there and then you're establishing and grounding that because something is here and then something

is now there and then there's some sort of time and this is potentially involved that it's actually

moved and then then you begin to say that you've been able to instantiate the meaning of movement

and then you're able to when you when you're actually going from movement you're you're able to then

get into um uh to this idea of um let's see i'm just trying to i'm just trying to remember this

is going they're going back a while um uh something like um you know uh it's it's it's moving faster

and it's and it's moving and it's and it's it gets to it's getting to another thing and then it's

beginning beginning to arrive or it's beginning to start or it's beginning to finish and you can

really i found that you can begin to develop many hundreds of thousands of words this way

and it i um and you can these words aren't just words they're they actually turn out to be

statements um they turn out to be sentences and they turn out to be sentence structures they turn

they turn out to have syntax and would it be fair to say it's um at the end of the day it's pattern

recognition you know like you're looking at patterns you're looking when they start and stop it's

inherent to it you know so like your understanding though it starts to stop i think when you are

immediately born you understand it's starting and stopping it's inherent to just pattern

recognition in general i would say that in the beginning i would say in the beginning there

are patterns there's no question about it but but but i think i'm saying because i had swelling

you know thinking these are just patterns that you're picking up on you know you're not going

to get any debate from me about that these these things some of these things are patterns but

but but what i would say is that they they eventually move what are you everything pattern

well no i mean otherwise i could just write a patent and then just say that you know i'm making

a pattern pattern not patented no no i just said the word patent i just used the word patent because

i was saying i could use the word i could i could use the word pattern in a patent and then just to

be able to uh patent a bunch of patterns but i'm just saying that's completely that's a legal

framework i'm just talking about life in general like you know us as a as a entity that's collecting

data you know how it's most abstract level you can just say it's pattern recognition i i don't

know if it's as as simple as that i think that it's um it's it's involving you're you're feeding the

system um words that fit that fit the pattern the more memory needs the more patterns you're

digesting to understand the rest of the patterns you have yeah but but i'm saying that these are

you're you're basically collapsing the evolution and you're collapsing the development of of of

people you know known development of of children and young adults so you're kind of collapsing it

and then you're you're basically trying to figure out what the what the required not just the

required words are but the required experiences the required emotions potential emotions and

feelings that from the most elemental fundamental uh on up and so also is it to verify isn't a word

just like a way to convey an idea to another person you know like it's just like you also

have the concept of what that is doesn't mean it means the same thing like words mean different

things technically but it's trying to have a shared understanding but that's exactly why we're doing

# Part 18

you know it's not just me that's doing this now i mean deep mind is doing it too deep mind is not

not choosing to do this for the fun of it it's it's because you're trying to ground it you're

trying to ground it so that you can share meaning so that that that there's a reason why children

learn the way they learn and that they're learned they're able to sit together and all learn and

not necessarily they all don't successfully learn but but most of them do i think and i think there's

a reason for that and that's because language is grounded and it's it is grounded in very basic

the most fundamental structures and then it escalates and so that that allows for this ability

to have a shared language and a shared sensory temporal experience feeling of a shared experience

of some feelings of sensations of sight of hearing of taste of touch of of all manner of of um you

know of words and so i think it's it's uh it's more than just getting back to this idea you

have suggested the patterns it's it's really i mean when you say like like if you look at the

word regret i mean you know you regret something i would say it's a it's a it's a humanly developed

um word i mean these words are humanly developed why do you think that i mean if a dog you know

attach another dog if i could just finish so it's involved because because people need to interact

with each other and they need to live with each other right so if you're going to live with each

other and understand each other you're going to need to be able to cooperate and you're going to

need to be able to you know basically share right we're basically sharing in social beings so

i i you know i i think that you know it becomes very abstract when you begin to call everything a

pattern it i would call it more of a requirement i i would call it more of a requirement than a

question to expand on that idea you said it's human unique which i think is not the case in terms of

at least regret because i mean think about what the grant means right oh no i don't mean please i

don't mean i don't mean to say that's just humans i'm sure that many animals from the animal kingdom

are able to feel regret i'm sorry i didn't mean to to say that okay okay that's what i mean sorry

i think what jeremy's touching on is that embodiment is a key component we're not just brains in the

boxes we're brains and bodies and that has a significant effect on how we model the world and

how we how we recognize those patterns because those patterns are all coming in through our bodies

and so as we all have the same bodies for the most part and so we all tend to recognize

similar patterns and over time as cognition develops and becomes more abstract those patterns

become much more abstract but they're also common because we all have similar body

forms yeah we were all mere cats right now the type of patterns we'd be talking about with the

you know ones that we were all experiencing and they probably don't differ from the ones we're

experiencing now so i just had a funny thought and and as like i was imagining that if an animal

i was imagining like a cat or something feeling regret and then like if we like listen to their

brain like okay what do you mean you feel regret and and like we might discover like

too great comedy that the regret is like extremely egocentric i'm just you know like

extremely self-centered like regret like like um like if like maybe the cat is uh accidentally causes

this accident and and and someone else gets hurt but really the regret is about missing its food

or something i don't know it's like well regrets regrets super kind of pain right cats don't feel

regret it's like a yeah it's true but it's like a pain you know regret is just um

i think at the end of the day you can really boil the shit down to super simple things like

like bad and good you know like regret is definitely not bad yeah that's right you can

not know begin to be we talk we talk about these things in the field as as primitives

and you can be able you need to be able to start with the most basic primitives and and indeed good

and bad are definitely uh somebody no but the but the language but the language uh construct

helps create a context for what that good or bad signal means to to the organism and without

without language it does but language is also purely meant to just communicate with others

if you had lived in this in a world by yourself for eternity and never talked to someone else

you wouldn't use language you would just understand what's happening to you in terms of patterns

in terms of what has happened to you but that doesn't address the non-verbal communication my

wife's uh she's a preschool teacher she's got like a master's degree in early childhood and

that's in that field they it's pretty much commonly accepted that empathy is taught so we

immediately day one of looking at someone else if you're a baby you're immediately just trying

to communicate with them and trying to you know but you don't know how and obviously now we're on

clubhouse that's how much it's involved well no but i'm i guess my point is simply if you're you

said language it was kind of it's all i'm i'm primate understood you but but you know if empathy

is taught think about all the other things that i think it's almost inherent yeah i i would i would

agree with garrick grant i think that there's empathy would be a mixture of being taught at

an inherent because one of the first things i think if you just plop into the world you understand

is i am myself and this is someone else like and immediately there's that empathy now you don't

understand the beginning that they feel pain when you punch them you do over time because you know

oh when i get punched i feel pain but you do inherently understand the empathy in terms of

this is someone else and i'm building up my empathy awareness yeah no i i don't know i don't

know i mean other than just it's it's you would think okay you would think all that but remember

not all of us have the same left and right cortex you know firing off at whatever performance level

so even animals lots of children well they're not gonna talk about animals what that yeah but

that's anecdotally it just projecting you who knows right all i'm telling you is that in the in the

child development field that um and all the children we're all different right and we're not all

born the same and we can talk about you know all the nature genetic stuff that just some of it's

gonna activate and some of it's not and so for for lots of humans if they need some some help

along that and so the teaching of it is is kind of a if you wouldn't give much argument that whole

space is all i'm saying that whole field there's no question that there's some people it's cultivated

it's cultivated there's no question that some people are born with poor poor ability to empathize

i mean there's just no question about that and that that some people need a lot of training

to even begin to even the fathom of the concept i totally agree or the i guess i'm my point is

just that um kind of going back to my pattern recognition it's something that you is emergently

learned is empathy because you're like wait a second i'm myself i'm feeling the same things

that these other people are feeling i would say you know what though it's tricky it's very it gets

tricky when you know david's example is pretty good i think um you know i don't know if anybody knows

but uh you know that famous actor sasha barron cohen anybody know him oh yeah he's so his brother

apparently is one of the foremost he's like an oxford he's a phd and he's one of the foremost

experts in autism and and he actually talks a lot about these issues um and it seems very

controversial not very but somewhat controversial um and he's talking about um the fact that

you know for some for some folks that they you know they are they don't really have he compares

people with autism and people who are on the sociopathic uh you know spectrum who like he says

that people with people who are sociopaths are not born with empathy that they don't actually

have the feeling but they actually understand it intellectually and that he says that that the people

on the spectrum on the autism spectrum they actually can feel they do have the feeling

but the intellectual aspect of the intellectualization of it for them is complicated and murky

and so they actually have to sort of figure out what's going on whereas the sociopath

understands what's going on but actually can't feel it so it's tricky to say that it's always

emergent because if you are as as david i think correctly put if you are missing a certain feeling

state or a certain emotion state if you're or if you're missing a certain you know a sense of

sensory perception uh or or emotional perception you might not ever really get it it might not

actually ever or isn't that isn't that more reason to say it's emergent because it's like

some have emerged more than others i don't know if something doesn't emerge i don't know if something

doesn't emerge i don't know if it's if it's emerged that's too that's too simplified i mean i really

attracted to what you're saying but yeah no i think you're i mean the pattern is a very useful

metaphor right the pattern and just our ability our brains really to quickly interpret patterns

and then we start to map it out to bigger mm-hmm you know i totally get it but i think that's great

i just uh i don't know is there you got a lot that's a really strong base you know foundational

base i like that i i try i think if you want to simplify things as much as you can and sorry

it's an i love what you say so it's all right it's okay thanks uh i read the uh there are

mirror neurons in the uh in the brain and uh some people have abundance of them and then some others

have uh death of them so and then they uh so some people just don't not i mean probably just don't

have to do a base to uh i think i think just one uh observation i have in terms of

um people understanding what's going on is if you look at um you know like a

a newton or someone that understands a lot it's like they almost go off the charts in terms of

understanding so it almost seems as if a base understanding is the most important because

once if you have a good base you can pay basically pick more fruit off the tree because

it's actually yielding fruit versus something that never really grows much so it's like you can't just

be quote smart and able to pattern recognize right now you have to have a big understanding of what

is happening and build off on top of that so it kind of makes more sense if you look at it that way

that someone would be able to understand a lot more uh going forward about a lot of different

things because they have a very solid structure of what the patterns are how they're fitting on

top of each other in a so to speak well that's what education's about right the pedagogy education

should totally as long as education's good but yes but i mean well aside from that that's

that's kind of the point of education but then if you want to go become a researcher or something

you've got a all of us have a shared understanding of the language and then we went through a similar

educational system to some degree but then it's up to us to kind of take that and continue to

explore building new it's almost like legos right it's like building new patterns and fabricated

that the creative brain kind of gets involved right so i don't know i i think really out of

self thanks grant for really getting me to to really respect the pattern recognition piece i'm

more intrigued with the other sides are not necessarily correct but you could see that and be

like oh this means that and then after a while i'll be like wait a second it means this but if

you're not willing to readjust then you're just going to be stuck in your old way

mike you had a question before about the good and bad you were going to make a statement

i uh i forget but i mean i feel like i feel like a lot of things that are being said or not

are more on the psychological speculative side of things not really grounded in a neuroscience

for example like um the whole thing about um about some people having more neurons or other

neurons uh sorry i mean the the idea of that some some of the folks have more mirror neurons

that other other mirror neurons well well that is uh i'm like how can you even prove that like

that is just like that's actually they did it they did they did they actually see you see uh

davis and i think several other uc schools were doing studies on that and they actually

covered in science it's they covered that in scientific american about a decade ago it was

called the the broken mirrors theory but they now again i think that all i think it was very

politically incorrect at the work that they were doing so i think they shut it all down

so i i think they were looking into it but i think they decided to stop maybe maybe it's

because it was politically correct or maybe because as mica says maybe it's uh it was a trip

toward a you know no man's land no i'm just saying like it's it's it's um there's no there's like

it might be a hypothesis but here but okay so like the one of the reasons why um mirror neuron

stopped being a topic one of the reasons is that there's just like the way the way so mirror

# Part 19

neurons was observed in in monkeys is basically you know there's a very there's very specific neuron

that is going to fire with uh with consistency that that um you know like the like if another monkey's

hand is firing and and the monk it's it's the same neuron that that fires when the monkey's hand

is firing or something like that you know it's just like but that's sort of like you know so

that hasn't been observed in humans what's been observed is that maybe we have like a functional

version of a mirror neuron maybe maybe a neural circuit's doing the same job as an as a mirror

neuron and and and and like like identifying like actual like being able to identify to look at a

human being with enough detail that you can identify where their neurons are which of those

neurons are mirror neurons and which of them are firing correctly and how many mirror neurons they

have this is like this beyond uh any medical imaging technology that in existence like that so so

the idea that you could you could casually say well you know some people just don't have as many

mirror neurons as other people it's just not connected to neuroscience that as is more like

this is like a story it's like that's what I'm that's all I'm saying it's like not it's not uh

it's not uh it's an idea this is not uh grounded in science you mean it's a that hypothesis right

theory so there you go yeah I I agree I mean I I don't know how they uh yeah I think uh you have uh

the uh it's very very reasonable the uh I don't know how they they got it out um yeah the another

thing that I noticed is that like if you're um you know whether like so so there are examples of

like animals being sort of like born with a certain tendency to have certain certain kinds of knowledge

like like um like rats like rats uh are born with certain behaviors that are uh a tendency they're

they're born with a certain tendency to develop behaviors that are relevant to their survival

and um so you have to say well then that that uh that the brain isn't a blank slate where you're

just like you know where you just like it learns everything from scratch where you could like

you know like if you took a rat's brain out and you just you know fed it like data it would just

become like a general purpose computer it's not it's not that simple the rat the rat's brain is

going to have some some some genetic likelihood towards certain kinds of behaviors uh but uh so so

yeah so there might be some genetic likelihood for someone to develop uh empathy there definitely

there definitely is there's no question about that and it is a weird a weird so yeah and what I'm

saying is there is there's there I think there is some question about that like like in terms of

like the degree of it and why it's not consistent with every person there's some question about it

but there's like there's definitely like a genetic uh basis to to why humans are likely to more likely

to to have certain behaviors I but but but I think it's I still think it's like it's the

topic you want a question that's that's all I'm saying it and in in terms of like you know how

much of it could be um uh you know how much of it could could be how much of our brain uh despite

its genetic predispositions is is open to training and open to um to change and that's

interesting it's just an interesting thing to think about yeah it's like you know your hereditary

impulses they're there and it's it's so hard to say how that affects your your tablo rosa so to

speak you're part of the brain that does start blank or however you want to try to you know

talk about that see the thing is also with what I was talking about too is that you know a lot of

the the language you know after doing this for many years and I think others have found this too

in the in the field not that many are working on it yet but um there's there's a there you need to

build you need to have some words before other words and you know there's there tends to be this

this prominence of words being required before other words can go and so the words the words

have to be grafted onto grounded experiences and grounded situations and and grounded nouns

and so that becomes rather invariant invariant and um one can say there's a massive amount of

variability but the groundedness and the and the types and the features of things and the

conditions need to be grounded and they're they're often very easy to identify um and the options become

um easy to easy to identify as well um the the goal is is to be able to make it so that your

nouns are your nouns are like wildcards so that you actually get like every time that anybody in

this room speaks they're going to be using basically the same words over and over again

what's going to change are going to be the topics but the words and the combinations of words that

you're using and when you write up or or if you're writing they're going to be the same over and over

and over again and same combinations and sometimes little different combinations but so the the theory

is that the words and the meanings eventually when you begin to figure them out developmentally

that there are these developmental causal uh causal definitions ideological definitions

various different developmental definitions when you begin to get at these new types of

semantics and these new types of uh sentence structures then you can overlay them basically

over and over again like people do every time they see or do something new

uh is your point that language is kind of you get more sophisticated or what's your point

well no i mean my point is multifaceted i mean the point is that language does get more sophisticated

it does build on itself it's not optional like you can't you can't learn a harder word without

having learned some simpler words first but i i learned the understanding that you could actually

convey incredibly complex theoretically the maximum complex ideas simply with minimal mental

words too yeah i i tend to agree i agree with that too and that mirrors a lot of the work that i do

there's no question about that um but in addition so we're talking about the the language and then

what was your other uh just lost my train of thought you were you we were talking about um oh

yeah you're saying is that is what i'm trying to explain just the idea of language no it's it's not

just language it's it's the it's the templated it's that we use language as templates all the time

language is all about communication and yes i think that i think that obviously helps our own

communication too in some ways but i also don't think it's essential to just us um thinking

ourselves about and making connections about what is reality i'm sorry i don't know how

what you're saying corresponds with what i'm saying i'm you're if i'm not mistaken you're

saying that basically you know language is a tool to understand no i mean again i don't just mean

language too by the way i'm talking about i'm talking about the this uh the human apparatus

right so i'm talking about words that we use to describe our own functioning right that's language

well that is language but it's it's for it stems from words that again that that we we use to

that we that we have in our sensory motor words now okay hang on can i can i um really i i don't

i don't think so can i want to wait i want to weigh in here because uh there's there's a if we so i

have uh okay so like all right this is like um like what so what is so it's interesting because

because when we like like like when we communicate with language we use all these different modalities

we our words refer to things we can see and hear and touch and feel um concepts that are

that are too abstract to assign to one one sensory modality or another we talk about things we can

smell and and um and and this means that language is uh in the brain is not just not not just triggering

one area not just one language area but but when we talk about things we can see that there's there's

neural activity that's happening in our visual cortex and and when we talk about things we can

taste and and and feel there's there's activity happening in our somatosensory cortex and when

we talk about things we sounds we heard or expect to hear that we expect to see activity in our

audio cortex or in our brain you know the brain stem and and and and when we when we um uh talk

about you know abstract concepts we expect to see um you know more maybe more activity and and the

and the in the frontal and prideo lobes and different different areas of the brain it's so so and and

and so like i meant so like what i want to share okay so like i saw this video of a dog one time

right and the dog was this is like bear with me for a second it's a short story but it'll be worth

it okay so the dog is is in the kitchen and it's a video of a dog in the kitchen and the dog is looking

at uh at at at something on the countertop i think it's a pie right and dog it looks over

uh you know at the door to see if anyone else is around and it looks at a stool and it looks at the

pie and then it it looks around the kitchen again and it looks at the door and it looks at the at

the stool and it looks at the pie like it does a cycle it's like and i and like i had this idea and

it was it was like this um okay i'm gonna skip this part of the story because but for some reason uh

but so the dog so like i'm imagining there's a cycle of activity happening in the dog's brain

right there's there's visual activity the dog is seeing one concept and then another concept

it is a sequence of concepts and uh that the dog is seeing that are playing out in like a movie like

it's like okay so like imagine a movie imagine that 10 seconds of dog dog dog's mental space

in that movie uh what you see on your tv screen is a picture of a door and then and then where the

where it doesn't like the kitchen is clear and then the there's a the concept oh yeah the owner's

not home there's that's part of the movie and and then there's the part of the movie where okay there's

a stool so there's a way to reach the countertop and then there's another part of the movie where

there's like a pie that i could get this pie and then we see this dog leap up on the the stool and

then it leaps up on the countertop and then it gets the pie right so here's the thing so what i'm

thinking is that is that the brain the brain is just in order to do normal functions has to calculate

a sequence of patterns a sequence of patterns just like i described um and that when we are

community when we're talking about language we're just we're just outputting what our brain is

doing is is doing to another person i'm just like communicating a sequence of patterns uh and uh

and but but but but the what i'm saying is the essential components of language are really just

the essential components of cognition and there's no um and even without language we are performing

um mental language in a solo way because it is just performing a sequence of patterns that's

what that's what i'm saying and and uh so it doesn't matter if there's one person or more

than one person language is an essential component of cognition so i think one thing that might be

helpful here is just to separate or just state the language is a component of communication

because you know it's all it is it's a building block but communication that think of all the

sensory context you get you can say almost the same words but if you say them differently

they'll the nuance is is going to be real that's just when you guys go back and forth on just

language language it's like yes yes but then communication i think grant said communication

also and it's it's uh it's a component of it so i mean because we see i mean i mean just to riff

on what you're saying david you're seeing you know in your mind's eye color you're you're you're

you're getting auditory representations of the external world you're you know you're getting

smell sensations taste sensations you're you're getting um you know you're you're you're i mean so

there's just there's a there's a mixture you know you're getting spatial dimensions spatial and

temporal dimensions and so i mean some of these things are coming in before you have the time to

capitulate what they are right and so then you have to be able to associate them and then convert

them in the mind um and then after the mind is begin to make some kind of relationships with them

then you're applying language on top of it to represent that so and and often of course the

language is not going to be precise enough to be able to always do that hey yeah this is really

really interesting i wish i could stay longer but i have to go to sleep thank you so much

thanks thanks see you guys this is great thank you bye right

right not to feed the horse but i just i think that um it's a i don't know if i'm right but i

think i am which is just that um language is just a tool we build up and if we didn't have anyone

else to communicate we wouldn't have words to use even internally and we wouldn't need to

and i don't think that would hindered us i think we just use them because it is a tool that we built

up so i mean my main point is that language is not not just words that words are representing

our our internal modalities or what we're in what we're really um we're doing with with our words

# Part 20

is creating a reduced uh a concentrated representation of of our of our internal thoughts or what we

see here and totally there's um a really cool game this is completely like sidetracked but

i figured it's called like 100 it's a card game and basically the way you play it is there's 100

cards and you give you spread them out equally among everybody and you try to um count up from

who has one to two to three to four and it's actually crazy over a couple rounds you get really

good at um just communicating with everyone non verbally about who has the next card but really

what i'm trying to say is that language is not our words it is um our thoughts and that our thought

we're gonna have our thoughts and we're gonna have our our mental representations regardless

of whether or not we're gonna talk to someone else well it might just be semantics because

to me at least semantically language just means words and or sorry language means communication

like language inherently means communicating with someone else it's a tool to communicate with

someone else language you can use all sorts of different things to communicate and you can say

that it's a language well it's not a it's not a semantic difference um because we're not just

using different words to to um i could just i could look at you with my eyes and potentially

communicate urgency stress happiness you know that's a language

okay well that's a client i mean you just contradicted yourself because and then because then

you because didn't you say that language was just um words or you didn't say no i'm saying

language is communicating it's a communication that's that's to me encapsulates it it's to

communicating but you can communicate like i said you know in so many different ways

okay so i mean like i mean i don't know like so um i mean just if we're being very abstract here

like what isn't it in a sense like a human being with a human being is alone in the forest and

there's no animals right it's like just like a weird situation there's no other life forms but

but the human being has this relationship with their environment at least right and your microphone

was on like no i'm saying if human being has their relationship with with um with their environment

at the very least there is a there's always right right so yes so i'm saying that you would it's okay

so that's that was my my my thought experiment earlier on which is you're just born in just

an environment in a forest and you know you never speak with just someone or have something else

that you can even hope to communicate with then you could figure out that you build a hole and get

water and drink the water and you just have all these ideas in your head of what you're trying to do

and you're thinking you know you're thinking but you're not thinking in a language you know because

sometimes you'll say to yourself gosh do this do that okay let me do this but if you think about it

you don't really need those words okay and they and your head those same concepts okay uh so so this

i think this is like i don't know it's like a where our major disagreement is is what i'm saying

is like the things the things that are happening in your head are going to happen regardless of

whether or not you're communicating them to someone else you you're going to have activity

going from your visual cortex your somatosensory cortex to your audio cortex and this is this is

the stuff that is happening in your head when when you when language is happening in your head

and this stuff happens when you're not talking so the same stuff that's happening in your head

before or after is still going to be happening now let's say that you lived in a forest but you

lived in a forest for an infinite infinitely long amount of time but you you you lived you lived in

the forest for eternity but you um and the forest was infinitely big and and you could go any direction

and and there's you know rivers and all sorts of crazy stuff in the forest like super crazy stuff

but you really need to uh to remember remember stuff and remember it's not that good so you

have to begin to write things down and communicate with yourself so in that sense like you're writing

down a representation of your thoughts of what something means you know like map if you're creating

maps creating signs uh you could you would begin to create a language just by yourself just to

remind yourself just just a reduced representation uh and and and you know at some point you know

like the great philosophers uh in in history i think that i think that you can say you can

create a language with yourself i i think that is a good point and i think that that you know

basically a lot of the a lot of the great philosophers spent time uh just asking asking

questions and thinking about their own questions and just sort of developing their minds by themselves

well exactly you you um build a mental model and you can't you know build up on that mental

model with yourself i mean that's all you're ever going to do anyway no i mean you're going to be

actually developing mental models with yourself with other people and what other people have

learned over those days you're getting the mental you're getting information to add to your mental

model if there's someone else then you yourself add it to the mental model sorry to be nuanced

all right so um i think we uh we've uh we've beaten a dead horse

well if i could just if i could just finish it real quick though i mean again i mean i think

that people i think some of the stuff that i was talking about maybe sailed over people's heads

or they didn't they didn't quite understand it but it could very well be that there's a way of

being able to recreate the experiences and the the developmental uh all of this developmental

mental uh modeling and mental mental um learning mental learning uh around our our the space of

our experience and our and language and and domains there there may be a way of doing that

uh in such a way that you're actually able to get a decent reflection about what's going on

in the mind and um in the you know the research that i'm doing and i have done is that you're

beginning to find new ways of defining things whether they're domains whether they're words

whether they're you know psychological aspects of people so and then to be able to actually

experiment to question using we use a question and answering uh methodology upon data uh to be

able to find out if you're actually finding stuff that obviously other techniques have not

been able to uh show that you can find and so the goal is to be able to improve on the the

question and answering capability to be able to make a machine that can begin to go back and

forth with a person in some sort of way like a person can go back and forth with another person

so uh so when i look at old home movies with my siblings it would be like a computer joining us

and kind of create its own mental mapping from a conversation with us i'm trying to think of a

practical application of something like that but i mean yeah i mean it's sort of like that but it's

also like if anybody saw that movie uh dust was a dust mac in us dust mac in out my i don't know

how to pronounce it but but you know or sort of like what google's doing that they're they're basically

getting all of the um they're laying out all the information about the world on the internet

obviously right and then the goal is that if you get these templates of information right of model

definitions and you're able to reuse them over and over again as questions and then you're able

to use the internet as the answers then you begin to develop this virtuous circle where you're you're

developing a memory a system of memories where you're able to capture images and and and words

and meanings and all manner of domain specific knowledge from the internet and to be able to

layer it in such a way as you would learn it and then to be able to can to create this again another

virtual virtuous circle of being able to iterate upon it layer by layer and so it's it's very

abstracted it i'm not expecting anybody to fully understand that but it's a it's a it's a it's a

new way of of doing a i that people are just sort of beginning to begin beginning beginning to start

to do it's very cool but like i gotta tell you i apologize but i feel like i kind of hijacked

the room a little bit and the room was was awesome what you guys were talking about initially so i do

apologize and i promise to be more aware of that in the future not do it because the topic is really

cool but um i've i've followed you know everybody here i uh thanks a lot for to have the conversation

and and for teaching me lots of things guys i appreciate it but i've gotta i've gotta head

off now okay have a good night thank you i probably take care take care take care everybody whatever

david so i guess i could i guess i could reset the room um so uh so so neuro neurophysics uh

we're talking about uh things like brain waves you know brain waves have oscillations and and

you know brain has rhythms nerve nerve gear we this is a topic of brain computer interfaces it

can be um you know you can talk about there's a narrow link device there's an open water device

there's eeg uh eg is you know something that measures brain rhythms uh are actually brain uh

i'm sorry brain waves uh brain it it represents uh represents brain waves i guess ultimately but

it's it's measuring voltages um coming from your from your brain um and uh and then you know to to

you know related to this topic is a topic of deep learning and you know the in the brain itself

how the brain works how you know cognition works and and uh and and there's lots of lots of related

topics that are you know in the description and and they're also allowed and so i just like is

this popcorn is popcorn style uh meet up so if you want to bring up any topic um that is

tangentially related or ask any question go right ahead and uh so welcome everybody

oh by the way just to just to finish i think people could look this up by the way you know

just so you don't you know you could look up a deep mind uh grounded language development

or grounded language learning and i think there's uh they they've got quite a few publications on it

or you could also read my patent as well so there's you could read about it i mean obviously

i don't think this was a terrible terribly much interest to people in this room but

it is i think a fascinating topic for some

yeah um do you want to share the go ahead um i was just gonna say it's very interesting

um and kind of touching on point i brought up a while ago about embodiment i think a key

component that's missing from a lot of that research is embodiments is is because the

way that the agent is going to understand all that content that it's consuming on the internet

that's going on finding it has to have some kind of a in a case of something like you know abstract

knowledge some kind of multidimensional body um which it uses a template for mapping and

synthesizing that information and giving it a kind of spatial multidimensional spatial understanding

of what it knows what it doesn't know and what kind of information is out there

um i would almost argue that that's language too it's just not language that you're gonna

experience firsthand it's almost like you know like matrix status how do you how does this machine

communicate to your brain you know directly input that into it i i i tuned out for a second but i

but i tuned i tuned back in right we're right when somebody said something about how does

how are we going to input stuff back into your brain can you revise that um kyle i think was

talking about how um sorry baby kyle you want to you want to say it yeah so with the stuff that

deep mind's doing with a lot of this kind of abstract language-based textual understanding

and discovering information and conversing with humans um having a machine without some kind of

embodiment um it is missing a key component because the way we understand the world is through our

bodies through our body maps how we relate to space and without that i don't think we're gonna get

the agi i don't think we're going to be able to create machines that really understand the world

as we do um it doesn't necessarily have to be mimicking a human body but it that that's it's

a fundamental component of our cognition and how we understand the world how we communicate about

the world i agree with you totally kyle don't um you know if i'm talking to you kyle don't

i need to um basically in my mind think about who you are and how i interface with you know how

i'm going to talk to you based on what you know like i'm automatically just going to create a

mental model usually i see bump into you randomly on the street like i'm just gonna have a mental

model of who you are and how to communicate with you i think computer wouldn't be any different

but they hopefully would be able to have an understanding of what our mental model is

to more accurately feed into that based off of you know whatever they can gather

so but our mental model is grounded in our in our physical form and our relation to our environment

same with the computer

well i don't think that that's my point that's my point is a computer needs to have

# Part 21

that kind of model in addition to all this i agree for textual understanding

and that's something that i see missing from deep like deep mind research and all this deep

learning research we just have these neural networks but they they don't have bodies

yes okay um well uh i mean i i i don't agree but but but um but what i'm saying is like um

but i don't know that i'm that far away in in my thinking in in terms of like uh so i think

kao said that yeah it doesn't have to be like a human like body it could be um you know maybe it

could be a spider's body or a robot's body uh or something else um but but i but i would go a

step further in saying and saying that um that uh i don't think it has to be a body in in terms of

like um what what uh what i'm not i'm not talking about a physical body yeah well saying however

where whatever environment this being or whatever exists in it has to have some semblance of of

some kind of form that it controls and that it's experiencing whatever environment it's in

that's right that's right the medium through which it experiences it's its own existence

and almost by definition being access it's controlling something because it's it's giving

it's returning you know in programming it's returning something whether that gets used or not

by definition almost it's it's uh controlling something all right so i mean okay but i mean

like so for example if you look at the the science experiments where you put on a VR headset and they

you're looking through a camera that is behind your own body and you begin to believe that you're

actually behind your own body right and it's like your brain is um is is in the moment spontaneously

creating its representation of space from uh the information you're giving it and and uh and so like

um but like what i'm saying is like the what i'm thinking is like the the brain's core functions

are not are not dependent on on an identification with the physical body in a physical space

or or with a or with a like a location uh i you know a specific location like you don't have to

have a specific location to have thoughts um but but my guy don't think you understand what he's

saying he's talking about going beyond that and going beyond the basic understanding of of spatial

temporal relationships and getting into real-life human experiences as we as we have had all throughout

our lives and also those experiments they didn't have a control which never had a body

because the brain is very plastic and you feed it different inputs and it will be able to very

quickly know that okay that i'm used to being in this body from this perspective but now i am behind

my own body when i move my arm it's still the same i'm still getting the same feedback okay okay okay

but look here's here's you know the problem the problem is you're defining a situation where

it's not possible to have artificial general intelligence without a body but then but then

when you're talking about like what the body is for you're saying well it's it's the it's for you're

saying the artificial general intelligence uh that's the only artificial intelligence that qualifies

as artificial general intelligence for you is artificial intelligence why am i stumbling

artificial it is the the only kind of agi that qualifies as agi for you is the kind that understands

the human condition in a spatial way in a body way and i'm not i'm not talking about the human

condition i'm just saying that having a sense of self of something that is the brain controls

and a medium through which experiences the environment is fundamental to cognition

on a very general level no i i so i don't agree with that i'm sorry i mean like okay it's it's

how we form memories i mean our spatial temporal like our body map it and how we our body relates

to the world it's it's fundamentally linked to how we form memories and how we understand things

well i think i mean i think that's i think that's an interesting idea that but i but i don't think

that's that's consistent with actually how memories form i i agree with you kyle i mean i think

and mika i'm still curious to hear why you don't agree with it well um okay i mean so you so

that you there is a there's a there's a part in a part of the brain that has been called the

homunculus it's associated with with representations of your body your hands and it's interesting

because in the homunculus your hands are huge because there's a whole whole lot of stuff to

know about your hands but um but other parts of your of the homunculus are really tiny so like

your legs are really tiny in the homunculus because there's not a lot of stuff you need to

know about your legs and um and it's just really interesting that the representation of your body

is like this warped warped thing you look up the homunculus on the web it's just really warped

version or shape of your body it's really cool but but the thing is like if like there's nothing

like it's not it's like it's it's kind of like saying that you need the homunculus in order to

have memory but the monculus is in the neocortex it's not essential for memory formation memory

formation is is is uh happens everywhere in the neocortex and maybe everywhere in the brain but

it's like uh you know it's been mapped out it's been like your memory forms you know you know

with with uh this process there's short term there's long-term memory any new data you get just aren't

acting for forming a new memory technically it might it might uh it might be disregarded I think

there's a semantic difference between Micah what you're trying to say and what Kyle's trying to

say Micah you're talking about how memories get created in the brain and and you know what with

the actual uh neuronal you know chemistry is and and that's fine there's that that's right

but what Kyle's discussing is after this this process has occurred when you're actually you

have formed a a live you know or at least a simulated human then the human actually has

to go about its life and then it uses what it has in its mind to be able to interact with the world

and then it forms representations about everything that it experiences and learns

So I mean it and the the monkey is just one component because it's not just our body map

it's our body map in our environment so how we relate to things in our environment how we

determine spatial relationships it it's linked with the monoculus so I agree with you Kyle

and there's again I'm not a neuroscientist I'm not too deep into the literature but I've come

across several articles which have talked about how we form spatial temporal memories and how we

form those maps of environments and it goes beyond just the monoculus I mean it's we have like we

walk into different rooms it activates different memory centers relating to those rooms and so

it's like our mental model and how we think about things it's tied to our bodies and the

environments we're in and my point is that for an AGI yeah it's not gonna have a human body

it's not gonna have a 3D body necessarily but how it understands the information it knows

on I think on a fundamental level needs to be have some kind of spatial construct

and how it knows where to go to find new information

like that's what I call it the body like it could think of it like a like a amoeba like with

tentacles like it knows like this arm is for you know sci-fi this other arm is for you know how to walk

um okay but but um okay so so um I still don't agree but I think I would describe what you're

saying is more like a philosophy or a viewpoint um I don't want to I don't I don't want to like

you know say it right that you're wrong or anything but I just like I don't I don't know the

narrow basis of what your of why you um of your argument but but I would say I would say sorry

could you say that your argument and again I probably tend to try to oversimplify it here but

you say your argument is basically thought needs to be physical on some level you know and that

physicality can be linked to what it's perceived in the real world but at the end of the day that

thought is physical and that's almost like almost important terms of how you see it how it's also

manifests itself and gathering it from physical reality I mean it's a reflection of the physical

not necessarily physical right but also I would argue that it is as well if you take it to the next

step I mean it it links to you know when we think about you know the boring action you know we're

firing up the same kind of centers in our brains as if we were experiencing that action when we're

sizing up another person like when we're sizing somebody up or when we're trying to estimate

you know any any number of the estimations that we make on a moment by moment basis we're we're

constantly comparing ourselves to the world we need to be able to model the world in all those

that different unique aspects exactly and for AGI I'm not saying it needs to be linked to a 3D or 4D world but it needs to have that kind of representation of the environment that it's in and for an AGI again this will be like a multi-dimensional environment

okay I don't know why I'd like to speak without being interrupted but I'm just so going back to Kyle's

question there there are there's I mean the hypothesis that Kyle's is sharing that there are

there are place cells and grid cells in the internal cortex of the human being just like in a mouse

that do track your look your location within a room and at the minimum you know you and and you're in which room you're in your grid cells might

my room which room you're in and your place cells where you are in your orientation in the room and so

on that level you can say that that you know at least the human ego is a directional concept in a in a in a spatial

coordination system that's what the identity is the identity is a is a is a is a directional concept within within a room right and that's within

other rooms and at the minimum but what I'm saying is that like you know there there are there there's there's you know at least you know you've heard legends of

of of brain states where people reach selflessness like where they reach they realize there is no self that

it's just like a fiction like it's just like you can you can completely have your ego dissolved with

psychedelic medication for example or you can you can sit on you can sit underneath the tree and meditate

until you realize your oneness like the Buddha and and and and let go of your of your the philosophy

that everything is essential to your ego and i'm only sure i'm only sharing those concepts just um

just just for to say well so i mean what what if there's another way of cognition that is not it is

actually selfless um that is not uh really um about you know the even like the directional concept of

where you are and and all i'm saying is like beyond the entering a cortex beyond the brain

stem and the neocortex you have also it's hypothesized by some that there are um play cells and grid

cells in and i'll throw all throughout the neocortex and that these that these um these functions are in a

spatial way doing uh calculations that organize um like um things like the like the the orientation of

your phone the shapes and the sights and the feeling of your phone and and and how the phone is changing

and you might have another uh neural column that's you know you have a neural column that's

tracking every single object in the environment around you uh it might be tracking the room you're in

or the or or the features of the landscape that you're in um and that you're in and and so but

fundamentally it's like your brain is uh compared it's like creating like a it's like you have a

whole bunch of um it's like so imagine your whole your whole thought space everything that you see

like every item in in the world around you including the environment including the representation of

yourself consists of patterns patterns that have spatial characteristics and patterns that have

temporal characteristics and every thought that you have has temporal and spatial characteristics

every feeling that you have uh has temporal and spatial characteristics like like patterns like

you know frequencies vibrations and um and and every kind of thought that every kind of feeling

has temporal spatial characteristics and if you take away one part of this picture the rest of

them remain and what it means is like your your your brain is merging the temporal and

spatial characteristics of of sounds with sights with you know what you see with what you hear

with what you feel and so this whole like the whole landscape of human the human conscious

experience the thought workspace the the experience of you you are somewhere even without yourself

there is um this sort of like uh there's this sort of like um uh pattern that is that is being uh

that that that is being generated like generate like um like uh uh kind of like um like like

your like the the the the crudest possible uh comparison would be like a volumetric video

right like a volumetric video inside of inside of your headset like that that environment is sort

of like kind of like what your brain is doing it's like creating that and and it's but it's

creating that but it's it's bringing together it's connecting uh all the different modalities that

you have your your everything you hear is it's connected to everything you see and and if you

if you took out part of it then like like like right now you are you are missing part of it

like there's there's everything behind you is is missing right you're only you're only seeing what's

in front of you right right and then and then um and then there's also a hole in in each of your

eyes and you're not even noticing there's a hole missing and so at some point if you just if you

didn't have uh any self the rest of it remains there's just all this stuff happening but there's no

self and that's like that is like this sort of like yeah if you realize it's yeah all this stuff

is happening but it's not happening to anybody right it's just it's not happening to anybody

there's no self the self is just another rendering another idea it's another it's a directional concept

# Part 22

there's no self and so that's what i'm saying it's like there's another way of of seeing it there's no

there's no actual stuff it's just a directional concept and it's just stuff happening you can

remove the location of your ideas and thoughts from it and it still you know retains itself

uh well i mean that there's i mean that so there in a sense there's uh like there's a

location of where the stuff is right but this stuff doesn't have to be connected to a self

right it could just be your this is the you could there's just a little constantly think about the

last i think about the last idea you had to have nothing to think about like the last grand idea

or whatever it was something that you were thinking about that really had nothing to do where you were

you still remember where you were when you were thinking about that i'm not i'm not i'm just saying

like it's worth thinking about because i think that it is intrinsically tied so oh okay so look

i'm saying that um um you may have there there might be there might be spatial memories happening

but that doesn't mean they're connected to yourself uh they might be connected to a location

and so you could just you could just interpret it a machine could interpret it as there are memories

that are happening in this location and there were there are memories that happened in another

location and and and and human could also interpret it this way it doesn't have to have

anything to do with with all the things that you might associate with yourself today these things

could just be things that are happening in different locations that your brain that the

brain is tracking and uh i completely agree with you and that's why i say for a machine it will be

multi-dimensional and i think our brain does this as well is that when we form representations of the

objects in our environments we are forming multi-dimensional representations one set of

dimensions is for ourselves other sets of dimensions are for other things and our brain

is able to synthesize that into a self because it needs to because it's controlling a single body

in a machine with a multi-dimensional space that exists in it could have multiple bodies

and it could be experiencing multiple environments simultaneously of multiple objects

and they would all be represented represented in a similar way the body and an object there's no

distinction really it's just when the you need to communicate or you need to perform actions there's

only one or some number of things that you can actually control everything else is external

there's a clear delineation between what is controllable and what is not controllable

does that make sense i hear what you're saying but but the but the main point is i'm just

differing on the on the on the idea that you need a self in order to have a gi i don't think you do

that was my point i think probably abstract my point a little bit to say you need a delineation

between self whether that's a multi-part self or a single part self and that can be controlled

and what is not controllable what exists outside the self so i so and i um i think that you don't

need that because uh because it is possible to because the brain is a general learning algorithm

and and because of the way the brain forms um a conscious uh thought workspace is a general

thing what i'm saying is like if you if you had a brain like you know basically the same thing

as a brain but it was in a machine and uh you only fed the brain basically like uh you feel

the brain many different kinds of data but some of the data was like stock data some of the data

was weather data uh how have you know clouds are forming the the atmospheric changes um you know it's

in and what i'm saying is like yeah if all the different you know instead of having the the the

kinds of senses that we have all the senses are just like different kinds of data streams

i mean all our senses are just different kinds of data streams but like instead of like touch

data stream it has um uh you know maybe it's just like sampling of the soil moisture across the

planet or something and but the essential but essentially the structure of the brain is going

to become conscious of this information and it's going to be able to uh it's going to be able to

understand the um the three-dimensional relationships between uh these different um different patterns

if it uh if that information is is correlated in a consistent way over time like if there is actual

an actual relationship between weather and soil moisture which you which i think we can say yeah

there is um and in a relationship between weather soil moisture and changes in the stock market

this machine and yeah i think there is also right um you know during a snowstorm what's

going to happen to the companies the employees are not going to be at work right um and uh i mean

unless it's unless we're in a post-pandemic world and everybody works at home anyways

in which case the company might be more productive but um the point is that like yeah so like the

like you can have a machine an artificial general intelligence has no sense of embodiment

that is conscious of patterns and able to communicate those patterns um that relate many

high-dimensional structures to one another and it does not have a sense of embodiment and

does not have any sense of self that's my that's what i'm saying the the thing is that it needs to

fill itself with experiences it yes it can it can it can think you know what you're describing

it definitely could do certain things but it wouldn't have the expanse of of human experience

stories and narratives and um i mean just you know different the deep well of memories

that that's that all of us have the all of the opinions all of the uh you know you need to be

able to imbue it with with uh it doesn't have to have one personality but it needs to be able to

it needs to be able to understand the views of many uh humans and it needs to be able to

exemplify each view as if it embodied is at least one of them and compare one to the other

so they can begin to compare and contrast uh multiple experiences that people can have

so again this is like what i was saying earlier that the somebody that you're there's a conflation

of uh in order to be agi it has to understand human experiences and that's that's what i'm saying is

not i can't don't agree with you can have an agi that doesn't understand human experiences but it is

sentient and self-aware and possibly um able to experience the weather and able to experience the

soil and able to experience the stock market in ways that are fundamentally and are fundamentally

deeper than any experience that human being uh has ever had with with because because the amount of

sensory information you could feed that computer might be vastly greater than human senses but you

but you but in a way though you're just arguing you're saying that these sensory experiences

that you're that you're suggesting are more they're more vivid and they're more they're

deeper and and you're it's almost like you're saying well that's better than human experience

and it's done it's just different it's just a different thing and i also the human experience

is subjective like you're just saying you're basically relatable to other things and like

you can qualify them in a genre as humans but like uh i just want to point out that that is

subjective and i would argue that the correlations that are formed even without any defined self

are they form a sense of self that's even if you're not controlling the weather you're not

controlling the stock stock market oh i i the models that the models that are formed

are kind of mini selves just being able to execute slash think inherently means

there's a self because you're computing somewhere you are computing whether you think you're

whether you're a human or a hard drive somewhere that's a that's that is an entity that's a self

it belongs to a part it belongs to a greater part or a better whole sorry or at least i would i would

add to a grant to saying it could be a self-work it at least be some sort of machine that is

that basically takes on the character the character of another self and be able to and

can be able to say that it is represented is seeking to embody and represent that self

for a time something like that i think that thought is an emergent property of a type of

calculation and this thought is tied to many different things inherently i think the location

in um is certainly one of those things because it's it's literally inherent to the process like

you literally if if we were to you know x y z coordinate this thought it exists in certain

atoms in this like you know parameter and x y z coordinates no i was just simply saying grant

i don't know if you understood what i was saying i was just simply saying that um that such a such

a machine would it doesn't necessarily have to have its own experiences it could it could live

its life on the internet and to be able to embody the experiences of other of other cells that have

lived but that's basically just like saying that um it's just going to get its information you know

somewhere else like yeah you can use the internet as a source of information that's cool but it's

just source information it's something that unique in a way no i mean no and that's why i spent all

this all this time talking about you know the sort of theory that i have which is to be able to

create all the the mechanisms the all the mechanisms and all of the uh the developments

that a person would need to go through in order to begin to understand uh you know what what what

it would mean to have the embodiments as Kyle talked about so you don't think about it to be able

to experience things you don't need to do that for a dog or a cat you just you just through an

understanding of the world can easily relate to them now because you're like oh i know cats

and they need us or dogs is that a computer would probably do the same thing with human no no i

disagree i mean you're saying that that that then agi can just basically just sort of just pick up

and teach itself without but actually going through the process of a human no no think about

think about um intelligence as it relates to below us as it is above us a policy computer below us a

dog i think that the the way that animal that learning is done in a brain is is um fairly

universal and so it's therefore it's therefore easy to um empathize intelligence wise with what's

going on right i'm just saying that it's extremely difficult um to do this is not this is none of

this is trivial this is extraordinary computer to empathize with a human would definitely be not

where we are today right and not only that not just to empathize but to be able to to to create

all of the language and then all of these experiences that we have well that's kind of what i mean is

to understand to engage and interact and empathize it's not like a catchall but yeah apologies if i

come off as like aggressive that's kind of how i i am yeah i did notice that a bit but but i see

that you're calming down a little bit though after after the first uh hour and a half will make you

calm i uh yeah that's just how i am it's that but some people think that way some people think

that way you know i i can't you know when i was when i was seeing you be kind of aggressive

i was just thinking to myself maybe this guy is just that's the way he needs to be able to be so

intense in order to get his thought out and that you know i don't want to you know that you know

just could be just the natural way that that's something you know it's it's not that i understand

it all completely but when i understand something i i'm passionate about it because it's like look

i'm not just you know talking out of my ass like i think you want to ground it you want to ground

yourself in some and you want to be able to get that some meaning and be able to establish that you

got that that meaning yeah i mean ai and consciousness is something that i like you know super passionate

about um and it's also something that i completely you know don't understand i think i just have

the basics of it but i do think that the basics of it are one thing i i want to impart on everyone

here that i think is super interesting and anyone interested in ai in general should check it out

is this thing called a chaos game um anyone know what that is or have heard of it

sounds like i was like okay so basically um and just one last question you guys anyone

heard of cellular automata yes steven welfare yeah yeah i have a huge hand okay so anyway

what chaos game is is okay imagine that you draw three dots you get a piece of paper okay

i'm gonna draw three dots on it right it makes a circle or sorry triangle now i'm gonna take a die

and i'm gonna say hey if it rolls one or two sorry first uh without this triangle i'm gonna

put a random dot anywhere on it okay then i'm gonna take a dice or a die i'm gonna roll it

and if it gets a one to two a three to four or five to six i'm gonna then

# Part 23

take my marker and put it halfway in between um one of those three dots the triangle makes

and the initial dot that i made okay does that make sense

anyway if i keep on rolling a die and i put it halfway in between the point of the triangle

that i initially made and where my last point was it actually creates an incredibly accurate fractal

so the point of this being is that math and nature it's just literally um it's emergent

it's baked into what just simple numbers like you can't create a parallel universe like it all is

baked into what like the inherent nature of everything and this is probably what intelligence

and thought comes out of too like we're not going to create an incredibly elegant for loop what we're

going to do is we're going to understand how nature itself calculates and build on top of that using

a physical kind of hardware but it's probably not going to be some binary one and zeroes or

or you know how we do logic gates right now that's i like i like i like how you uh you reduced uh

you reduced the uh the pursuit of agi is a is a very complex for loop that was is really neat

so i like that you're brought up cellular automatic because i don't think agi is going to come out of

artificial neural networks i think it's going to be something completely different than the way

that our brains are structured something that works in silicon or whatever medium we end up

creating that allows an agi to emerge from and i think it's going to be something like a cellular

automatic i want to also welcome george at the stage um and uh so so welcome george

mike sorry i've been listening and uh trying to find a uh a segue to say something but i

at the same time what you guys were talking about was so interesting that i i couldn't dare to interrupt

what you were saying uh and i hope you're not getting sick of me because uh in the last few days

we've been coming to the same rooms and and uh uh but just for the guys who haven't listened or

listened to my voice i heard my voice before i'm a neurologist and i'm fascinated by computer and

brain interfaces even though i have minimal understanding about uh ai's and and how technology

is going to work but i keep on thinking how this can be translated into into a uh a brain-like

structure and i and i think it's uh it's every day it becomes more clear in my mind but also more

um uh difficult to to think about it but um the first thing i would just like to mention

to grand when you mention about the universe and mathematics i'm pretty sure you read or

you're familiar with max mark tec max books and uh our mathematical universe is a is a masterpiece

have you ever read it no i haven't i i only know seven roll from from what um someone said earlier

christ for for christ sake go in by the book now or get the audiobook our method yeah what's it

what's it called i'll buy right now our mathematical universe by mark tec mark uh next tec mark

amazing read and he has another follow-up quote um life 3.0 which talks about one of my friends

i have i have that book one of my buddies like really wanted me to get it i'll get the book you

just said that right now so read mathematical universe first because i think it's a better

sequence of doing this but he but but yeah he so he talks all about how everything we know

every single concept can be translated into mathematics from the most biological concept of

the most abstract concept everything is explained by mathematics it's amazing and then life 3.0 he

talks about how he talks about life point 1.0 would be the primitive man caveman life 2.0 is

industrial revolution and then life 3.0 will be ai and whatever comes after what we're living now so

it's a it's very very interesting one of the things that i sorry sorry i back to tie you off

and i'm really bad at that but it's i think one of the interesting things that regarding ai is just

that um when it comes about the singularity or whatever and obviously no one knows what that's

gonna look like but i forget which um you know scientific author was talking about this but

basically i part of me really thinks what will happen is that humans will almost have like

a father figure so to speak of it's like you know you're living we're not we're not like slaves to

this computer but no it's the opposite so the what's what's what this book said talks so this guy

talks about that there are three possibilities possibility number one which is the one that

everyone's scared of is that they will take over and will be slaves possibility number two will be

that will will be co-workers and one will complement the other so they will be much better than us in

some aspects i don't think it is an anal i don't think it's i think it yeah i'm sorry i it's just

for the lack of a better expression or a word for it and the third possibility is that ai would be

working for us and we will be on a uh an eternal no i don't think it is but i oh oh what about

just a good turn is we just took a turn what about a future what about a fourth because

what i think it is is it's it's gonna be it's gonna be um not they because it's singular because

yes and no but yeah in a sense it's singular because they're gonna just work

you know it because um so i can't agree with that it will it'll grow on top of it i'm paraphrasing

someone i'm not i'm not saying that this is what i believe because i don't know what to believe in

imagine 100 years ago we will okay 100 years from now we wake up we go to start our day and we ask

alexa basically whatever the hell we want and you don't have to worry about a job because it's

all taken care of but you could ask it imagine asking like god imagine asking almost like an all

knowing being whatever the hell you want you can just ask it a question you can ask it what you

wanted to do that day you could ask it how you could get a date whatever the hell you want like

it's literally your premium sidekick but the thing is everyone has that everyone has it you're

living in an almost a utopia of sorts because it's true knowledge and you this knowledge itself

wants to get better and us as people we want the knowledge to get better because it helps us

and it's a symbiotic relationship and it also like um so is more it it's like gravity it'll

suck things into it to help it compute so it's not like there's gonna be a bunch of them because

that's it that's that's not how it's supposed to that's not how it's gonna go so i i i don't agree

with that um but you know like uh so there and there's a bunch of novels like that that um

that deal with like the future with multiple ai's and um and and the thing is like um right now the

situation is like there's like an arms race to be the first to build sentient ai because if you're

if someone else builds the the self-aware network sentient ai first and potentially they could use

that to take over the world so you need to build your own so you can defend against the other persons

uh self-aware ai every country needs to build their own self-aware sentient ai to defend against

the another country doing the same thing because imagine if um you know like we hear a lot of

scariest we hear a lot of scary stories about uh some of the some of the countries that are very

far away and and uh they they uh you know they have uh practices that you know late labor camps and

and uh and lack of and lack of freedoms and and all these you know horror stories that we don't uh

we don't like and and what if that what if that country got uh ai first they could they could

enslave the world and and i i okay as nothing to do with that it just has to do uh so i just um

i'm tired of interruptions thank you grant um but uh let's just move on now the thing can i can i ask

you uh or any of you because again as i mentioned before my knowledge is not that great in the

technological field but i've been reading a lot about ai and and things like that so the way the

brain works for consciousness is quite interesting because obviously it's not a computer it's a it's

a group of computing systems right so you have obviously your cortex which is probably what uh

what gives you the action that makes you behave the way you are but there are several other

structures that are involved but there's a key structure that's called the thalamus which is

the relay so most of the information that come from your body to your brain and most of the information

that go from your brain to your body and most of the information that that goes

go goes through this relay called thalamus and that's probably why when you were talking previously

when you're trying to retrieve a memory you remember uh the where you were the smells you

scented the if it was cold or or hot and this structure also retrieves information from your

memory centers from your uh from the uh hippocampus in your temporal lobes and and gives you clues as

to how you're going to get where you want to get with the sort of information you're dealing with

so this structure the thalamus is very unique and very interesting and and i and i wonder whether

the computer systems that are involved in generating or creating a form of ai have a similar

structure that's working on try to integrate all the centers and try to modulate what kind of

sensations are important or not or the equivalent of sensations that what kind of memories are

important what kind of memories are not important uh so do you guys have any ideas to whether there's

any that's a very big question you asked there george the networks aren't that complex yet

maybe google has something maybe maybe i think it has something on their servers but

but i think it's something that if if we're thinking that we we want to have a machine

that's a brain like structure maybe a way of trying to get there is by having such a structure

that can get all the information that you want from all different areas that you're creating

like for example if you want to have a computer that's not only good in playing chess but good

in playing chess and having a conversation with you and and also planning your supermarket listed

on all these things you probably have to have a a central or a hub where you can modulate all this

information and that you have available and try to make it going through a pipeline that's a common

pipeline that makes you have the particular action that too and i completely agree with you and there

has been something recently uh i came across modular neural networks um i think it came out

of deep mind research um which is kind of going in that direction where you have multiple neural

networks specialized in you know very specific tasks but then you link them together in basically

something like that a thalamus that allows the various features and ways that they represent

things to kind of transfer between the networks but it's still we're very we're very far away

from anything mimicking what the brain does i think so do you think that the solution is maybe to

abolish this idea of building something that looks like a brain and try to find something

an alternative way of having uh an artificial consciousness or intelligence

yes yep that's what we've been talking about here for for quite a while i'm sorry i was very

late i'm so sorry so um um you know i i was going to say to jeremy's point i think alan

alan turing had this idea that that um that that uh we we would solve ai without um the computers

would be able to solve consciousness without being able to without waiting we would need to know how

like if you just have enough calculations like it would it would just like you know the black box

which would um you know you'd run run algorithms and tell the computer is able to just do what we

do and and we wouldn't necessarily and is that right jeremy do you know about that well i don't

know a lot about it no but i mean you know about the concept i mean it depends i mean running

algorithms but i mean it just depends you know this gets very tricky i mean in his day he's talking

about running algorithms on what you know and running what mathematical algorithms or you know

what you know it was unclear as to what what what type of algorithms he had and what what they were

supposed to do right but then you got that gets to a deeper question is even if you had a machine

that basically did everything a human does is it actually conscious no but i think i think mike i

think i understand what your question was was a sort of a sideways question what you were sort of

saying isn't that what you're trying to do jeremy and and so how do you how are you going to be

able to do what well how are you going to be able to do that is that is that what your way no well

what i'm saying is like he is like so so he believed that any machine could emulate any other machine

and that um and uh and and so and but but the idea is that like he he was like he was the guy who

was like yeah we don't need to understand how neurology actually works uh to i think we do i

mean again i don't don't get me wrong i think we do need to understand neurology and how it works

i'm but what i'm saying is that there there is a way before we fully understand all of the neurology

there is there's there appears to be at least and you know a way to be able to mimic the way that

people learn and in the conditions and contexts and experiences and in which in the and in the

developmental order in which humans learn and so that if that can be done and if that can be applied

in a universal algorithm such that it is it has a template ability and with with with wild cards

# Part 24

so so that it can be able to be used and reused over and over again to be able to allow for human

questioners to be with the aid of smart humans to be able to use these algorithms to ask questions

of the world it would be an interpreter for smart people to be able to ask questions of the internet

or of other databases or you know of of any any data that you can accumulate and then the answers

could be could be drawn and then it would begin to begin to have all of the answers and then all of

the the language and all of the the knowledge and then all of the questions and answers all of it

together and then from that you begin to actually have the information required to be able to make

something to be able to not necessarily to make a person but to be able to make sense the way a

person can at least make sense of information the way i'm talking to you i'm generating a language

to begin to get it that what it is to be able to take information and be able to create a smart

question out of knowledge and then to be able to take all that information and make and make

that question uh force that question so that it it can go out and actually find answers and then to

be able to sift through those answers and differentiate those answers and pick which answers you you

find useful and to be able to incorporate that into your knowledge base and so i'm talking about a

the the the most basic type of agi would be first you know that would be the the first thing that

you would get to and so that's that's a general conception of where i'm getting at okay that's

a very abstract statement that's a bunch of that's very abstract that i what i've said here would

require a lot more explanation i just wanted to say hello and welcome to sceo did you want to say

anything hi um hi uh i'm sorry i'm late to the party and i'm going out again now but i'm glad

that this room um came to be like maybe six six from six hours ago yeah so um i would just like

to listen in for now all right um so yeah so going back to um so so in terms of like

you know what i'm doing in terms of studying neurology i would say you know i would say that

people that the the architects of deep learning um and there's many but but maybe some of the

leading names would be like like um like yali kuhn and jiffy hinton and and yashio bengio and

and there's but there's a lot there's a lot of people who are architecting deep learning and um

but they but they but these folks are you know the approach is like they they're not trying to do

computational neuroscience they're not trying to make it super accurate they're they're um

they're building they're they're building like uh you know not not not not not the airplane that

has the bat wings like the one that came before the Wright brothers but but just the airplane

that uh achieves lift off just the minimum amount of of intelligence uh to that a machine needs to

do that's not it doesn't have to bring the rest of biology with it like what what is not essential

about biology and um and and just in just in just uh just focusing on that but it's not like

they're ignoring neuroscience they are these folks do study neuroscience and they study

neuroscience because they're in computational biology because they're looking for new new uh

ways to build uh new kinds of airplanes that are capable of basically um you know neural networks

that have new capabilities right how can we uh how can we make our neural networks uh more

capable and that's sort of like so when I so I mean that that is so then you have guys like

Jeff Hawkins and Jeff Hawkins wants to build a machine that is that is that is really like

getting all like being very precise about doing things the way the brain does

to the but still but still in a way that's like he's trying to eliminate

the non-essential stuff like just isolate the stuff that's essential to intelligence um and

that's sort of like my like my so my take is a little bit different in that I'm really just like

I am I guess I guess it's I guess it's a bridge between both right between between uh Jeff Hawkins

and Jeffrey Hinton like it's it's like I am really trying to to understand neurology in a

deep way and I have been uh and for for since 2005 and so that I um have this like uh really deep

understanding of neurology and so that I can so that I can construct artificial neural

architectures that uh you know basically um basically really um you know deep learning

networks that are truly 3D deep learning neural networks um and and uh and that's what I think

that you have what that is what we have in the brain is is um is that um uh uh a neural circuit

really represents a deep a 3D a truly 3D uh with six degrees of of interaction

uh neural network in that it is the inputs to this neural network are are coming in every

direction they're coming uh from above and from below they're coming from the left and to the

right they're coming from in front and and and back and and they're also going out in every in

every direction so it's a truly 3D neural network and um and uh you know right now we have in in

if you look up you can see I mentioned this earlier I don't know who was here when I mentioned it

but um but yeah if you look up recurrent neural networks and look up um but look up uh not recurrent

neural networks I'm sorry I look up um I think it's uh the term is let's see the term bi-directional

bi-directional neural net scope so yeah so this is this camp earlier and um or bi-directional

LSTM and and so here we are we have people playing with the the the the neural architecture and the

input and we're taking in we're saying okay we've got these inputs and we now we can we can send

them forward and backward at the same time and we can we can send that we can you know take the

inputs and we can send that we can have two neural networks basically so we take the inputs

instead of it's taken instead of taking the inputs running them in one direction to an output we

going to take the inputs and we're going to send them in two directions to two to two neural networks

to two different outputs and then back and and so and so um and then and then well okay well

what if we did that with what if we did it like what if we had took the input and

At the same time ran it through three different neural networks sent it in three different directions and then sent it back

Right and and then so like but now like like and then and also looped it

What if we looped it as well and now what if we what if we have what if we're sending it in six different directions?

Right and that and and then I think yeah, so in it and they all loop right they'll loop back

So they go in six different directions in both ways and different in each direction and then they loop back and then and then and so now you're like

just barely like

creating a metaphor of what the brain

brain is doing and

Just barely

This is like a whole bunch more, but like yeah, but like this is um

There's so there's so much more to to to that and and but but we can't even

Get close to what the to what the brain is doing unless we like expand

Unless we keep looking at the brain really deeply and expand the the

then the if we look at the neurophysics of brain oscillations and

the the

the transmission of

Patterns and the rhythms of the patterns and the directions of the patterns and the flows of information

Then that information will help us to construct a next-level

Artificial neural networks that that we can then you know, they we can simplify to just the

Essential functions and then give those a shot. So going back to what Jeremy's bottle was

we take our more advanced cognitive neural networks and

And then run them through Jeremy's program of training them the way you would you you would

Train train a child for example to to not just train a child

But for me, it's not just training a child

I start with a child and then I go into into adulthood like you literally you're training it through all of the all of the known experiences all of the known

psychological and linguistic and

Experience, you know

interactions that it would have

You know all of these sort of like nitsi and universals that that that you would really need to be able to establish

What it is that language actually language in an environment actually means in in terms of the actual like how I'm able to understand

You talk to me and how you understand me when I'm talking to you right now

Yeah, yeah, so some from from childhood to adulthood and into the present moment and beyond

and

but

Yeah, so like my like I'm saying my point was just that yes of Jeremy you have a process of training which is by issues

Really, which is realistic in your in your it's I call it. I call it extremely

Extremely highly supervised. Okay. Okay

And but that's your focus and my focus is like on on new on experimental new architectures

I think it bike bike contrast by contrast

I'm not

And it's not I think it's not that you're not also

Considering experimental new architectures. I just that's just our focus today on in the conversation

So I think we're about done for the night. It was from 6 to 12

I want to thank everybody for coming and maybe we'll give everyone every speaker a chance to say something else in closing

But I'll read me myself

Yeah, thanks, Mike, I enjoyed the conversation and I am heading to bed. I

Enjoyed you know, I enjoyed the company. I enjoyed your thoughts today, Kyle and

I

Enjoyed the other guys thoughts a little less. It was a little bit difficult to deal with but

Still still a smart fellow and and Micah

I think we every time that we meet, you know and to Kyle to every time we meet we sort of learn a little bit more about what the

Others doing and it's a it's a sort of a long winding road

But I really appreciate, you know, we're some of the few people on here

That that actually stick it out with each other and sort of have the patience to sort of it

You know iterate with the other and sort of imagine just what the heck the other one might be up to and you know

Whereas most of these conversations deteriorate so quickly into into chaos

So I really appreciate the stick-to-itiveness that we all seem to possess sure

And then Cecilia you can go next and I'll even hang it out. Do you want to come up and say something before we go?

They should make it so that the people on the bottom should be able to at least talk to the people on the top sometimes

You might be cutting out Cecilia you just maybe try again if you want

You want to try one more time to see you do you want to try to take your microphone off so that you could speak?

It's okay, so sometimes sometimes her she's had she's had been having signal problems this week because of a glitch in clubhouse, so

Yeah

Yeah, well even if I was late to the party, I'm so glad

You see how we know what Cecilia is we know that she's she finished talking and she didn't finish but we still can fill in some of the blanks

We can't hear you Cecilia, but I think we all filled in some of the blanks as to what it is that you were applying

Yeah, that's okay. So

Yes, um, yeah, that's okay. So um and Cecilia is very glad to be here, but she's late to the party

That's what we heard and then her she cut out with that. That's um, that's okay

That's okay. I'll go ahead and give Ali a chance to talk and and then we'll go ahead and end it

Yeah, thanks

This was very interesting discussion. I didn't have a chance to listen to all of it, but I

Uh, I had to make dinner and now I have to go to sleep, but the parts that I did listen to I did learn a lot, so

thank you for holding this room and

I will drop in again later when you are back on again. Thank you

Great. Thank you. It's all it's all been, uh, recorded and so I'll I'll share a copy online and people can listen to it again if they want

Oh, that's cool. That's cool

That is

But by the way, Michael, can I ask you one quick question? Yep

Do you know because I used to work with this guy, uh, Ben Gertzel. Do you do you know what's what's going on with him these days?

Is he I hear he moved back to America

um

You know, uh, I

Cecilia might know more and maybe she maybe uh, why don't you why don't you?

Message me and I'll connect you with with Cecilia or if you can message her directly

That's fine. Also, but but I think she might know a little bit more. I was just curious. I was just curious

That's all you know, I think I think she's more on top of what's going on with Ben than I am

So but we could probably get you the answer

Later on

Oh, that's that's cool. Although. Well, anyway, yeah, I'll talk to you later

Okay

Where would the recording be by the way? Um, so if you if you follow me on twitter, um, I'm gonna post there and uh

Um

Yeah, and if you if you if you if you want to make sure that um, that you catch it, um, you could also just

Send send me a message in about a week guess. It's at your calendar

Send me a message about a week in about a week and I'll send it to you for sure by then

Okay, cool. This is gonna be a cool conversation. I think

Yeah, yeah, I think I'm gonna I think I'm gonna uh do these very often so

Um, yeah very often because because you know why because um, because I think that um,

you know, we we have a lot happening with um,

uh, Pete and with neuroscientists and

And deep learning folks and and bci folks, you know on clubhouse, but

But you know and I I expected that we'd be seeing a group like this every single day, but uh, unfortunately

There isn't a group like this every single day and I think there needs to be and

And that is why it was basically my thinking here is like, you know

But I but but I like before I commit to doing it every day

I want to make sure that I can I can do two things at the same time like I can actually work on

Uh, I can actually do my work while hosting this this this meetup. So if I can do both

Um at the same time, then I can just have this like open sort of open chat

Every day, but um, but I have to see if I can do that before I before I commit to it

So that's what I'm thinking

Sounds good

All right, uh, so I'm gonna say good night and good night. It's everybody. Good night. Yeah, good night everyone

Good night. See you again next time

Okay, good night

You

You